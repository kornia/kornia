<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />

        <script async src="https://www.googletagmanager.com/gtag/js?id=G-YSCFZB2WDV"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-YSCFZB2WDV');

        </script>
    <link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="kornia.color" href="color.html" /><link rel="prev" title="Augmentation Containers" href="augmentation.container.html" />
        <link rel="canonical" href="https://kornia.readthedocs.io/augmentation.module.html" />

    <link rel="shortcut icon" href="_static/kornia_logo_favicon.png"/><!-- Generated with Sphinx 7.4.7 and Furo 2024.08.06 -->
        <title>Image Augmentations - Kornia</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d75fae25" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="_static/css/main.css?v=9b880210" />




<style>
  body {
    --color-code-background: #f0f0f0;
  --color-code-foreground: black;
  --color-sidebar-background: #3980F5;
  --color-sidebar-background-border: #3980F5;
  --color-sidebar-caption-text: white;
  --color-sidebar-link-text--top-level: white;
  --color-sidebar-link-text: white;
  --sidebar-caption-font-size: normal;
  --color-sidebar-item-background--hover:  #5dade2;

  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-sidebar-background: #1a1c1e;
  --color-sidebar-background-border: #1a1c1e;
  --color-sidebar-caption-text: white;
  --color-sidebar-link-text--top-level: white;

    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-sidebar-background: #1a1c1e;
  --color-sidebar-background-border: #1a1c1e;
  --color-sidebar-caption-text: white;
  --color-sidebar-link-text--top-level: white;

      }
    }
  }
</style></head>
  <body>

    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>


<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">Kornia</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">

      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">

  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="_static/img/kornia_logo_only_light.svg" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="_static/img/kornia_logo_only_dark.svg" alt="Dark Logo"/>
  </div>


</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">GET STARTED</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="get-started/introduction.html">What is Kornia library ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/highlights.html">Highlighted Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/about.html">About</a></li>
<li class="toctree-l1"><a class="reference external" href="https://kornia.github.io/tutorials/">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/multi-framework-support.html">Multi-Framework Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/training.html">Training API (experimental)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.luxonis.com/en/latest/pages/tutorials/creating-custom-nn-models/#kornia">OpenCV AI Kit</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/governance.html">Kornia AI Organization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API REFERENCE</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="augmentation.html">kornia.augmentation</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of kornia.augmentation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="augmentation.auto.html">Automatic Augmentation Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="augmentation.base.html">Base Classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="augmentation.container.html">Augmentation Containers</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Image Augmentations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="color.html">kornia.color</a></li>
<li class="toctree-l1"><a class="reference internal" href="contrib.html">kornia.contrib</a></li>
<li class="toctree-l1"><a class="reference internal" href="core.html">kornia.core</a></li>
<li class="toctree-l1"><a class="reference internal" href="enhance.html">kornia.enhance</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature.html">Local Features and Image Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="filters.html">kornia.filters</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="geometry.html">kornia.geometry</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of kornia.geometry</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="geometry.bbox.html">kornia.geometry.bbox</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.boxes.html">kornia.geometry.boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.keypoints.html">kornia.geometry.keypoints</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.calibration.html">kornia.geometry.calibration</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="geometry.camera.html">kornia.geometry.camera</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of kornia.geometry.camera</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="geometry.camera.pinhole.html">Pinhole Camera</a></li>
<li class="toctree-l3"><a class="reference internal" href="geometry.camera.perspective.html">Perspective Camera</a></li>
<li class="toctree-l3"><a class="reference internal" href="geometry.camera.stereo.html">Stereo Camera</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="geometry.conversions.html">kornia.geometry.conversions</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.depth.html">kornia.geometry.depth</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.epipolar.html">kornia.geometry.epipolar</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.homography.html">kornia.geometry.homography</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.liegroup.html">kornia.geometry.liegroup</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.liegroup.html#lie-algebra">lie algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.liegroup.html#lie-group-and-lie-algebra">lie group and lie algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.linalg.html">kornia.geometry.linalg</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.line.html">kornia.geometry.line</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.quaternion.html">kornia.geometry.quaternion</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.solvers.html">kornia.geometry.solvers</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.subpix.html">kornia.geometry.subpix</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.transform.html">kornia.geometry.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.ransac.html">kornia.geometry.ransac</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="sensors.html">kornia.sensors</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of kornia.sensors</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="sensors.camera.html">kornia.sensors.camera</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="io.html">kornia.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="image.html">kornia.image</a></li>
<li class="toctree-l1"><a class="reference internal" href="losses.html">kornia.losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Models Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">kornia.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="morphology.html">kornia.morphology</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerf.html">kornia.nerf</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">ONNXSequential: Chain Multiple ONNX Models with Ease</a></li>
<li class="toctree-l1"><a class="reference internal" href="tracking.html">kornia.tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">kornia.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">kornia.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="x.html">kornia.x</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KORNIA APPLICATIONS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="applications/intro.html">Computer Vision Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/visual_prompting.html">Visual Prompting</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/face_detection.html">Face Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_augmentations.html">Image Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_classification.html">Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_matching.html">Image Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_stitching.html">Image Stitching</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_registration.html">Image Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_denoising.html">Image Denoising</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/semantic_segmentation.html">Semantic segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/object_detection.html">Object detection</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KORNIA MODELS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="models/efficient_vit.html">EfficientViT</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/rt_detr.html">Real-Time Detection Transformer (RT-DETR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/segment_anything.html">Segment Anything (SAM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/mobile_sam.html">Faster Segment Anything (MobileSAM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/yunet.html">YuNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/vit.html">Vision Transformer (ViT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/vit_mobile.html">MobileViT</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/tiny_vit.html">TinyViT</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/loftr.html">LoFTR (matching)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/defmo.html">DeFMO (video)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/hardnet.html">Hardnet (descriptor)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/affnet.html">Affnet (detection)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/sold2.html">SOLD2 (Line detection and matching)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/dexined.html">Dexined (edge detection)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">SUPPORT</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/kornia/kornia/issues">Issue tracker</a></li>
<li class="toctree-l1"><a class="reference external" href="https://join.slack.com/t/kornia/shared_invite/zt-csobk21g-2AQRi~X9Uu6PLMuUZdvfjA">Slack community</a></li>
<li class="toctree-l1"><a class="reference external" href="https://librecv.org">LibreCV community</a></li>
<li class="toctree-l1"><a class="reference external" href="https://twitter.com/kornia_foss">Twitter @kornia_foss</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/chinese.html">Kornia 社区</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.youtube.com/channel/UCI1SE1Ij2Fast5BSKxoa7Ag">Kornia Youtube</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.linkedin.com/company/kornia/">Kornia LinkedIn</a></li>
<li class="toctree-l1"><a class="reference external" href="https://kornia.org">Kornia AI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">COMMUNITY</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community/contribute.html">Contribute to Kornia</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/faqs.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/bibliography.html">Bibliography</a></li>
</ul>

</div>
</div>

      </div>

    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="_sources/augmentation.module.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="image-augmentations">
<h1>Image Augmentations<a class="headerlink" href="#image-augmentations" title="Link to this heading">¶</a></h1>
<section id="transforms2d">
<h2>Transforms2D<a class="headerlink" href="#transforms2d" title="Link to this heading">¶</a></h2>
<p>Set of operators to perform data augmentation on 2D image tensors.</p>
<section id="intensity">
<h3>Intensity<a class="headerlink" href="#intensity" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.ColorJiggle">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">ColorJiggle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">brightness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contrast</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">saturation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hue</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.ColorJiggle" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random transformation to the brightness, contrast, saturation and hue of a tensor image.</p>
<img alt="_images/ColorJiggle.png" src="_images/ColorJiggle.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>brightness</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – The brightness factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>contrast</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – The contrast factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>saturation</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – The saturation factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>hue</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – The hue factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.adjust_brightness" title="kornia.enhance.adjust_brightness"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_brightness()</span></code></a>,
<a class="reference internal" href="enhance.html#kornia.enhance.adjust_contrast" title="kornia.enhance.adjust_contrast"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_contrast()</span></code></a>. <a class="reference internal" href="enhance.html#kornia.enhance.adjust_saturation" title="kornia.enhance.adjust_saturation"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_saturation()</span></code></a>,
<a class="reference internal" href="enhance.html#kornia.enhance.adjust_hue" title="kornia.enhance.adjust_hue"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_hue()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">ColorJiggle</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993]],</span>

<span class="go">         [[0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993]],</span>

<span class="go">         [[0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">ColorJiggle</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.ColorJitter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">ColorJitter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">brightness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contrast</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">saturation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hue</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.ColorJitter" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random transformation to the brightness, contrast, saturation and hue of a tensor image.</p>
<p>This implementation aligns PIL. Hence, the output is close to TorchVision. However, it does not
follow the color theory and is not be actively maintained. Prefer using
<a class="reference internal" href="#kornia.augmentation.ColorJiggle" title="kornia.augmentation.ColorJiggle"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.augmentation.ColorJiggle()</span></code></a></p>
<img alt="_images/ColorJitter.png" src="_images/ColorJitter.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>brightness</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – The brightness factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>contrast</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – The contrast factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>saturation</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – The saturation factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>hue</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – The hue factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>silence_instantiation_warning</strong> – if True, silence the warning at instantiation.</p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_brightness_accumulative()</span></code>,
<a class="reference internal" href="enhance.html#kornia.enhance.adjust_contrast_with_mean_subtraction" title="kornia.enhance.adjust_contrast_with_mean_subtraction"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_contrast_with_mean_subtraction()</span></code></a>,
<code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_saturation_with_gray_subtraction()</span></code>,
<a class="reference internal" href="enhance.html#kornia.enhance.adjust_hue" title="kornia.enhance.adjust_hue"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_hue()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">ColorJitter</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993]],</span>

<span class="go">         [[0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993]],</span>

<span class="go">         [[0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993],</span>
<span class="go">          [0.9993, 0.9993, 0.9993]]]])</span>
</pre></div>
</div>
<p>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">ColorJitter</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomAutoContrast">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomAutoContrast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">clip_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomAutoContrast" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random auto-contrast of a tensor image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>clip_output</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if true clip output
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.normalize_min_max" title="kornia.enhance.normalize_min_max"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.normalize_min_max()</span></code></a></p>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomBoxBlur">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomBoxBlur</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(3,</span> <span class="pre">3)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">border_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomBoxBlur" title="Link to this definition">¶</a></dt>
<dd><p>Add random blur with a box filter to an image tensor.</p>
<img alt="_images/RandomBoxBlur.png" src="_images/RandomBoxBlur.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – the blurring kernel size.
Default:  <code class="code docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">3)</span></code></p></li>
<li><p><strong>border_type</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – the padding mode to be applied before convolving.
The expected modes are: <code class="docutils literal notranslate"><span class="pre">constant</span></code>, <code class="docutils literal notranslate"><span class="pre">reflect</span></code>, <code class="docutils literal notranslate"><span class="pre">replicate</span></code> or <code class="docutils literal notranslate"><span class="pre">circular</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;reflect&quot;</span></code></p></li>
<li><p><strong>normalized</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if True, L1 norm of the kernel is set to 1.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="filters.html#kornia.filters.box_blur" title="kornia.filters.box_blur"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.filters.box_blur()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">RandomBoxBlur</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 1, 24, 24])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomBoxBlur</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomBrightness">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomBrightness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">brightness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomBrightness" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random transformation to the brightness of a tensor image.</p>
<p>This implementation aligns PIL. Hence, the output is close to TorchVision.</p>
<img alt="_images/RandomBrightness.png" src="_images/RandomBrightness.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>brightness</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – the brightness factor to apply
Default:  <code class="code docutils literal notranslate"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>clip_output</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if true clip output
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>silence_instantiation_warning</strong> – if True, silence the warning at instantiation.</p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.adjust_brightness" title="kornia.enhance.adjust_brightness"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_brightness()</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomBrightness</span><span class="p">(</span><span class="n">brightness</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">2.</span><span class="p">),</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[0.0505, 0.3225, 0.0000],</span>
<span class="go">          [0.0000, 0.0000, 0.1883],</span>
<span class="go">          [0.0443, 0.4507, 0.0099]],</span>

<span class="go">         [[0.1866, 0.0000, 0.0000],</span>
<span class="go">          [0.0000, 0.0000, 0.0000],</span>
<span class="go">          [0.0728, 0.2519, 0.3543]],</span>

<span class="go">         [[0.0000, 0.0000, 0.2359],</span>
<span class="go">          [0.4694, 0.0000, 0.4284],</span>
<span class="go">          [0.0000, 0.1072, 0.5070]]]])</span>
</pre></div>
</div>
<p>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomBrightness</span><span class="p">((</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">1.2</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomChannelDropout">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomChannelDropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_drop_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomChannelDropout" title="Link to this definition">¶</a></dt>
<dd><p>Apply random channel dropout to a batch of images.</p>
<img alt="_images/RandomChannelDropout.png" src="_images/RandomChannelDropout.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_drop_channels</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Number of channels to drop randomly. Default is 1.
Default:  <code class="code docutils literal notranslate"><span class="pre">1</span></code></p></li>
<li><p><strong>fill_value</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – Value to fill the dropped channels with. Default is 0.0.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Apply the same transformation across the batch. Defaults to False.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – Probability of applying the transformation. Defaults to 0.5.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Whether to keep the output shape the same as input <code class="docutils literal notranslate"><span class="pre">True</span></code> or broadcast it
to the batch form <code class="docutils literal notranslate"><span class="pre">False</span></code>. Defaults to False.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl class="simple">
<dt>If <cite>num_drop_channels</cite> is set to 1, it means that for each image in the batch,</dt><dd><p>we will randomly choose one channel to drop.</p>
</dd>
<dt>If <cite>num_drop_channels</cite> is set to 2, it means that for each image in the batch,</dt><dd><p>we will randomly choose two channels to drop.</p>
</dd>
<dt>If num_drop_channels is set to 3, it means that for each image in the batch,</dt><dd><p>we will randomly choose three channels to drop (all image).</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomChannelDropout</span><span class="p">(</span><span class="n">num_drop_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="go">tensor([[[[1., 1., 1.],</span>
<span class="go">          [1., 1., 1.],</span>
<span class="go">          [1., 1., 1.]],</span>

<span class="go">         [[0., 0., 0.],</span>
<span class="go">          [0., 0., 0.],</span>
<span class="go">          [0., 0., 0.]],</span>

<span class="go">         [[1., 1., 1.],</span>
<span class="go">          [1., 1., 1.],</span>
<span class="go">          [1., 1., 1.]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomChannelDropout</span><span class="p">(</span><span class="n">num_drop_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomChannelShuffle">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomChannelShuffle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomChannelShuffle" title="Link to this definition">¶</a></dt>
<dd><p>Shuffle the channels of a batch of multi-dimensional images.</p>
<img alt="_images/RandomChannelShuffle.png" src="_images/RandomChannelShuffle.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input <code class="docutils literal notranslate"><span class="pre">True</span></code> or broadcast it
to the batch form <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">RandomChannelShuffle</span><span class="p">()(</span><span class="n">img</span><span class="p">)</span>
<span class="go">tensor([[[[4., 5.],</span>
<span class="go">          [6., 7.]],</span>

<span class="go">         [[0., 1.],</span>
<span class="go">          [2., 3.]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomChannelShuffle</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomClahe">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomClahe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">clip_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(40.0,</span> <span class="pre">40.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(8,</span> <span class="pre">8)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slow_and_differentiable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomClahe" title="Link to this definition">¶</a></dt>
<dd><p>Apply CLAHE equalization on the input tensor randomly.</p>
<img alt="_images/equalize_clahe.png" src="_images/equalize_clahe.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>clip_limit</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – threshold value for contrast limiting. If 0 clipping is disabled.
Default:  <code class="code docutils literal notranslate"><span class="pre">(40.0,</span> <span class="pre">40.0)</span></code></p></li>
<li><p><strong>grid_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – number of tiles to be cropped in each direction (GH, GW).
Default:  <code class="code docutils literal notranslate"><span class="pre">(8,</span> <span class="pre">8)</span></code></p></li>
<li><p><strong>slow_and_differentiable</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – flag to select implementation
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.equalize_clahe" title="kornia.enhance.equalize_clahe"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.equalize_clahe()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomClahe</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 1, 10, 20])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomClahe</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([2, 3, 10, 20])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomClahe</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomContrast">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomContrast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">contrast</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomContrast" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random transformation to the contrast of a tensor image.</p>
<p>This implementation aligns PIL. Hence, the output is close to TorchVision.</p>
<img alt="_images/RandomContrast.png" src="_images/RandomContrast.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>contrast</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – the contrast factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>clip_output</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if true clip output.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.adjust_contrast" title="kornia.enhance.adjust_contrast"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_contrast()</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomContrast</span><span class="p">(</span><span class="n">contrast</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.</span><span class="p">),</span> <span class="n">p</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[0.2750, 0.4258, 0.0490],</span>
<span class="go">          [0.0732, 0.1704, 0.3514],</span>
<span class="go">          [0.2716, 0.4969, 0.2525]],</span>

<span class="go">         [[0.3505, 0.1934, 0.2227],</span>
<span class="go">          [0.0124, 0.0936, 0.1629],</span>
<span class="go">          [0.2874, 0.3867, 0.4434]],</span>

<span class="go">         [[0.0893, 0.1564, 0.3778],</span>
<span class="go">          [0.5072, 0.2201, 0.4845],</span>
<span class="go">          [0.2325, 0.3064, 0.5281]]]])</span>
</pre></div>
</div>
<p>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomContrast</span><span class="p">((</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">1.2</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomEqualize">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomEqualize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomEqualize" title="Link to this definition">¶</a></dt>
<dd><p>Equalize given tensor image or a batch of tensor images randomly.</p>
<img alt="_images/RandomEqualize.png" src="_images/RandomEqualize.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – Probability to equalize an image.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.equalize" title="kornia.enhance.equalize"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.equalize()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">equalize</span> <span class="o">=</span> <span class="n">RandomEqualize</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">equalize</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],</span>
<span class="go">          [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],</span>
<span class="go">          [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],</span>
<span class="go">          [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],</span>
<span class="go">          [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomEqualize</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomDissolving">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomDissolving</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(100,</span> <span class="pre">500)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'2.1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomDissolving" title="Link to this definition">¶</a></dt>
<dd><p>Perform dissolving transformation using StableDiffusion models.</p>
<p>Based on <span id="id1">[<a class="reference internal" href="community/bibliography.html#id50" title="Jian Shi, Pengyi Zhang, Ni Zhang, Hakim Ghazzai, and Peter Wonka. Dissolving is amplifying: towards fine-grained anomaly detection. 2024.">SZZ+24</a>]</span>, the dissolving transformation is essentially applying one-step
reverse diffusion. Our implementation currently supports HuggingFace implementations of SD 1.4, 1.5
and 2.1. SD 1.X tends to remove more details than SD2.1.</p>
<div class="table-wrapper colwidths-given docutils container" id="id12">
<table class="docutils align-default" id="id12">
<caption><span class="caption-text">Title</span><a class="headerlink" href="#id12" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 33.3%" />
<col style="width: 33.3%" />
<col style="width: 33.3%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>SD 1.4</p></th>
<th class="head"><p>SD 1.5</p></th>
<th class="head"><p>SD 2.1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>figure:: <a class="reference external" href="https://raw.githubusercontent.com/kornia/data/main/dslv-sd-1.4.png">https://raw.githubusercontent.com/kornia/data/main/dslv-sd-1.4.png</a></p></td>
<td><p>figure:: <a class="reference external" href="https://raw.githubusercontent.com/kornia/data/main/dslv-sd-1.5.png">https://raw.githubusercontent.com/kornia/data/main/dslv-sd-1.5.png</a></p></td>
<td><p>figure:: <a class="reference external" href="https://raw.githubusercontent.com/kornia/data/main/dslv-sd-2.1.png">https://raw.githubusercontent.com/kornia/data/main/dslv-sd-2.1.png</a></p></td>
</tr>
</tbody>
</table>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>version</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – the version of the stable diffusion model.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;2.1&quot;</span></code></p></li>
<li><p><strong>step_range</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – the step range of the diffusion model steps. Higher the step, stronger
the dissolving effects.
Default:  <code class="code docutils literal notranslate"><span class="pre">(100,</span> <span class="pre">500)</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></span>) – additional arguments for <cite>.from_pretrained</cite> for HF StableDiffusionPipeline.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomGamma">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomGamma</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomGamma" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random transformation to the gamma of a tensor image.</p>
<p>This implementation aligns PIL. Hence, the output is close to TorchVision.</p>
<img alt="_images/RandomGamma.png" src="_images/RandomGamma.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>gamma</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – the gamma factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>gain</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – the gain factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.adjust_gamma" title="kornia.enhance.adjust_gamma"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_gamma()</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomGamma</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">2.</span><span class="p">),(</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">),</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[1.0000, 1.0000, 0.3912],</span>
<span class="go">          [0.4883, 0.7801, 1.0000],</span>
<span class="go">          [1.0000, 1.0000, 0.9702]],</span>

<span class="go">         [[1.0000, 0.8368, 0.9048],</span>
<span class="go">          [0.1824, 0.5597, 0.7609],</span>
<span class="go">          [1.0000, 1.0000, 1.0000]],</span>

<span class="go">         [[0.5452, 0.7441, 1.0000],</span>
<span class="go">          [1.0000, 0.8990, 1.0000],</span>
<span class="go">          [0.9267, 1.0000, 1.0000]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomGamma</span><span class="p">((</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">1.2</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomGaussianBlur">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomGaussianBlur</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">border_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">separable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomGaussianBlur" title="Link to this definition">¶</a></dt>
<dd><p>Apply gaussian blur given tensor image or a batch of tensor images randomly.</p>
<p>The standard deviation is sampled for each instance.</p>
<img alt="_images/RandomGaussianBlur.png" src="_images/RandomGaussianBlur.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – the size of the kernel.</p></li>
<li><p><strong>sigma</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – the range for the standard deviation of the kernel.</p></li>
<li><p><strong>border_type</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – the padding mode to be applied before convolving.
The expected modes are: <code class="docutils literal notranslate"><span class="pre">constant</span></code>, <code class="docutils literal notranslate"><span class="pre">reflect</span></code>, <code class="docutils literal notranslate"><span class="pre">replicate</span></code> or <code class="docutils literal notranslate"><span class="pre">circular</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;reflect&quot;</span></code></p></li>
<li><p><strong>separable</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – run as composition of two 1d-convolutions.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>silence_instantiation_warning</strong> – if True, silence the warning at instantiation.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="filters.html#kornia.filters.gaussian_blur2d" title="kornia.filters.gaussian_blur2d"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.filters.gaussian_blur2d()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">blur</span> <span class="o">=</span> <span class="n">RandomGaussianBlur</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">blur</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0.5941, 0.5833, 0.5022, 0.4384, 0.3934],</span>
<span class="go">          [0.5310, 0.4964, 0.4113, 0.3637, 0.3472],</span>
<span class="go">          [0.4991, 0.4997, 0.4312, 0.3620, 0.3081],</span>
<span class="go">          [0.6082, 0.5667, 0.4954, 0.3825, 0.3508],</span>
<span class="go">          [0.7042, 0.6849, 0.6275, 0.4753, 0.4105]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomGaussianBlur</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomGaussianIllumination">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomGaussianIllumination</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.01,</span> <span class="pre">0.15)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">center</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.1,</span> <span class="pre">0.9)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.2,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-1.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomGaussianIllumination" title="Link to this definition">¶</a></dt>
<dd><p>Applies random 2D Gaussian illumination patterns to a batch of images.</p>
<img alt="_images/RandomGaussianIllumination.png" src="_images/RandomGaussianIllumination.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gain</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – Range for the gain factor (intensity) applied to the generated illumination.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.01,</span> <span class="pre">0.15)</span></code></p></li>
<li><p><strong>center</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – The center coordinates of the Gaussian distribution are expressed as a
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.1,</span> <span class="pre">0.9)</span></code></p></li>
<li><p><strong>dimensions</strong> (<em>percentage</em><em> of </em><em>the spatial</em>) – math:(H, W).</p></li>
<li><p><strong>sigma</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – The sigma values (standard deviation) of the Gaussian distribution are expressed as a
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.2,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>dimensions</strong> – math:(H, W).</p></li>
<li><p><strong>sign</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – Range for the sign of the Gaussian distribution. If only one sign is needed,
Default:  <code class="code docutils literal notranslate"><span class="pre">(-1.0,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>float.</strong> (<em>insert only as a tuple or</em>)</p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – Probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – If True, apply the same transformation across the entire batch. Default is False.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The generated random numbers are not reproducible across different devices and dtypes. By default,
the parameters will be generated on CPU. This can be changed by calling
<code class="docutils literal notranslate"><span class="pre">self.set_rng_device_and_dtype(device=&quot;cuda&quot;,</span> <span class="pre">dtype=torch.float64)</span></code>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomGaussianIllumination</span><span class="p">(</span><span class="n">gain</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0.7266, 1.0000, 0.7266],</span>
<span class="go">          [0.6621, 0.9121, 0.6621],</span>
<span class="go">          [0.5000, 0.6911, 0.5000]],</span>

<span class="go">         [[0.7266, 1.0000, 0.7266],</span>
<span class="go">          [0.6621, 0.9121, 0.6621],</span>
<span class="go">          [0.5000, 0.6911, 0.5000]],</span>

<span class="go">         [[0.7266, 1.0000, 0.7266],</span>
<span class="go">          [0.6621, 0.9121, 0.6621],</span>
<span class="go">          [0.5000, 0.6911, 0.5000]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomGaussianIllumination</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomGaussianNoise">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomGaussianNoise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomGaussianNoise" title="Link to this definition">¶</a></dt>
<dd><p>Add gaussian noise to a batch of multi-dimensional images.</p>
<img alt="_images/RandomGaussianNoise.png" src="_images/RandomGaussianNoise.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – The mean of the gaussian distribution.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>std</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – The standard deviation of the gaussian distribution.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">RandomGaussianNoise</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)(</span><span class="n">img</span><span class="p">)</span>
<span class="go">tensor([[[[ 2.5410,  0.7066],</span>
<span class="go">          [-1.1788,  1.5684]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomGaussianNoise</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomGrayscale">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomGrayscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rgb_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomGrayscale" title="Link to this definition">¶</a></dt>
<dd><p>Apply random transformation to Grayscale according to a probability p value.</p>
<img alt="_images/RandomGrayscale.png" src="_images/RandomGrayscale.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rgb_weights</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – Weights that will be applied on each channel (RGB).
The sum of the weights should add up to one.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of the image to be transformed to grayscale.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.1</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="color.html#kornia.color.rgb_to_grayscale" title="kornia.color.rgb_to_grayscale"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.color.rgb_to_grayscale()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomGrayscale</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[-1.1344, -0.1330,  0.1517],</span>
<span class="go">          [-0.0791,  0.6711, -0.1413],</span>
<span class="go">          [-0.1717, -0.9023,  0.0819]],</span>

<span class="go">         [[-1.1344, -0.1330,  0.1517],</span>
<span class="go">          [-0.0791,  0.6711, -0.1413],</span>
<span class="go">          [-0.1717, -0.9023,  0.0819]],</span>

<span class="go">         [[-1.1344, -0.1330,  0.1517],</span>
<span class="go">          [-0.0791,  0.6711, -0.1413],</span>
<span class="go">          [-0.1717, -0.9023,  0.0819]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomGrayscale</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomHue">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomHue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hue</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">0.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomHue" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random transformation to the hue of a tensor image.</p>
<p>This implementation aligns PIL. Hence, the output is close to TorchVision.</p>
<img alt="_images/RandomHue.png" src="_images/RandomHue.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hue</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – the saturation factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">0.0)</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.adjust_hue" title="kornia.enhance.adjust_hue"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_hue()</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomHue</span><span class="p">(</span><span class="n">hue</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">),</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[0.3993, 0.2823, 0.6816],</span>
<span class="go">          [0.6117, 0.2090, 0.4081],</span>
<span class="go">          [0.4693, 0.5529, 0.9527]],</span>

<span class="go">         [[0.1610, 0.5962, 0.4971],</span>
<span class="go">          [0.9152, 0.3971, 0.8742],</span>
<span class="go">          [0.4194, 0.6771, 0.7162]],</span>

<span class="go">         [[0.6323, 0.7682, 0.0885],</span>
<span class="go">          [0.0223, 0.1689, 0.2939],</span>
<span class="go">          [0.5185, 0.8964, 0.4556]]]])</span>
</pre></div>
</div>
<p>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomHue</span><span class="p">((</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomInvert">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomInvert</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomInvert" title="Link to this definition">¶</a></dt>
<dd><p>Invert the tensor images values randomly.</p>
<img alt="_images/RandomInvert.png" src="_images/RandomInvert.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_val</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – The expected maximum value in the input tensor. The shape has to
according to the input tensor shape, or at least has to work with broadcasting.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.invert" title="kornia.enhance.invert"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.invert()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inv</span> <span class="o">=</span> <span class="n">RandomInvert</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inv</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="go">tensor([[[[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],</span>
<span class="go">          [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],</span>
<span class="go">          [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],</span>
<span class="go">          [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],</span>
<span class="go">          [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomInvert</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomJPEG">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomJPEG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">jpeg_quality</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomJPEG" title="Link to this definition">¶</a></dt>
<dd><p>Applies random (differentiable) JPEG coding to a tensor image.</p>
<img alt="_images/RandomJPEG.png" src="_images/RandomJPEG.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>jpeg_quality</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – The range of compression rates to be applied.
Default:  <code class="code docutils literal notranslate"><span class="pre">50.0</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.jpeg_codec_differentiable" title="kornia.enhance.jpeg_codec_differentiable"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.jpeg_codec_differentiable()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">images</span> <span class="o">=</span> <span class="mf">0.1904</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomJPEG</span><span class="p">(</span><span class="n">jpeg_quality</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">50.0</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">images_jpeg</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">images</span> <span class="o">=</span> <span class="mf">0.1904</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomJPEG</span><span class="p">(</span><span class="n">jpeg_quality</span><span class="o">=</span><span class="mf">20.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>  <span class="c1"># Samples a JPEG quality from the range [30.0, 70.0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="n">images</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomLinearCornerIllumination">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomLinearCornerIllumination</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.01,</span> <span class="pre">0.2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-1.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomLinearCornerIllumination" title="Link to this definition">¶</a></dt>
<dd><p>Applies random 2D Linear from corner illumination patterns to a batch of images.</p>
<img alt="_images/RandomLinearCornerIllumination.png" src="_images/RandomLinearCornerIllumination.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gain</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – Range for the gain factor (intensity) applied to the generated illumination.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.01,</span> <span class="pre">0.2)</span></code></p></li>
<li><p><strong>sign</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – Range for the sign of the distribution. If only one sign is needed,
Default:  <code class="code docutils literal notranslate"><span class="pre">(-1.0,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>float.</strong> (<em>insert only as a tuple or</em>)</p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – Probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – If True, apply the same transformation across the entire batch. Default is False.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The generated random numbers are not reproducible across different devices and dtypes. By default,
the parameters will be generated on CPU. This can be changed by calling
<code class="docutils literal notranslate"><span class="pre">self.set_rng_device_and_dtype(device=&quot;cuda&quot;,</span> <span class="pre">dtype=torch.float64)</span></code>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomLinearCornerIllumination</span><span class="p">(</span><span class="n">gain</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0.3750, 0.4375, 0.5000],</span>
<span class="go">          [0.3125, 0.3750, 0.4375],</span>
<span class="go">          [0.2500, 0.3125, 0.3750]],</span>

<span class="go">         [[0.3750, 0.4375, 0.5000],</span>
<span class="go">          [0.3125, 0.3750, 0.4375],</span>
<span class="go">          [0.2500, 0.3125, 0.3750]],</span>

<span class="go">         [[0.3750, 0.4375, 0.5000],</span>
<span class="go">          [0.3125, 0.3750, 0.4375],</span>
<span class="go">          [0.2500, 0.3125, 0.3750]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomLinearCornerIllumination</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomLinearIllumination">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomLinearIllumination</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.01,</span> <span class="pre">0.2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-1.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomLinearIllumination" title="Link to this definition">¶</a></dt>
<dd><p>Applies random 2D Linear illumination patterns to a batch of images.</p>
<img alt="_images/RandomLinearIllumination.png" src="_images/RandomLinearIllumination.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gain</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – Range for the gain factor (intensity) applied to the generated illumination.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.01,</span> <span class="pre">0.2)</span></code></p></li>
<li><p><strong>sign</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – Range for the sign of the distribution. If only one sign is needed,
Default:  <code class="code docutils literal notranslate"><span class="pre">(-1.0,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>float.</strong> (<em>insert only as a tuple or</em>)</p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – Probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – If True, apply the same transformation across the entire batch. Default is False.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The generated random numbers are not reproducible across different devices and dtypes. By default,
the parameters will be generated on CPU. This can be changed by calling
<code class="docutils literal notranslate"><span class="pre">self.set_rng_device_and_dtype(device=&quot;cuda&quot;,</span> <span class="pre">dtype=torch.float64)</span></code>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomLinearIllumination</span><span class="p">(</span><span class="n">gain</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0.2500, 0.2500, 0.2500],</span>
<span class="go">          [0.3750, 0.3750, 0.3750],</span>
<span class="go">          [0.5000, 0.5000, 0.5000]],</span>

<span class="go">         [[0.2500, 0.2500, 0.2500],</span>
<span class="go">          [0.3750, 0.3750, 0.3750],</span>
<span class="go">          [0.5000, 0.5000, 0.5000]],</span>

<span class="go">         [[0.2500, 0.2500, 0.2500],</span>
<span class="go">          [0.3750, 0.3750, 0.3750],</span>
<span class="go">          [0.5000, 0.5000, 0.5000]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomLinearIllumination</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomMedianBlur">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomMedianBlur</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(3,</span> <span class="pre">3)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomMedianBlur" title="Link to this definition">¶</a></dt>
<dd><p>Add random blur with a median filter to an image tensor.</p>
<img alt="_images/RandomMedianBlur.png" src="_images/RandomMedianBlur.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – the blurring kernel size.
Default:  <code class="code docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">3)</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="filters.html#kornia.filters.median_blur" title="kornia.filters.median_blur"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.filters.median_blur()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">RandomMedianBlur</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 1, 4, 4])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[[[0., 1., 1., 0.],</span>
<span class="go">          [1., 1., 1., 1.],</span>
<span class="go">          [1., 1., 1., 1.],</span>
<span class="go">          [0., 1., 1., 0.]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomMedianBlur</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomMotionBlur">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomMotionBlur</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">angle</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">direction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">border_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">BorderType.CONSTANT.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.NEAREST.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomMotionBlur" title="Link to this definition">¶</a></dt>
<dd><p>Perform motion blur on 2D images (4D tensor).</p>
<img alt="_images/RandomMotionBlur.png" src="_images/RandomMotionBlur.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>kernel_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]]</span>) – motion kernel size (odd and positive).
If int, the kernel will have a fixed size.
If Tuple[int, int], it will randomly generate the value from the range batch-wisely.</p></li>
<li><p><strong>angle</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>) – angle of the motion blur in degrees (anti-clockwise rotation).
If float, it will generate the value from (-angle, angle).</p></li>
<li><p><strong>direction</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>) – forward/backward direction of the motion blur.
Lower values towards -1.0 will point the motion blur towards the back (with angle provided via angle),
while higher values towards 1.0 will point the motion blur forward. A value of 0.0 leads to a
uniformly (but still angled) motion blur.
If float, it will generate the value from (-direction, direction).
If Tuple[int, int], it will randomly generate the value from the range.</p></li>
<li><p><strong>border_type</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BorderType</span></code>]</span>, <em>optional</em>) – the padding mode to be applied before convolving.
CONSTANT = 0, REFLECT = 1, REPLICATE = 2, CIRCULAR = 3.
Default:  <code class="code docutils literal notranslate"><span class="pre">BorderType.CONSTANT.name</span></code></p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – the interpolation mode.
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.NEAREST.name</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 3, 3)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
<p>Please set <code class="docutils literal notranslate"><span class="pre">resample</span></code> to <code class="docutils literal notranslate"><span class="pre">'bilinear'</span></code> if more meaningful gradients wanted.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="filters.html#kornia.filters.motion_blur" title="kornia.filters.motion_blur"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.filters.motion_blur()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">motion_blur</span> <span class="o">=</span> <span class="n">RandomMotionBlur</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">35.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">motion_blur</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0.5773, 1.0000, 1.0000, 1.0000, 0.7561],</span>
<span class="go">          [0.5773, 1.0000, 1.0000, 1.0000, 0.7561],</span>
<span class="go">          [0.5773, 1.0000, 1.0000, 1.0000, 0.7561],</span>
<span class="go">          [0.5773, 1.0000, 1.0000, 1.0000, 0.7561],</span>
<span class="go">          [0.5773, 1.0000, 1.0000, 1.0000, 0.7561]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomMotionBlur</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">35.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomPlanckianJitter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomPlanckianJitter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'blackbody'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">select_from</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomPlanckianJitter" title="Link to this definition">¶</a></dt>
<dd><p>Apply planckian jitter transformation to input tensor.</p>
<img alt="_images/RandomPlanckianJitter.png" src="_images/RandomPlanckianJitter.png" />
<p>This is physics based color augmentation, that creates realistic
variations in chromaticity, this can simulate the illumination
changes in the scene.</p>
<p>See <span id="id2">[<a class="reference internal" href="community/bibliography.html#id29" title="Simone Zini, Marco Buzzelli, Bartłomiej Twardowski, and Joost van de Weijer. Planckian jitter: enhancing the color quality of self-supervised visual representations. arXiv preprint arXiv:2202.07993, 2022.">ZBTvdW22</a>]</span> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – ‘blackbody’ or ‘CIED’.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;blackbody&quot;</span></code></p></li>
<li><p><strong>select_from</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – choose a list of jitters to apply from. <cite>blackbody</cite> range [0-24], <cite>CIED</cite> range [0-22]
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability that the random erasing operation will be performed.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1].</p>
</div>
<p class="rubric">Examples</p>
<p>To apply planckian jitter based on mode</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomPlanckianJitter</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;CIED&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[ 1.0000, -0.2389],</span>
<span class="go">          [-1.7740,  0.4628]],</span>

<span class="go">         [[-1.0845, -1.3986],</span>
<span class="go">          [ 0.4033,  0.8380]],</span>

<span class="go">         [[-0.9228, -0.5175],</span>
<span class="go">          [-0.7654,  0.2335]]]])</span>
</pre></div>
</div>
<p>To apply planckian jitter on image(s) from list of interested jitters</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomPlanckianJitter</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;blackbody&#39;</span><span class="p">,</span> <span class="n">select_from</span><span class="o">=</span><span class="p">[</span><span class="mi">23</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[-1.1258, -1.1524],</span>
<span class="go">          [-0.2506, -0.4339]],</span>

<span class="go">         [[ 0.8487,  0.6920],</span>
<span class="go">          [-0.3160, -2.1152]],</span>

<span class="go">         [[ 0.4681, -0.1577],</span>
<span class="go">          [ 1.4437,  0.2660]]],</span>


<span class="go">        [[[ 0.2465,  1.0000],</span>
<span class="go">          [-0.2125, -0.1653]],</span>

<span class="go">         [[ 0.9318,  1.0000],</span>
<span class="go">          [ 1.0000,  0.0537]],</span>

<span class="go">         [[ 0.2426, -0.1621],</span>
<span class="go">          [-0.3302, -0.9093]]]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomPlasmaBrightness">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomPlasmaBrightness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">roughness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.1,</span> <span class="pre">0.7)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intensity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomPlasmaBrightness" title="Link to this definition">¶</a></dt>
<dd><p>Adds brightness to the image based on a fractal map generated by the diamond square algorithm.</p>
<img alt="_images/RandomPlasmaBrightness.png" src="_images/RandomPlasmaBrightness.png" />
<p>This is based on the original paper: TorMentor: Deterministic dynamic-path, data augmentations with fractals.
See: <span id="id3">[<a class="reference internal" href="community/bibliography.html#id31" title="Anguelos Nicolaou, Vincent Christlein, Edgar Riba, Jian Shi, Georg Vogeler, and Mathias Seuret. Tormentor: deterministic dynamic-path, data augmentations with fractals. 2022. URL: https://arxiv.org/abs/2204.03776, doi:10.48550/ARXIV.2204.03776.">NCR+22</a>]</span> for more details.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="contrib.html#kornia.contrib.diamond_square" title="kornia.contrib.diamond_square"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.contrib.diamond_square()</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>roughness</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – value to scale during the recursion in the generation of the fractal map.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.1,</span> <span class="pre">0.7)</span></code></p></li>
<li><p><strong>intensity</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – value that scales the intensity values of the generated maps.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">RandomPlasmaBrightness</span><span class="p">(</span><span class="n">roughness</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)(</span><span class="n">img</span><span class="p">)</span>
<span class="go">tensor([[[[0.6415, 1.0000, 0.3142, 0.6836],</span>
<span class="go">          [1.0000, 0.5593, 0.5556, 0.4566],</span>
<span class="go">          [0.5809, 1.0000, 0.7005, 1.0000]]]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomPlasmaContrast">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomPlasmaContrast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">roughness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.1,</span> <span class="pre">0.7)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomPlasmaContrast" title="Link to this definition">¶</a></dt>
<dd><p>Adds contrast to the image based on a fractal map generated by the diamond square algorithm.</p>
<img alt="_images/RandomPlasmaContrast.png" src="_images/RandomPlasmaContrast.png" />
<p>This is based on the original paper: TorMentor: Deterministic dynamic-path, data augmentations with fractals.
See: <span id="id4">[<a class="reference internal" href="community/bibliography.html#id31" title="Anguelos Nicolaou, Vincent Christlein, Edgar Riba, Jian Shi, Georg Vogeler, and Mathias Seuret. Tormentor: deterministic dynamic-path, data augmentations with fractals. 2022. URL: https://arxiv.org/abs/2204.03776, doi:10.48550/ARXIV.2204.03776.">NCR+22</a>]</span> for more details.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="contrib.html#kornia.contrib.diamond_square" title="kornia.contrib.diamond_square"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.contrib.diamond_square()</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>roughness</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – value to scale during the recursion in the generation of the fractal map.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.1,</span> <span class="pre">0.7)</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">RandomPlasmaContrast</span><span class="p">(</span><span class="n">roughness</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)(</span><span class="n">img</span><span class="p">)</span>
<span class="go">tensor([[[[0.9651, 1.0000, 1.0000, 1.0000],</span>
<span class="go">          [1.0000, 0.9103, 0.8038, 0.9263],</span>
<span class="go">          [0.6882, 1.0000, 0.9544, 1.0000]]]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomPlasmaShadow">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomPlasmaShadow</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">roughness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.1,</span> <span class="pre">0.7)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shade_intensity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-1.0,</span> <span class="pre">0.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shade_quantity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomPlasmaShadow" title="Link to this definition">¶</a></dt>
<dd><p>Add gaussian noise to a batch of multi-dimensional images.</p>
<img alt="_images/RandomPlasmaShadow.png" src="_images/RandomPlasmaShadow.png" />
<p>This is based on the original paper: TorMentor: Deterministic dynamic-path, data augmentations with fractals.
See: <span id="id5">[<a class="reference internal" href="community/bibliography.html#id31" title="Anguelos Nicolaou, Vincent Christlein, Edgar Riba, Jian Shi, Georg Vogeler, and Mathias Seuret. Tormentor: deterministic dynamic-path, data augmentations with fractals. 2022. URL: https://arxiv.org/abs/2204.03776, doi:10.48550/ARXIV.2204.03776.">NCR+22</a>]</span> for more details.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="contrib.html#kornia.contrib.diamond_square" title="kornia.contrib.diamond_square"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.contrib.diamond_square()</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>roughness</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – value to scale during the recursion in the generation of the fractal map.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.1,</span> <span class="pre">0.7)</span></code></p></li>
<li><p><strong>shade_intensity</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – value that scales the intensity values of the generated maps.
Default:  <code class="code docutils literal notranslate"><span class="pre">(-1.0,</span> <span class="pre">0.0)</span></code></p></li>
<li><p><strong>shade_quantity</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – value to select the pixels to mask.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">RandomPlasmaShadow</span><span class="p">(</span><span class="n">roughness</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)(</span><span class="n">img</span><span class="p">)</span>
<span class="go">tensor([[[[0.7682, 1.0000, 1.0000, 1.0000],</span>
<span class="go">          [1.0000, 1.0000, 1.0000, 1.0000],</span>
<span class="go">          [1.0000, 1.0000, 1.0000, 1.0000]]]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomPosterize">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomPosterize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomPosterize" title="Link to this definition">¶</a></dt>
<dd><p>Posterize given tensor image or a batch of tensor images randomly.</p>
<img alt="_images/RandomPosterize.png" src="_images/RandomPosterize.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>bits</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – Integer that ranged from (0, 8], in which 0 gives black image and 8 gives the original.
If int x, bits will be generated from (x, 8) then convert to int.
If tuple (x, y), bits will be generated from (x, y) then convert to int.
Default:  <code class="code docutils literal notranslate"><span class="pre">3</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.posterize" title="kornia.enhance.posterize"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.posterize()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">posterize</span> <span class="o">=</span> <span class="n">RandomPosterize</span><span class="p">(</span><span class="mf">3.</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">posterize</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0.4863, 0.7529, 0.0784, 0.1255, 0.2980],</span>
<span class="go">          [0.6275, 0.4863, 0.8941, 0.4549, 0.6275],</span>
<span class="go">          [0.3451, 0.3922, 0.0157, 0.1569, 0.2824],</span>
<span class="go">          [0.5176, 0.6902, 0.8000, 0.1569, 0.2667],</span>
<span class="go">          [0.6745, 0.9098, 0.3922, 0.8627, 0.4078]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomPosterize</span><span class="p">(</span><span class="mf">3.</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomRain">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomRain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">number_of_drops</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1000,</span> <span class="pre">2000)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_height</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(5,</span> <span class="pre">20)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-5,</span> <span class="pre">5)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomRain" title="Link to this definition">¶</a></dt>
<dd><p>Add Random Rain to the image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>number_of_drops</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – number of drops per image
Default:  <code class="code docutils literal notranslate"><span class="pre">(1000,</span> <span class="pre">2000)</span></code></p></li>
<li><p><strong>drop_height</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – height of the drop in image(same for each drops in one image)
Default:  <code class="code docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">20)</span></code></p></li>
<li><p><strong>drop_width</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – width of the drop in image(same for each drops in one image)
Default:  <code class="code docutils literal notranslate"><span class="pre">(-5,</span> <span class="pre">5)</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rain</span> <span class="o">=</span> <span class="n">RandomRain</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">drop_height</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">drop_width</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">number_of_drops</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rain</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0.4963, 0.7843, 0.0885, 0.1320, 0.3074],</span>
<span class="go">          [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],</span>
<span class="go">          [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],</span>
<span class="go">          [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],</span>
<span class="go">          [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]]]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomRGBShift">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomRGBShift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">r_shift_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">g_shift_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b_shift_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomRGBShift" title="Link to this definition">¶</a></dt>
<dd><p>Randomly shift each channel of an image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>r_shift_limit</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – maximum value up to which the shift value can be generated for red channel;
recommended interval - [0, 1], should always be positive
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>g_shift_limit</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – maximum value up to which the shift value can be generated for green channel;
recommended interval - [0, 1], should always be positive
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>b_shift_limit</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – maximum value up to which the shift value can be generated for blue channel;
recommended interval - [0, 1], should always be positive
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input <code class="docutils literal notranslate"><span class="pre">True</span></code> or broadcast it
to the batch form <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1].</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomRGBShift</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">((</span><span class="n">inp</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="n">inp</span><span class="p">))</span><span class="o">.</span><span class="n">double</span><span class="p">())</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inp</span>
<span class="go">tensor([[[[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],</span>
<span class="go">          [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],</span>
<span class="go">          [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],</span>
<span class="go">          [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],</span>
<span class="go">          [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]],</span>

<span class="go">         [[0.5529, 0.9527, 0.0362, 0.1852, 0.3734],</span>
<span class="go">          [0.3051, 0.9320, 0.1759, 0.2698, 0.1507],</span>
<span class="go">          [0.0317, 0.2081, 0.9298, 0.7231, 0.7423],</span>
<span class="go">          [0.5263, 0.2437, 0.5846, 0.0332, 0.1387],</span>
<span class="go">          [0.2422, 0.8155, 0.7932, 0.2783, 0.4820]],</span>

<span class="go">         [[0.8198, 0.9971, 0.6984, 0.5675, 0.8352],</span>
<span class="go">          [0.2056, 0.5932, 0.1123, 0.1535, 0.2417],</span>
<span class="go">          [0.7262, 0.7011, 0.2038, 0.6511, 0.7745],</span>
<span class="go">          [0.4369, 0.5191, 0.6159, 0.8102, 0.9801],</span>
<span class="go">          [0.1147, 0.3168, 0.6965, 0.9143, 0.9351]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomRGBShift</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="go">tensor([[[[0.9374, 1.0000, 0.5297, 0.5732, 0.7486],</span>
<span class="go">          [1.0000, 0.9313, 1.0000, 0.8968, 1.0000],</span>
<span class="go">          [0.7901, 0.8429, 0.4635, 0.6100, 0.7351],</span>
<span class="go">          [0.9597, 1.0000, 1.0000, 0.6022, 0.7234],</span>
<span class="go">          [1.0000, 1.0000, 0.8383, 1.0000, 0.8606]],</span>

<span class="go">         [[0.6524, 1.0000, 0.1357, 0.2847, 0.4729],</span>
<span class="go">          [0.4046, 1.0000, 0.2754, 0.3693, 0.2502],</span>
<span class="go">          [0.1312, 0.3076, 1.0000, 0.8226, 0.8418],</span>
<span class="go">          [0.6258, 0.3432, 0.6841, 0.1327, 0.2382],</span>
<span class="go">          [0.3417, 0.9150, 0.8927, 0.3778, 0.5815]],</span>

<span class="go">         [[0.3850, 0.5623, 0.2636, 0.1328, 0.4005],</span>
<span class="go">          [0.0000, 0.1584, 0.0000, 0.0000, 0.0000],</span>
<span class="go">          [0.2914, 0.2663, 0.0000, 0.2163, 0.3397],</span>
<span class="go">          [0.0021, 0.0843, 0.1811, 0.3754, 0.5453],</span>
<span class="go">          [0.0000, 0.0000, 0.2617, 0.4795, 0.5003]]]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomSaltAndPepperNoise">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomSaltAndPepperNoise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">amount</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.01,</span> <span class="pre">0.06)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">salt_vs_pepper</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.4,</span> <span class="pre">0.6)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomSaltAndPepperNoise" title="Link to this definition">¶</a></dt>
<dd><p>Apply random Salt and Pepper noise to input images.</p>
<img alt="_images/RandomSaltAndPepperNoise.png" src="_images/RandomSaltAndPepperNoise.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>amount</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – A float or a tuple representing the range for the amount of noise to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.01,</span> <span class="pre">0.06)</span></code></p></li>
<li><p><strong>salt_vs_pepper</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – A float or a tuple representing the range for the ratio of Salt to Pepper noise.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.4,</span> <span class="pre">0.6)</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – The probability of applying the transformation. Default is 0.5.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – If True, apply the same transformation across the entire batch. Default is False.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <cite>amount</cite> parameter controls the intensity of the noise, while <cite>salt_vs_pepper</cite> controls the ratio
of Salt to Pepper noise.</p>
<p>The values for <cite>amount</cite> and <cite>salt_vs_pepper</cite> should be between 0 and 1. The recommended value for
<cite>salt_vs_pepper</cite> is 0.5, and for <cite>amount</cite>, values less than 0.2 are recommended.</p>
<p>If <cite>amount</cite> and <cite>salt_vs_pepper</cite> are floats (unique values), the transformation is applied with these
exact values, rather than randomly sampling from the specified range. However, the masks are still
generated randomly using these exact parameters.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomSaltAndPepperNoise</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">salt_vs_pepper</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[1.0000, 0.0000, 0.0000],</span>
<span class="go">          [1.0000, 1.0000, 0.1166],</span>
<span class="go">          [0.1644, 0.7379, 0.0000]],</span>

<span class="go">         [[1.0000, 0.0000, 0.0000],</span>
<span class="go">          [1.0000, 1.0000, 0.7150],</span>
<span class="go">          [0.5793, 0.9809, 0.0000]],</span>

<span class="go">         [[1.0000, 0.0000, 0.0000],</span>
<span class="go">          [1.0000, 1.0000, 0.7850],</span>
<span class="go">          [0.9752, 0.0903, 0.0000]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomSaltAndPepperNoise</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">salt_vs_pepper</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomSaturation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomSaturation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">saturation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomSaturation" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random transformation to the saturation of a tensor image.</p>
<p>This implementation aligns PIL. Hence, the output is close to TorchVision.</p>
<img alt="_images/RandomSaturation.png" src="_images/RandomSaturation.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>saturation</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – the saturation factor to apply.
Default:  <code class="code docutils literal notranslate"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.adjust_saturation" title="kornia.enhance.adjust_saturation"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.adjust_saturation()</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomSaturation</span><span class="p">(</span><span class="n">saturation</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">2.</span><span class="p">),</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[0.5569, 0.7682, 0.3529],</span>
<span class="go">          [0.4811, 0.3474, 0.7411],</span>
<span class="go">          [0.5028, 0.8964, 0.6772]],</span>

<span class="go">         [[0.6323, 0.5358, 0.5265],</span>
<span class="go">          [0.4203, 0.2706, 0.5525],</span>
<span class="go">          [0.5185, 0.7863, 0.8681]],</span>

<span class="go">         [[0.3711, 0.4989, 0.6816],</span>
<span class="go">          [0.9152, 0.3971, 0.8742],</span>
<span class="go">          [0.4636, 0.7060, 0.9527]]]])</span>
</pre></div>
</div>
<p>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomSaturation</span><span class="p">((</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">1.2</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomSharpness">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomSharpness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sharpness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomSharpness" title="Link to this definition">¶</a></dt>
<dd><p>Sharpen given tensor image or a batch of tensor images randomly.</p>
<img alt="_images/RandomSharpness.png" src="_images/RandomSharpness.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>sharpness</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – factor of sharpness strength. Must be above 0.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.sharpness" title="kornia.enhance.sharpness"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.sharpness()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sharpness</span> <span class="o">=</span> <span class="n">RandomSharpness</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sharpness</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],</span>
<span class="go">          [0.6341, 0.4810, 0.7367, 0.4177, 0.6323],</span>
<span class="go">          [0.3489, 0.4428, 0.1562, 0.2443, 0.2939],</span>
<span class="go">          [0.5185, 0.6462, 0.7050, 0.2288, 0.2823],</span>
<span class="go">          [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomSharpness</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomSnow">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomSnow</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">snow_coefficient</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.5,</span> <span class="pre">0.5)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">brightness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(2,</span> <span class="pre">2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomSnow" title="Link to this definition">¶</a></dt>
<dd><p>Generates snow effect on given tensor image or a batch tensor images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>snow_coefficient</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – A tuple of floats (lower and upper bound) between 0 and 1 that control
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.5,</span> <span class="pre">0.5)</span></code></p></li>
<li><p><strong>image</strong> (<em>the amount</em><em> of </em><em>snow to add to the</em>)</p></li>
<li><p><strong>snow.</strong> (<em>brightness</em><em> of </em><em>the</em>)</p></li>
<li><p><strong>brightness</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – A tuple of floats (lower and upper bound) greater than 1 that controls the
Default:  <code class="code docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">2)</span></code></p></li>
<li><p><strong>snow.</strong></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – If True, apply the same transformation to each image in a batch. Default: False.</p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – Probability of applying the transformation. Default: 0.5.</p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Keep the output tensor with the same shape as input. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">snow</span> <span class="o">=</span> <span class="n">kornia</span><span class="o">.</span><span class="n">augmentation</span><span class="o">.</span><span class="n">RandomSnow</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">snow_coefficient</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">),</span> <span class="n">brightness</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">snow</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([2, 3, 4, 4])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomSolarize">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomSolarize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomSolarize" title="Link to this definition">¶</a></dt>
<dd><p>Solarize given tensor image or a batch of tensor images randomly.</p>
<img alt="_images/RandomSolarize.png" src="_images/RandomSolarize.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>thresholds</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – If float x, threshold will be generated from (0.5 - x, 0.5 + x).
If tuple (x, y), threshold will be generated from (x, y).
Default:  <code class="code docutils literal notranslate"><span class="pre">0.1</span></code></p></li>
<li><p><strong>additions</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – If float x, addition will be generated from (-x, x).
If tuple (x, y), addition will be generated from (x, y).
Default:  <code class="code docutils literal notranslate"><span class="pre">0.1</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.solarize" title="kornia.enhance.solarize"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.solarize()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">solarize</span> <span class="o">=</span> <span class="n">RandomSolarize</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">solarize</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0.4132, 0.1412, 0.1790, 0.2226, 0.3980],</span>
<span class="go">          [0.2754, 0.4194, 0.0130, 0.4538, 0.2771],</span>
<span class="go">          [0.4394, 0.4923, 0.1129, 0.2594, 0.3844],</span>
<span class="go">          [0.3909, 0.2118, 0.1094, 0.2516, 0.3728],</span>
<span class="go">          [0.2278, 0.0000, 0.4876, 0.0353, 0.5100]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomSolarize</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</section>
<section id="geometric">
<h3>Geometric<a class="headerlink" href="#geometric" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.CenterCrop">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">CenterCrop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cropping_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'slice'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.CenterCrop" title="Link to this definition">¶</a></dt>
<dd><p>Crop a given image tensor at the center.</p>
<img alt="_images/CenterCrop.png" src="_images/CenterCrop.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]]</span>) – Desired output size (out_h, out_w) of the crop.
If integer,  out_h = out_w = size.
If Tuple[int, int], out_h = size[0], out_w = size[1].</p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – The interpolation mode.
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation for the whole batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>cropping_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – The used algorithm to crop. <code class="docutils literal notranslate"><span class="pre">slice</span></code> will use advanced slicing to extract the tensor based
on the sampled indices. <code class="docutils literal notranslate"><span class="pre">resample</span></code> will use <cite>warp_affine</cite> using the affine transformation
to extract and resize at once. Use <cite>slice</cite> for efficiency, or <cite>resample</cite> for proper
differentiability.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;slice&quot;</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, out_h, out_w)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="geometry.transform.html#kornia.geometry.transform.crop_by_boxes" title="kornia.geometry.transform.crop_by_boxes"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.geometry.transform.crop_by_boxes()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span>
<span class="go">tensor([[[[-1.1258, -1.1524, -0.2506, -0.4339],</span>
<span class="go">          [ 0.8487,  0.6920, -0.3160, -2.1152],</span>
<span class="go">          [ 0.3223, -1.2633,  0.3500,  0.3081],</span>
<span class="go">          [ 0.1198,  1.2377,  1.1168, -0.2473]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">CenterCrop</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cropping_mode</span><span class="o">=</span><span class="s2">&quot;resample&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[[[ 0.6920, -0.3160],</span>
<span class="go">          [-1.2633,  0.3500]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s2">&quot;border&quot;</span><span class="p">)</span>
<span class="go">tensor([[[[ 0.6920,  0.6920, -0.3160, -0.3160],</span>
<span class="go">          [ 0.6920,  0.6920, -0.3160, -0.3160],</span>
<span class="go">          [-1.2633, -1.2633,  0.3500,  0.3500],</span>
<span class="go">          [-1.2633, -1.2633,  0.3500,  0.3500]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">CenterCrop</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cropping_mode</span><span class="o">=</span><span class="s2">&quot;resample&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.PadTo">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">PadTo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'constant'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.PadTo" title="Link to this definition">¶</a></dt>
<dd><p>Pad the given sample to a specific size. Always occurs (p=1.0).</p>
<img alt="_images/PadTo.png" src="_images/PadTo.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – a tuple of ints in the format (height, width) that give the spatial
dimensions to pad inputs to.</p></li>
<li><p><strong>pad_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – the type of padding to perform on the image (valid values
are those accepted by torch.nn.functional.pad)
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;constant&quot;</span></code></p></li>
<li><p><strong>pad_value</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – fill value for ‘constant’ padding applied to the image
Default:  <code class="code docutils literal notranslate"><span class="pre">0</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad" title="(in PyTorch v2.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.pad()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                      <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                      <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pad</span> <span class="o">=</span> <span class="n">PadTo</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">pad_value</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[[[0., 0., 0., 1., 1.],</span>
<span class="go">          [0., 0., 0., 1., 1.],</span>
<span class="go">          [0., 0., 0., 1., 1.],</span>
<span class="go">          [1., 1., 1., 1., 1.]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pad</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">tensor([[[[0., 0., 0.],</span>
<span class="go">          [0., 0., 0.],</span>
<span class="go">          [0., 0., 0.]]]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomAffine">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomAffine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">degrees</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">translate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shear</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">SamplePadding.ZEROS.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomAffine" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random 2D affine transformation to a tensor image.</p>
<img alt="_images/RandomAffine.png" src="_images/RandomAffine.png" />
<p>The transformation is computed so that the image center is kept invariant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>degrees</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>) – Range of degrees to select from.
If degrees is a number instead of sequence like (min, max), the range of degrees
will be (-degrees, +degrees). Set to 0 to deactivate rotations.</p></li>
<li><p><strong>translate</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – tuple of maximum absolute fraction for horizontal
and vertical translations. For example translate=(a, b), then horizontal shift
is randomly sampled in the range -img_width * a &lt; dx &lt; img_width * a and vertical shift is
randomly sampled in the range -img_height * b &lt; dy &lt; img_height * b. Will not translate by default.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>scale</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – scaling factor interval.
If (a, b) represents isotropic scaling, the scale is randomly sampled from the range a &lt;= scale &lt;= b.
If (a, b, c, d), the scale is randomly sampled from the range a &lt;= scale_x &lt;= b, c &lt;= scale_y &lt;= d.
Will keep original scale by default.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>shear</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – Range of degrees to select from.
If float, a shear parallel to the x axis in the range (-shear, +shear) will be applied.
If (a, b), a shear parallel to the x axis in the range (-shear, +shear) will be applied.
If (a, b, c, d), then x-axis shear in (shear[0], shear[1]) and y-axis shear in (shear[2], shear[3])
will be applied. Will not apply shear by default.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – resample mode from “nearest” (0) or “bilinear” (1).
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>padding_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">SamplePadding</span></code>]</span>, <em>optional</em>) – padding mode from “zeros” (0), “border” (1) or “reflection” (2).
Default:  <code class="code docutils literal notranslate"><span class="pre">SamplePadding.ZEROS.name</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="geometry.transform.html#kornia.geometry.transform.warp_affine" title="kornia.geometry.transform.warp_affine"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.geometry.transform.warp_affine()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomAffine</span><span class="p">((</span><span class="o">-</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="p">,</span> <span class="n">aug</span><span class="o">.</span><span class="n">transform_matrix</span>
<span class="go">(tensor([[[[0.3961, 0.7310, 0.1574],</span>
<span class="go">          [0.1781, 0.3074, 0.5648],</span>
<span class="go">          [0.4804, 0.8379, 0.4234]]]]), tensor([[[ 0.9923, -0.1241,  0.1319],</span>
<span class="go">         [ 0.1241,  0.9923, -0.1164],</span>
<span class="go">         [ 0.0000,  0.0000,  1.0000]]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">tensor([[[[0.3890, 0.6573, 0.1865],</span>
<span class="go">          [0.2063, 0.3074, 0.5459],</span>
<span class="go">          [0.3892, 0.7896, 0.4224]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[[0.4963, 0.7682, 0.0885],</span>
<span class="go">          [0.1320, 0.3074, 0.6341],</span>
<span class="go">          [0.4901, 0.8964, 0.4556]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomAffine</span><span class="p">((</span><span class="o">-</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomCrop">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomCrop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_if_needed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'constant'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cropping_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'slice'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomCrop" title="Link to this definition">¶</a></dt>
<dd><p>Crop random patches of a tensor image on a given size.</p>
<img alt="_images/RandomCrop.png" src="_images/RandomCrop.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – Desired output size (out_h, out_w) of the crop.
Must be Tuple[int, int], then out_h = size[0], out_w = size[1].</p></li>
<li><p><strong>padding</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – Optional padding on each border
of the image. Default is None, i.e no padding. If a sequence of length
4 is provided, it is used to pad left, top, right, bottom borders
respectively. If a sequence of length 2 is provided, it is used to
pad left/right, top/bottom borders, respectively.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>pad_if_needed</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]</span>, <em>optional</em>) – It will pad the image if smaller than the
desired size to avoid raising an exception. Since cropping is done
after padding, the padding seems to be done at a random offset.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>fill</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Pixel fill value for constant fill. Default is 0. If a tuple of
length 3, it is used to fill R, G, B channels respectively.
This value is only used when the padding_mode is constant.
Default:  <code class="code docutils literal notranslate"><span class="pre">0</span></code></p></li>
<li><p><strong>padding_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – Type of padding. Should be: constant, reflect, replicate.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;constant&quot;</span></code></p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – the interpolation mode.
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation for the whole batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>cropping_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – The used algorithm to crop. <code class="docutils literal notranslate"><span class="pre">slice</span></code> will use advanced slicing to extract the tensor based
on the sampled indices. <code class="docutils literal notranslate"><span class="pre">resample</span></code> will use <cite>warp_affine</cite> using the affine transformation
to extract and resize at once. Use <cite>slice</cite> for efficiency, or <cite>resample</cite> for proper
differentiability.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;slice&quot;</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, out_h, out_w)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 3, 3)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="o">*</span><span class="mi">1</span><span class="o">*</span><span class="mi">3</span><span class="o">*</span><span class="mf">3.</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomCrop</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cropping_mode</span><span class="o">=</span><span class="s2">&quot;resample&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[[[3., 4.],</span>
<span class="go">          [6., 7.]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s2">&quot;replicate&quot;</span><span class="p">)</span>
<span class="go">tensor([[[[3., 4., 4.],</span>
<span class="go">          [3., 4., 4.],</span>
<span class="go">          [6., 7., 7.]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomCrop</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cropping_mode</span><span class="o">=</span><span class="s2">&quot;resample&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomElasticTransform">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomElasticTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(63,</span> <span class="pre">63)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(32.0,</span> <span class="pre">32.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'zeros'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomElasticTransform" title="Link to this definition">¶</a></dt>
<dd><p>Add random elastic transformation to a tensor image.</p>
<img alt="_images/RandomElasticTransform.png" src="_images/RandomElasticTransform.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – the size of the Gaussian kernel.
Default:  <code class="code docutils literal notranslate"><span class="pre">(63,</span> <span class="pre">63)</span></code></p></li>
<li><p><strong>sigma</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – The standard deviation of the Gaussian in the y and x directions,
respectively. Larger sigma results in smaller pixel displacements.
Default:  <code class="code docutils literal notranslate"><span class="pre">(32.0,</span> <span class="pre">32.0)</span></code></p></li>
<li><p><strong>alpha</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – The scaling factor that controls the intensity of the deformation
in the y and x directions, respectively.
Default:  <code class="code docutils literal notranslate"><span class="pre">(1.0,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Interpolation flag used by <cite>grid_sample</cite>.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – Interpolation mode used by <cite>grid_sample</cite>. Either ‘nearest’ (0) or ‘bilinear’ (1).
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>padding_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – The padding used by <code class="docutils literal notranslate"><span class="pre">`grid_sample`</span></code>. Either ‘zeros’, ‘border’ or ‘refection’.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;zeros&quot;</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="geometry.transform.html#kornia.geometry.transform.elastic_transform2d" title="kornia.geometry.transform.elastic_transform2d"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.geometry.transform.elastic_transform2d()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">RandomElasticTransform</span><span class="p">()(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 1, 2, 2])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomElasticTransform</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomErasing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomErasing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.02,</span> <span class="pre">0.33)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.3,</span> <span class="pre">3.3)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomErasing" title="Link to this definition">¶</a></dt>
<dd><p>Erase a random rectangle of a tensor image according to a probability p value.</p>
<img alt="_images/RandomErasing.png" src="_images/RandomErasing.png" />
<p>The operator removes image parts and fills them with zero values at a selected rectangle
for each of the images in the batch.</p>
<p>The rectangle will have an area equal to the original image area multiplied by a value uniformly
sampled between the range [scale[0], scale[1]) and an aspect ratio sampled
between [ratio[0], ratio[1])</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scale</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – range of proportion of erased area against input image.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.02,</span> <span class="pre">0.33)</span></code></p></li>
<li><p><strong>ratio</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – range of aspect ratio of erased area.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.3,</span> <span class="pre">3.3)</span></code></p></li>
<li><p><strong>value</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – the value to fill the erased area.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability that the random erasing operation will be performed.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 3, 3)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomErasing</span><span class="p">((</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.8</span><span class="p">),</span> <span class="p">(</span><span class="mf">.3</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mf">.3</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[1., 0., 0.],</span>
<span class="go">          [1., 0., 0.],</span>
<span class="go">          [1., 0., 0.]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomErasing</span><span class="p">((</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.8</span><span class="p">),</span> <span class="p">(</span><span class="mf">.3</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mf">.3</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomFisheye">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomFisheye</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">center_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">center_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomFisheye" title="Link to this definition">¶</a></dt>
<dd><p>Add random camera radial distortion.</p>
<img alt="_images/RandomFisheye.png" src="_images/RandomFisheye.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>center_x</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Ranges to sample respect to x-coordinate center with shape (2,).</p></li>
<li><p><strong>center_y</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Ranges to sample respect to y-coordinate center with shape (2,).</p></li>
<li><p><strong>gamma</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Ranges to sample for the gamma values respect to optical center with shape (2,).</p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">center_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">center_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gamma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">.9</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">RandomFisheye</span><span class="p">(</span><span class="n">center_x</span><span class="p">,</span> <span class="n">center_y</span><span class="p">,</span> <span class="n">gamma</span><span class="p">)(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 1, 2, 2])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomFisheye</span><span class="p">(</span><span class="n">center_x</span><span class="p">,</span> <span class="n">center_y</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomHorizontalFlip">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomHorizontalFlip</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomHorizontalFlip" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random horizontal flip to a tensor image or a batch of tensor images with a given probability.</p>
<img alt="_images/RandomHorizontalFlip.png" src="_images/RandomHorizontalFlip.png" />
<p>Input should be a tensor of shape (C, H, W) or a batch of tensors <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.
If Input is a tuple it is assumed that the first element contains the aforementioned tensors and the second,
the corresponding transformation matrix that has been applied to them. In this case the module
will Horizontally flip the tensors and concatenate the corresponding transformation matrix to the
previous one. This is especially useful when using this functionality as part of an <code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code> module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of the image being flipped.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="geometry.transform.html#kornia.geometry.transform.hflip" title="kornia.geometry.transform.hflip"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.geometry.transform.hflip()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span> <span class="o">=</span> <span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">seq</span><span class="o">.</span><span class="n">transform_matrix</span>
<span class="go">(tensor([[[[0., 0., 0.],</span>
<span class="go">          [0., 0., 0.],</span>
<span class="go">          [1., 1., 0.]]]]), tensor([[[-1.,  0.,  2.],</span>
<span class="go">         [ 0.,  1.,  0.],</span>
<span class="go">         [ 0.,  0.,  1.]]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span> <span class="o">=</span> <span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">seq</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">seq</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomPerspective">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomPerspective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">distortion_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'basic'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomPerspective" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random perspective transformation to an image tensor with a given probability.</p>
<img alt="_images/RandomPerspective.png" src="_images/RandomPerspective.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>distortion_scale</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – the degree of distortion, ranged from 0 to 1.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – the interpolation method to use.
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch. Default: False.</p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of the image being perspectively transformed.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>sampling_method</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – <code class="docutils literal notranslate"><span class="pre">'basic'</span></code> | <code class="docutils literal notranslate"><span class="pre">'area_preserving'</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'basic'</span></code>
If <code class="docutils literal notranslate"><span class="pre">'basic'</span></code>, samples by translating the image corners randomly inwards.
If <code class="docutils literal notranslate"><span class="pre">'area_preserving'</span></code>, samples by randomly translating the image corners in any direction.
Preserves area on average. See <a class="reference external" href="https://arxiv.org/abs/2104.03308">https://arxiv.org/abs/2104.03308</a> for further details.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.geometry.transform.warp_pespective()</span></code>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomPerspective</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[[[0.0000, 0.2289, 0.0000],</span>
<span class="go">          [0.0000, 0.4800, 0.0000],</span>
<span class="go">          [0.0000, 0.0000, 0.0000]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">tensor([[[[0.0500, 0.0961, 0.0000],</span>
<span class="go">          [0.2011, 0.3144, 0.0000],</span>
<span class="go">          [0.0031, 0.0130, 0.0053]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomPerspective</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomResizedCrop">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomResizedCrop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.08,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(3.0</span> <span class="pre">/</span> <span class="pre">4.0,</span> <span class="pre">4.0</span> <span class="pre">/</span> <span class="pre">3.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cropping_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'slice'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomResizedCrop" title="Link to this definition">¶</a></dt>
<dd><p>Crop random patches in an image tensor and resizes to a given size.</p>
<img alt="_images/RandomResizedCrop.png" src="_images/RandomResizedCrop.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – Desired output size (out_h, out_w) of each edge.
Must be Tuple[int, int], then out_h = size[0], out_w = size[1].</p></li>
<li><p><strong>scale</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – range of size of the origin size cropped.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.08,</span> <span class="pre">1.0)</span></code></p></li>
<li><p><strong>ratio</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>, <em>optional</em>) – range of aspect ratio of the origin aspect ratio cropped.
Default:  <code class="code docutils literal notranslate"><span class="pre">(3.0</span> <span class="pre">/</span> <span class="pre">4.0,</span> <span class="pre">4.0</span> <span class="pre">/</span> <span class="pre">3.0)</span></code></p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – the interpolation mode.
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of the augmentation been applied.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>cropping_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – The used algorithm to crop. <code class="docutils literal notranslate"><span class="pre">slice</span></code> will use advanced slicing to extract the tensor based
on the sampled indices. <code class="docutils literal notranslate"><span class="pre">resample</span></code> will use <cite>warp_affine</cite> using the affine transformation
to extract and resize at once. Use <cite>slice</cite> for efficiency, or <cite>resample</cite> for proper
differentiability.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;slice&quot;</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, out_h, out_w)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 3, 3)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>                        <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
<span class="gp">... </span>                        <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cropping_mode</span><span class="o">=</span><span class="s2">&quot;resample&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[[[1.0000, 1.5000, 2.0000],</span>
<span class="go">          [4.0000, 4.5000, 5.0000],</span>
<span class="go">          [7.0000, 7.5000, 8.0000]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s2">&quot;border&quot;</span><span class="p">)</span>
<span class="go">tensor([[[[1., 1., 2.],</span>
<span class="go">          [4., 4., 5.],</span>
<span class="go">          [7., 7., 8.]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cropping_mode</span><span class="o">=</span><span class="s2">&quot;resample&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomRotation90">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomRotation90</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">times</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomRotation90" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random 90 * n degree rotation to a tensor image or a batch of tensor images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>times</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – the range of n times 90 degree rotation needs to be applied.</p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – Default: the interpolation mode.</p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="geometry.transform.html#kornia.geometry.transform.affine" title="kornia.geometry.transform.affine"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.geometry.transform.affine()</span></code></a>. This version is relatively
slow as it operates based on affine transformations.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">sci_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>                      <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                      <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                      <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomRotation90</span><span class="p">(</span><span class="n">times</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[[[    2.0000,     0.0000,     0.0000,     2.0000],</span>
<span class="go">          [    0.0000,     0.0000,     2.0000,     1.0000],</span>
<span class="go">          [    0.0000,     0.0000,     1.0000,     0.0000],</span>
<span class="go">          [    1.0000,     0.0000,     0.0000,     0.0000]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="o">.</span><span class="n">transform_matrix</span>
<span class="go">tensor([[[    -0.0000,      1.0000,      0.0000],</span>
<span class="go">         [    -1.0000,     -0.0000,      3.0000],</span>
<span class="go">         [     0.0000,      0.0000,      1.0000]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inv</span> <span class="o">=</span> <span class="n">aug</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">profile</span><span class="o">=</span><span class="s1">&#39;default&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomRotation90</span><span class="p">(</span><span class="n">times</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomRotation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomRotation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">degrees</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomRotation" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random rotation to a tensor image or a batch of tensor images given an amount of degrees.</p>
<img alt="_images/RandomRotation.png" src="_images/RandomRotation.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>degrees</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>) – range of degrees to select from. If degrees is a number the
range of degrees to select from will be (-degrees, +degrees).</p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – Default: the interpolation mode.</p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="geometry.transform.html#kornia.geometry.transform.affine" title="kornia.geometry.transform.affine"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.geometry.transform.affine()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>                      <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                      <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                      <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomRotation</span><span class="p">(</span><span class="n">degrees</span><span class="o">=</span><span class="mf">45.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[[[0.9824, 0.0088, 0.0000, 1.9649],</span>
<span class="go">          [0.0000, 0.0029, 0.0000, 0.0176],</span>
<span class="go">          [0.0029, 1.0000, 1.9883, 0.0000],</span>
<span class="go">          [0.0000, 0.0088, 1.0117, 1.9649]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="o">.</span><span class="n">transform_matrix</span>
<span class="go">tensor([[[ 1.0000, -0.0059,  0.0088],</span>
<span class="go">         [ 0.0059,  1.0000, -0.0088],</span>
<span class="go">         [ 0.0000,  0.0000,  1.0000]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inv</span> <span class="o">=</span> <span class="n">aug</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomRotation</span><span class="p">(</span><span class="n">degrees</span><span class="o">=</span><span class="mf">45.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomShear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomShear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shear</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">SamplePadding.ZEROS.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomShear" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random 2D shear transformation to a tensor image.</p>
<p>The transformation is computed so that the image center is kept invariant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shear</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>) – Range of degrees to select from.
If float, a shear parallel to the x axis in the range (-shear, +shear) will be applied.
If (a, b), a shear parallel to the x axis in the range (-shear, +shear) will be applied.
If (a, b, c, d), then x-axis shear in (shear[0], shear[1]) and y-axis shear in (shear[2], shear[3])
will be applied. Will not apply shear by default.</p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – resample mode from “nearest” (0) or “bilinear” (1).
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>padding_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">SamplePadding</span></code>]</span>, <em>optional</em>) – padding mode from “zeros” (0), “border” (1) or “reflection” (2).
Default:  <code class="code docutils literal notranslate"><span class="pre">SamplePadding.ZEROS.name</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="geometry.transform.html#kornia.geometry.transform.warp_affine" title="kornia.geometry.transform.warp_affine"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.geometry.transform.warp_affine()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomShear</span><span class="p">((</span><span class="o">-</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="p">,</span> <span class="n">aug</span><span class="o">.</span><span class="n">transform_matrix</span>
<span class="go">(tensor([[[[0.4403, 0.7614, 0.1516],</span>
<span class="go">          [0.1753, 0.3074, 0.6127],</span>
<span class="go">          [0.4438, 0.8924, 0.4061]]]]), tensor([[[ 1.0000,  0.0100, -0.0100],</span>
<span class="go">         [-0.1183,  0.9988,  0.1194],</span>
<span class="go">         [ 0.0000,  0.0000,  1.0000]]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">tensor([[[[0.4045, 0.7577, 0.1393],</span>
<span class="go">          [0.2071, 0.3074, 0.5582],</span>
<span class="go">          [0.3958, 0.8868, 0.4265]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomShear</span><span class="p">((</span><span class="o">-</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomThinPlateSpline">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomThinPlateSpline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">SamplePadding.ZEROS.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomThinPlateSpline" title="Link to this definition">¶</a></dt>
<dd><p>Add random noise to the Thin Plate Spline algorithm.</p>
<img alt="_images/RandomThinPlateSpline.png" src="_images/RandomThinPlateSpline.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scale</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – the scale factor to apply to the destination points.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.2</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Interpolation flag used by <code class="docutils literal notranslate"><span class="pre">grid_sample</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>mode</strong> – Interpolation mode used by <cite>grid_sample</cite>. Either ‘bilinear’ or ‘nearest’.</p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="geometry.transform.html#kornia.geometry.transform.warp_image_tps" title="kornia.geometry.transform.warp_image_tps"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.geometry.transform.warp_image_tps()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">RandomThinPlateSpline</span><span class="p">()(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 1, 2, 2])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomThinPlateSpline</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomVerticalFlip">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomVerticalFlip</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomVerticalFlip" title="Link to this definition">¶</a></dt>
<dd><p>Apply a random vertical flip to a tensor image or a batch of tensor images with a given probability.</p>
<img alt="_images/RandomVerticalFlip.png" src="_images/RandomVerticalFlip.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of the image being flipped.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 3, 3)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="geometry.transform.html#kornia.geometry.transform.vflip" title="kornia.geometry.transform.vflip"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.geometry.transform.vflip()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span> <span class="o">=</span> <span class="n">RandomVerticalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">seq</span><span class="o">.</span><span class="n">transform_matrix</span>
<span class="go">(tensor([[[[0., 1., 1.],</span>
<span class="go">          [0., 0., 0.],</span>
<span class="go">          [0., 0., 0.]]]]), tensor([[[ 1.,  0.,  0.],</span>
<span class="go">         [ 0., -1.,  2.],</span>
<span class="go">         [ 0.,  0.,  1.]]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span> <span class="o">=</span> <span class="n">RandomVerticalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">seq</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">seq</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</section>
<section id="mix">
<h3>Mix<a class="headerlink" href="#mix" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomCutMixV2">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomCutMixV2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_mix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cut_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_keys</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomCutMixV2" title="Link to this definition">¶</a></dt>
<dd><p>Apply CutMix augmentation to a batch of tensor images.</p>
<img alt="_images/RandomCutMixV2.png" src="_images/RandomCutMixV2.png" />
<p>Implementation for <cite>CutMix: Regularization Strategy to Train Strong Classifiers with
Localizable Features</cite> <span id="id6">[<a class="reference internal" href="community/bibliography.html#id15" title="Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo. Cutmix: regularization strategy to train strong classifiers with localizable features. In International Conference on Computer Vision (ICCV). 2019.">YHO+19</a>]</span>.</p>
<p>The function returns (inputs, labels), in which the inputs is the tensor that contains the mixup images
while the labels is a <span class="math notranslate nohighlight">\((\text{num_mixes}, B, 3)\)</span> tensor that contains (label_permuted_batch, lambda)
for each cutmix.</p>
<p>The implementation referred to the following repository: <a class="reference external" href="https://github.com/clovaai/CutMix-PyTorch">https://github.com/clovaai/CutMix-PyTorch</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>height</strong> – the width of the input image.</p></li>
<li><p><strong>width</strong> – the width of the input image.</p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability for applying an augmentation to a batch. This param controls the augmentation
probabilities batch-wisely.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>num_mix</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – cut mix times.
Default:  <code class="code docutils literal notranslate"><span class="pre">1</span></code></p></li>
<li><p><strong>beta</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – hyperparameter for generating cut size from beta distribution.
Beta cannot be set to 0 after torch 1.8.0. If None, it will be set to 1.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>cut_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – controlling the minimum and maximum cut ratio from [0, 1].
If None, it will be set to [0, 1], which means no restriction.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
This flag will not maintain permutation order.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p>Input image tensors, shape of <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p></li>
<li><p>Raw labels, shape of <span class="math notranslate nohighlight">\((B)\)</span>.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Adjusted image, shape of <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p></li>
<li><p>Raw labels, permuted labels and lambdas for each mix, shape of <span class="math notranslate nohighlight">\((B, num_mix, 3)\)</span>.</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple[Tensor, Tensor]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This implementation would randomly cutmix images in a batch. Ideally, the larger batch size would be preferred.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cutmix</span> <span class="o">=</span> <span class="n">RandomCutMixV2</span><span class="p">(</span><span class="n">data_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cutmix</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<span class="go">[tensor([[[[0.8879, 0.4510, 1.0000],</span>
<span class="go">          [0.1498, 0.4015, 1.0000],</span>
<span class="go">          [1.0000, 1.0000, 1.0000]]],</span>


<span class="go">        [[[1.0000, 1.0000, 0.7995],</span>
<span class="go">          [1.0000, 1.0000, 0.0542],</span>
<span class="go">          [0.4594, 0.1756, 0.9492]]]]), tensor([[[0.0000, 1.0000, 0.4444],</span>
<span class="go">         [1.0000, 0.0000, 0.4444]]])]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomJigsaw">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomJigsaw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(4,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_keys</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ensure_perm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomJigsaw" title="Link to this definition">¶</a></dt>
<dd><p>RandomJigsaw augmentation.</p>
<img alt="_images/RandomJigsaw.png" src="_images/RandomJigsaw.png" />
<p>Make Jigsaw puzzles for each image individually. To mix with different images in a
batch, referring to <code class="xref py py-class docutils literal notranslate"><span class="pre">kornia.augmentation.RandomMosic</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>grid</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – the Jigsaw puzzle grid. e.g. (2, 2) means
each output will mix image patches in a 2x2 grid.
Default:  <code class="code docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">4)</span></code></p></li>
<li><p><strong>ensure_perm</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – to ensure the nonidentical patch permutation generation against
the original one.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>data_keys</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">DataKey</span></code>]]]</span>, <em>optional</em>) – the input type sequential for applying augmentations.
Accepts “input”, “image”, “mask”, “bbox”, “bbox_xyxy”, “bbox_xywh”, “keypoints”,
“class”, “label”.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation for the whole batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input <code class="docutils literal notranslate"><span class="pre">True</span></code> or broadcast it
to the batch form <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">jigsaw</span> <span class="o">=</span> <span class="n">RandomJigsaw</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">jigsaw</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([8, 3, 256, 256])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomMixUpV2">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomMixUpV2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lambda_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_keys</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomMixUpV2" title="Link to this definition">¶</a></dt>
<dd><p>Apply MixUp augmentation to a batch of tensor images.</p>
<img alt="_images/RandomMixUpV2.png" src="_images/RandomMixUpV2.png" />
<p>Implementation for <cite>mixup: BEYOND EMPIRICAL RISK MINIMIZATION</cite> <span id="id7">[<a class="reference internal" href="community/bibliography.html#id13" title="Hongyi Zhang, Moustapha Cisse nad Yann N. Dauphin, and David Lopez-Paz. Mixup: beyond empirical risk minimization. International Conference on Learning Representations, 2018. URL: https://openreview.net/forum?id=r1Ddp1-Rb.">ZnYNDLP18</a>]</span>.</p>
<p>The function returns (inputs, labels), in which the inputs is the tensor that contains the mixup images
while the labels is a <span class="math notranslate nohighlight">\((B, 3)\)</span> tensor that contains (label_batch, label_permuted_batch, lambda) for
each image.</p>
<p>The implementation is on top of the following repository:
<a class="reference external" href="https://github.com/hongyi-zhang/mixup/blob/master/cifar/utils.py">https://github.com/hongyi-zhang/mixup/blob/master/cifar/utils.py</a>.</p>
<p>The loss and accuracy are computed as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">loss_mixup</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span>
    <span class="n">loss_a</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">loss_b</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="n">loss_a</span> <span class="o">+</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">loss_b</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">acc_mixup</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">+</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability for applying an augmentation to a batch. This param controls the augmentation
probabilities batch-wisely.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>lambda_val</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – min-max value of mixup strength. Default is 0-1.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
This flag will not maintain permutation order.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p>Input image tensors, shape of <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p></li>
<li><p>Label: raw labels, shape of <span class="math notranslate nohighlight">\((B)\)</span>.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Adjusted image, shape of <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p></li>
<li><p>Raw labels, permuted labels and lambdas for each mix, shape of <span class="math notranslate nohighlight">\((B, 3)\)</span>.</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple[Tensor, Tensor]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This implementation would randomly mixup images in a batch. Ideally, the larger batch size would be preferred.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mixup</span> <span class="o">=</span> <span class="n">RandomMixUpV2</span><span class="p">(</span><span class="n">data_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mixup</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<span class="go">[tensor([[[[0.7576, 0.2793, 0.4031],</span>
<span class="go">          [0.7347, 0.0293, 0.7999],</span>
<span class="go">          [0.3971, 0.7544, 0.5695]]],</span>


<span class="go">        [[[0.4388, 0.6387, 0.5247],</span>
<span class="go">          [0.6826, 0.3051, 0.4635],</span>
<span class="go">          [0.4550, 0.5725, 0.4980]]]]), tensor([[0.0000, 0.0000, 0.1980],</span>
<span class="go">        [1.0000, 1.0000, 0.4162]])]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomMosaic">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomMosaic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mosaic_grid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(2,</span> <span class="pre">2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_ratio_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.3,</span> <span class="pre">0.7)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_bbox_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_keys</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'constant'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cropping_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'slice'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomMosaic" title="Link to this definition">¶</a></dt>
<dd><p>Mosaic augmentation.</p>
<img alt="https://raw.githubusercontent.com/kornia/data/main/random_mosaic.png" src="https://raw.githubusercontent.com/kornia/data/main/random_mosaic.png" />
<p>Given a certain number of images, mosaic transform combines them into one output image.
The output image is composed of the parts from each sub-image. To mess up each image individually,
referring to <a class="reference internal" href="#kornia.augmentation.RandomJigsaw" title="kornia.augmentation.RandomJigsaw"><code class="xref py py-class docutils literal notranslate"><span class="pre">kornia.augmentation.RandomJigsaw</span></code></a>.</p>
<p>The mosaic transform steps are as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Concate selected images into a super-image.</p></li>
<li><p>Crop out the outcome image according to the top-left corner and crop size.</p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]]</span>, <em>optional</em>) – the output tensor width and height after mosaicing.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>start_ratio_range</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – top-left (x, y) position for cropping the mosaic images.
Default:  <code class="code docutils literal notranslate"><span class="pre">(0.3,</span> <span class="pre">0.7)</span></code></p></li>
<li><p><strong>mosaic_grid</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – the number of images and image arrangement. e.g. (2, 2) means
each output will mix 4 images in a 2x2 grid.
Default:  <code class="code docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">2)</span></code></p></li>
<li><p><strong>min_bbox_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – minimum area of bounding boxes. Default to 0.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>data_keys</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">DataKey</span></code>]]]</span>, <em>optional</em>) – the input type sequential for applying augmentations.
Accepts “input”, “image”, “mask”, “bbox”, “bbox_xyxy”, “bbox_xywh”, “keypoints”,
“class”, “label”.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation for the whole batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.7</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input <code class="docutils literal notranslate"><span class="pre">True</span></code> or broadcast it
to the batch form <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>padding_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – Type of padding. Should be: constant, reflect, replicate.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;constant&quot;</span></code></p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – the interpolation mode.
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>cropping_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – The used algorithm to crop. <code class="docutils literal notranslate"><span class="pre">slice</span></code> will use advanced slicing to extract the tensor based
on the sampled indices. <code class="docutils literal notranslate"><span class="pre">resample</span></code> will use <cite>warp_affine</cite> using the affine transformation
to extract and resize at once. Use <cite>slice</cite> for efficiency, or <cite>resample</cite> for proper
differentiability.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;slice&quot;</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mosaic</span> <span class="o">=</span> <span class="n">RandomMosaic</span><span class="p">((</span><span class="mi">300</span><span class="p">,</span> <span class="mi">300</span><span class="p">),</span> <span class="n">data_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;bbox_xyxy&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span>
<span class="gp">... </span>    <span class="p">[</span><span class="mi">70</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
<span class="gp">... </span>    <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">175</span><span class="p">,</span> <span class="mi">220</span><span class="p">],</span>
<span class="gp">... </span><span class="p">]])</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">mosaic</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">boxes</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(torch.Size([8, 3, 300, 300]), torch.Size([8, 8, 4]))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomTransplantation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomTransplantation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">excluded_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_keys</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomTransplantation" title="Link to this definition">¶</a></dt>
<dd><p>RandomTransplantation augmentation.</p>
<img alt="_images/RandomTransplantation.png" src="_images/RandomTransplantation.png" />
<p>Randomly transplant (copy and paste) image features and corresponding segmentation masks between images in a batch.
The transplantation transform works as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Based on the parameter <cite>p</cite>, a certain number of images in the batch are selected as acceptor of a
transplantation.</p></li>
<li><p>For each acceptor, the image below in the batch is selected as donor (via circling: <span class="math notranslate nohighlight">\(i - 1 \mod B\)</span>).</p></li>
<li><p>From the donor, a random label is selected and the corresponding image features and segmentation mask are
transplanted to the acceptor.</p></li>
</ol>
</div></blockquote>
<p>The augmentation is described in <cite>Semantic segmentation of surgical hyperspectral images under geometric domain
shifts</cite> <span id="id8">[<a class="reference internal" href="community/bibliography.html#id43" title="Jan Sellner, Silvia Seidlitz, Alexander Studier-Fischer, Alessandro Motta, Berkin Özdemir, Beat Peter Müller-Stich, Felix Nickel, and Lena Maier-Hein. Semantic segmentation of surgical hyperspectral images under geometric domain shifts. 2023. arXiv:2303.10972.">SSSF+23</a>]</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>excluded_labels</strong> (<span class="sphinx_autodoc_typehints-type">Optional[Union[Sequence[int], Tensor]]</span>, <em>optional</em>) – sequence of labels which should not be transplanted from a donor. This can be useful if only
parts of the image are annotated and the non-annotated regions (with a specific label index) should be
excluded from the augmentation. If no label is left in the donor image, nothing is transplanted.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type">float</span>, <em>optional</em>) – probability for applying an augmentation to an image. This parameter controls how many images in a batch
receive a transplant.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>p_batch</strong> (<span class="sphinx_autodoc_typehints-type">float</span>, <em>optional</em>) – probability for applying an augmentation to a batch. This param controls the augmentation
probabilities batch-wise.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>data_keys</strong> (<span class="sphinx_autodoc_typehints-type">Optional[list[str | int | DataKey]]</span>, <em>optional</em>) – the input type sequential for applying augmentations. There must be at least one “mask” tensor. If no
data keys are given, the first tensor is assumed to be <cite>DataKey.INPUT</cite> and the second tensor <cite>DataKey.MASK</cite>.
Accepts “input”, “mask”.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>This augmentation requires that segmentation masks are available for all images in the batch and that at
least some objects in the image are annotated.</p></li>
<li><p>When using this class directly (<cite>RandomTransplantation()(…)</cite>), it works for arbitrary spatial dimensions
including 2D and 3D images. When wrapping in <code class="xref py py-class docutils literal notranslate"><span class="pre">kornia.augmentation.AugmentationSequential</span></code>, use
<a class="reference internal" href="#kornia.augmentation.RandomTransplantation" title="kornia.augmentation.RandomTransplantation"><code class="xref py py-class docutils literal notranslate"><span class="pre">kornia.augmentation.RandomTransplantation</span></code></a> for 2D and
<a class="reference internal" href="#kornia.augmentation.RandomTransplantation3D" title="kornia.augmentation.RandomTransplantation3D"><code class="xref py py-class docutils literal notranslate"><span class="pre">kornia.augmentation.RandomTransplantation3D</span></code></a> for 3D images.</p></li>
</ul>
</div>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p>Segmentation mask tensor which is used to determine the objects for transplantation: <span class="math notranslate nohighlight">\((B, *)\)</span>.</p></li>
<li><p>(optional) Additional image or mask tensors where the features are transplanted based on the first
segmentation mask: <span class="math notranslate nohighlight">\((B, C, *)\)</span> (<cite>DataKey.INPUT</cite>) or <span class="math notranslate nohighlight">\((B, *)\)</span> (<cite>DataKey.MASK</cite>).</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Tensor:</dt><dd><ul class="simple">
<li><p>Augmented mask tensors: <span class="math notranslate nohighlight">\((B, *)\)</span>.</p></li>
</ul>
</dd>
<dt>list[Tensor]:</dt><dd><ul class="simple">
<li><p>Augmented mask tensors: <span class="math notranslate nohighlight">\((B, *)\)</span>.</p></li>
<li><p>Additional augmented image or mask tensors: <span class="math notranslate nohighlight">\((B, C, *)\)</span> (<cite>DataKey.INPUT</cite>) or <span class="math notranslate nohighlight">\((B, *)\)</span>
(<cite>DataKey.MASK</cite>).</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor | <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>[Tensor]</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomTransplantation</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span>
<span class="go">tensor([[[0, 0, 1, 1, 0],</span>
<span class="go">         [1, 2, 0, 0, 0],</span>
<span class="go">         [1, 2, 1, 1, 0],</span>
<span class="go">         [0, 0, 0, 0, 2],</span>
<span class="go">         [2, 2, 2, 0, 2]],</span>

<span class="go">        [[2, 0, 0, 2, 1],</span>
<span class="go">         [2, 1, 0, 2, 1],</span>
<span class="go">         [2, 0, 1, 0, 2],</span>
<span class="go">         [2, 2, 2, 0, 2],</span>
<span class="go">         [2, 1, 0, 0, 0]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_out</span><span class="p">,</span> <span class="n">mask_out</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_out</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([2, 3, 5, 5])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask_out</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([2, 5, 5])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask_out</span>
<span class="go">tensor([[[2, 0, 1, 2, 0],</span>
<span class="go">         [2, 2, 0, 2, 0],</span>
<span class="go">         [2, 2, 1, 1, 2],</span>
<span class="go">         [2, 2, 2, 0, 2],</span>
<span class="go">         [2, 2, 2, 0, 2]],</span>

<span class="go">        [[0, 0, 0, 2, 0],</span>
<span class="go">         [2, 1, 0, 0, 0],</span>
<span class="go">         [2, 0, 1, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 2],</span>
<span class="go">         [2, 1, 0, 0, 0]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">[</span><span class="s2">&quot;selected_labels&quot;</span><span class="p">]</span>  <span class="c1"># Image 0 received label 2 from image 1 and image 1 label 0 from image 0</span>
<span class="go">tensor([2, 0])</span>
</pre></div>
</div>
<p>You can apply the same augmentation again in which case the same objects get transplanted between the images:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">[</span><span class="s2">&quot;selection&quot;</span><span class="p">]</span>  <span class="c1"># The pixels (objects) which get transplanted</span>
<span class="go">tensor([[[ True, False, False,  True, False],</span>
<span class="go">         [ True, False, False,  True, False],</span>
<span class="go">         [ True, False, False, False,  True],</span>
<span class="go">         [ True,  True,  True, False,  True],</span>
<span class="go">         [ True, False, False, False, False]],</span>

<span class="go">        [[ True,  True, False, False,  True],</span>
<span class="go">         [False, False,  True,  True,  True],</span>
<span class="go">         [False, False, False, False,  True],</span>
<span class="go">         [ True,  True,  True,  True, False],</span>
<span class="go">         [False, False, False,  True, False]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="go">tensor([[[0., 0., 0., 0., 0.],</span>
<span class="go">         [0., 0., 0., 0., 0.],</span>
<span class="go">         [0., 0., 0., 0., 0.],</span>
<span class="go">         [0., 0., 0., 0., 0.],</span>
<span class="go">         [0., 0., 0., 0., 0.]],</span>

<span class="go">        [[1., 1., 1., 1., 1.],</span>
<span class="go">         [1., 1., 1., 1., 1.],</span>
<span class="go">         [1., 1., 1., 1., 1.],</span>
<span class="go">         [1., 1., 1., 1., 1.],</span>
<span class="go">         [1., 1., 1., 1., 1.]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_out2</span><span class="p">,</span> <span class="n">mask_out2</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="n">image2</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_out2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="go">tensor([[[1., 0., 0., 1., 0.],</span>
<span class="go">         [1., 0., 0., 1., 0.],</span>
<span class="go">         [1., 0., 0., 0., 1.],</span>
<span class="go">         [1., 1., 1., 0., 1.],</span>
<span class="go">         [1., 0., 0., 0., 0.]],</span>

<span class="go">        [[0., 0., 1., 1., 0.],</span>
<span class="go">         [1., 1., 0., 0., 0.],</span>
<span class="go">         [1., 1., 1., 1., 0.],</span>
<span class="go">         [0., 0., 0., 0., 1.],</span>
<span class="go">         [1., 1., 1., 0., 1.]]])</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
<section id="transforms3d">
<h2>Transforms3D<a class="headerlink" href="#transforms3d" title="Link to this heading">¶</a></h2>
<p>Set of operators to perform data augmentation on 3D volumetric tensors.</p>
<section id="id9">
<h3>Geometric<a class="headerlink" href="#id9" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.CenterCrop3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">CenterCrop3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.CenterCrop3D" title="Link to this definition">¶</a></dt>
<dd><p>Apply center crop on 3D volumes (5D tensor).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation for the whole batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>size</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>] or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Desired output size (out_d, out_h, out_w) of the crop.
If integer, out_d = out_h = out_w = size.
If Tuple[int, int, int], out_d = size[0], out_h = size[1], out_w = size[2].</p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – resample mode from “nearest” (0) or “bilinear” (1).
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, D, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 4, 4)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, out_d, out_h, out_w)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 4, 4)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span>
<span class="go">tensor([[[[[-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920],</span>
<span class="go">           [-0.3160, -2.1152,  0.3223, -1.2633,  0.3500,  0.3081],</span>
<span class="go">           [ 0.1198,  1.2377,  1.1168, -0.2473, -1.3527, -1.6959],</span>
<span class="go">           [ 0.5667,  0.7935,  0.5988, -1.5551, -0.3414,  1.8530]],</span>

<span class="go">          [[ 0.7502, -0.5855, -0.1734,  0.1835,  1.3894,  1.5863],</span>
<span class="go">           [ 0.9463, -0.8437, -0.6136,  0.0316, -0.4927,  0.2484],</span>
<span class="go">           [ 0.4397,  0.1124,  0.6408,  0.4412, -0.1023,  0.7924],</span>
<span class="go">           [-0.2897,  0.0525,  0.5229,  2.3022, -1.4689, -1.5867]]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">CenterCrop3D</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[[ 0.3223, -1.2633],</span>
<span class="go">           [ 1.1168, -0.2473]],</span>

<span class="go">          [[-0.6136,  0.0316],</span>
<span class="go">           [ 0.6408,  0.4412]]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">CenterCrop3D</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomAffine3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomAffine3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">degrees</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">translate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shears</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomAffine3D" title="Link to this definition">¶</a></dt>
<dd><p>Apply affine transformation 3D volumes (5D tensor).</p>
<p>The transformation is computed so that the center is kept invariant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>degrees</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]]</span>) – Range of yaw (x-axis), pitch (y-axis), roll (z-axis) to select from.
If degrees is a number, then yaw, pitch, roll will be generated from the range of (-degrees, +degrees).
If degrees is a tuple of (min, max), then yaw, pitch, roll will be generated from the range of (min, max).
If degrees is a list of floats [a, b, c], then yaw, pitch, roll will be generated from (-a, a), (-b, b)
and (-c, c).
If degrees is a list of tuple ((a, b), (m, n), (x, y)), then yaw, pitch, roll will be generated from
(a, b), (m, n) and (x, y).
Set to 0 to deactivate rotations.</p></li>
<li><p><strong>translate</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – tuple of maximum absolute fraction for horizontal, vertical and
depthical translations (dx,dy,dz). For example translate=(a, b, c), then
horizontal shift will be randomly sampled in the range -img_width * a &lt; dx &lt; img_width * a
vertical shift will be randomly sampled in the range -img_height * b &lt; dy &lt; img_height * b.
depthical shift will be randomly sampled in the range -img_depth * c &lt; dz &lt; img_depth * c.
Will not translate by default.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>scale</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – scaling factor interval.
If (a, b) represents isotropic scaling, the scale is randomly sampled from the range a &lt;= scale &lt;= b.
If ((a, b), (c, d), (e, f)), the scale is randomly sampled from the range a &lt;= scale_x &lt;= b,
c &lt;= scale_y &lt;= d, e &lt;= scale_z &lt;= f. Will keep original scale by default.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>shears</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]]</span>, <em>optional</em>) – Range of degrees to select from.
If shear is a number, a shear to the 6 facets in the range (-shear, +shear) will be applied.
If shear is a tuple of 2 values, a shear to the 6 facets in the range (shear[0], shear[1]) will be applied.
If shear is a tuple of 6 values, a shear to the i-th facet in the range (-shear[i], shear[i])
will be applied.
If shear is a tuple of 6 tuples, a shear to the i-th facet in the range (-shear[i, 0], shear[i, 1])
will be applied.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – resample mode from “nearest” (0) or “bilinear” (1).
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False). Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, D, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 4, 4)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 4, 4)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomAffine3D</span><span class="p">((</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">aug</span><span class="o">.</span><span class="n">transform_matrix</span>
<span class="go">(tensor([[[[[0.4503, 0.4763, 0.1680],</span>
<span class="go">           [0.2029, 0.4267, 0.3515],</span>
<span class="go">           [0.3195, 0.5436, 0.3706]],</span>

<span class="go">          [[0.5255, 0.3508, 0.4858],</span>
<span class="go">           [0.0795, 0.1689, 0.4220],</span>
<span class="go">           [0.5306, 0.7234, 0.6879]],</span>

<span class="go">          [[0.2971, 0.2746, 0.3471],</span>
<span class="go">           [0.4924, 0.4960, 0.6460],</span>
<span class="go">           [0.3187, 0.4556, 0.7596]]]]]), tensor([[[ 0.9722, -0.0603,  0.2262, -0.1381],</span>
<span class="go">         [ 0.1131,  0.9669, -0.2286,  0.1486],</span>
<span class="go">         [-0.2049,  0.2478,  0.9469,  0.0102],</span>
<span class="go">         [ 0.0000,  0.0000,  0.0000,  1.0000]]]))</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomAffine3D</span><span class="p">((</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomCrop3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomCrop3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_if_needed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'constant'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomCrop3D" title="Link to this definition">¶</a></dt>
<dd><p>Apply random crop on 3D volumes (5D tensor).</p>
<p>Crops random sub-volumes on a given size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation for the whole batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – Desired output size (out_d, out_h, out_w) of the crop.
Must be Tuple[int, int, int], then out_d = size[0], out_h = size[1], out_w = size[2].</p></li>
<li><p><strong>padding</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</span>, <em>optional</em>) – Optional padding on each border of the image.
Default is None, i.e no padding. If a sequence of length 6 is provided, it is used to pad
left, top, right, bottom, front, back borders respectively.
If a sequence of length 3 is provided, it is used to pad left/right,
top/bottom, front/back borders, respectively.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>pad_if_needed</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]</span>, <em>optional</em>) – It will pad the image if smaller than the
desired size to avoid raising an exception. Since cropping is done
after padding, the padding seems to be done at a random offset.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>fill</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Pixel fill value for constant fill. Default is 0. If a tuple of
length 3, it is used to fill R, G, B channels respectively.
This value is only used when the padding_mode is constant.
Default:  <code class="code docutils literal notranslate"><span class="pre">0</span></code></p></li>
<li><p><strong>padding_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – Type of padding. Should be: constant, edge, reflect or symmetric. Default is constant.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;constant&quot;</span></code></p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – resample mode from “nearest” (0) or “bilinear” (1).
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, D, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 4, 4)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, , out_d, out_h, out_w)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 4, 4)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomCrop3D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="go">tensor([[[[[-1.1258, -1.1524],</span>
<span class="go">           [-0.4339,  0.8487]],</span>

<span class="go">          [[-1.2633,  0.3500],</span>
<span class="go">           [ 0.1665,  0.8744]]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomCrop3D</span><span class="p">((</span><span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomDepthicalFlip3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomDepthicalFlip3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomDepthicalFlip3D" title="Link to this definition">¶</a></dt>
<dd><p>Apply random flip along the depth axis of 3D volumes (5D tensor).</p>
<p>Input should be a tensor of shape <span class="math notranslate nohighlight">\((C, D, H, W)\)</span> or a batch of tensors <span class="math notranslate nohighlight">\((*, C, D, H, W)\)</span>.
If Input is a tuple it is assumed that the first element contains the aforementioned tensors and the second,
the corresponding transformation matrix that has been applied to them. In this case the module
will Depthically flip the tensors and concatenate the corresponding transformation matrix to the
previous one. This is especially useful when using this functionality as part of an <code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code> module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of the image being flipped.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input <code class="docutils literal notranslate"><span class="pre">True</span></code> or broadcast it
to the batch form <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, D, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 4, 4)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 4, 4)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span> <span class="o">=</span> <span class="n">RandomDepthicalFlip3D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">seq</span><span class="o">.</span><span class="n">transform_matrix</span>
<span class="go">(tensor([[[[[1., 0., 0.],</span>
<span class="go">           [0., 1., 0.],</span>
<span class="go">           [0., 0., 1.]],</span>

<span class="go">          [[1., 0., 0.],</span>
<span class="go">           [0., 1., 0.],</span>
<span class="go">           [0., 0., 1.]],</span>

<span class="go">          [[1., 0., 0.],</span>
<span class="go">           [0., 1., 0.],</span>
<span class="go">           [0., 0., 1.]]]]]), tensor([[[ 1.,  0.,  0.,  0.],</span>
<span class="go">         [ 0.,  1.,  0.,  0.],</span>
<span class="go">         [ 0.,  0., -1.,  2.],</span>
<span class="go">         [ 0.,  0.,  0.,  1.]]]))</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomDepthicalFlip3D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomHorizontalFlip3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomHorizontalFlip3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomHorizontalFlip3D" title="Link to this definition">¶</a></dt>
<dd><p>Apply random horizontal flip to 3D volumes (5D tensor).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of the image being flipped.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input <code class="docutils literal notranslate"><span class="pre">True</span></code> or broadcast it
to the batch form <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, D, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 4, 4)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 4, 4)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span> <span class="o">=</span> <span class="n">RandomHorizontalFlip3D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">seq</span><span class="o">.</span><span class="n">transform_matrix</span>
<span class="go">(tensor([[[[[0., 0., 1.],</span>
<span class="go">           [0., 1., 0.],</span>
<span class="go">           [1., 0., 0.]],</span>

<span class="go">          [[0., 0., 1.],</span>
<span class="go">           [0., 1., 0.],</span>
<span class="go">           [1., 0., 0.]],</span>

<span class="go">          [[0., 0., 1.],</span>
<span class="go">           [0., 1., 0.],</span>
<span class="go">           [1., 0., 0.]]]]]), tensor([[[-1.,  0.,  0.,  2.],</span>
<span class="go">         [ 0.,  1.,  0.,  0.],</span>
<span class="go">         [ 0.,  0.,  1.,  0.],</span>
<span class="go">         [ 0.,  0.,  0.,  1.]]]))</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomHorizontalFlip3D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomRotation3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomRotation3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">degrees</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomRotation3D" title="Link to this definition">¶</a></dt>
<dd><p>Apply random rotations to 3D volumes (5D tensor).</p>
<p>Input should be a tensor of shape (C, D, H, W) or a batch of tensors <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span>.
If Input is a tuple it is assumed that the first element contains the aforementioned tensors and the second,
the corresponding transformation matrix that has been applied to them. In this case the module
will rotate the tensors and concatenate the corresponding transformation matrix to the
previous one. This is especially useful when using this functionality as part of an <code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code> module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>degrees</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]]</span>) – Range of degrees to select from.
If degrees is a number, then yaw, pitch, roll will be generated from the range of (-degrees, +degrees).
If degrees is a tuple of (min, max), then yaw, pitch, roll will be generated from the range of (min, max).
If degrees is a list of floats [a, b, c], then yaw, pitch, roll will be generated from (-a, a), (-b, b)
and (-c, c).
If degrees is a list of tuple ((a, b), (m, n), (x, y)), then yaw, pitch, roll will be generated from
(a, b), (m, n) and (x, y).
Set to 0 to deactivate rotations.</p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – resample mode from “nearest” (0) or “bilinear” (1).
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, D, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 4, 4)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 4, 4)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomRotation3D</span><span class="p">((</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">aug</span><span class="o">.</span><span class="n">transform_matrix</span>
<span class="go">(tensor([[[[[0.3819, 0.4886, 0.2111],</span>
<span class="go">           [0.1196, 0.3833, 0.4722],</span>
<span class="go">           [0.3432, 0.5951, 0.4223]],</span>

<span class="go">          [[0.5553, 0.4374, 0.2780],</span>
<span class="go">           [0.2423, 0.1689, 0.4009],</span>
<span class="go">           [0.4516, 0.6376, 0.7327]],</span>

<span class="go">          [[0.1605, 0.3112, 0.3673],</span>
<span class="go">           [0.4931, 0.4620, 0.5700],</span>
<span class="go">           [0.3505, 0.4685, 0.8092]]]]]), tensor([[[ 0.9722,  0.1131, -0.2049,  0.1196],</span>
<span class="go">         [-0.0603,  0.9669,  0.2478, -0.1545],</span>
<span class="go">         [ 0.2262, -0.2286,  0.9469,  0.0556],</span>
<span class="go">         [ 0.0000,  0.0000,  0.0000,  1.0000]]]))</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomRotation3D</span><span class="p">((</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomVerticalFlip3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomVerticalFlip3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomVerticalFlip3D" title="Link to this definition">¶</a></dt>
<dd><p>Apply random vertical flip to 3D volumes (5D tensor).</p>
<p>Input should be a tensor of shape <span class="math notranslate nohighlight">\((C, D, H, W)\)</span> or a batch of tensors <span class="math notranslate nohighlight">\((*, C, D, H, W)\)</span>.
If Input is a tuple it is assumed that the first element contains the aforementioned tensors and the second,
the corresponding transformation matrix that has been applied to them. In this case the module
will Vertically flip the tensors and concatenate the corresponding transformation matrix to the
previous one. This is especially useful when using this functionality as part of an <code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code> module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of the image being flipped.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – apply the same transformation across the batch.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input <code class="docutils literal notranslate"><span class="pre">True</span></code> or broadcast it
to the batch form <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, D, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 4, 4)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 4, 4)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span> <span class="o">=</span> <span class="n">RandomVerticalFlip3D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">seq</span><span class="o">.</span><span class="n">transform_matrix</span>
<span class="go">(tensor([[[[[0., 0., 1.],</span>
<span class="go">           [0., 1., 0.],</span>
<span class="go">           [1., 0., 0.]],</span>

<span class="go">          [[0., 0., 1.],</span>
<span class="go">           [0., 1., 0.],</span>
<span class="go">           [1., 0., 0.]],</span>

<span class="go">          [[0., 0., 1.],</span>
<span class="go">           [0., 1., 0.],</span>
<span class="go">           [1., 0., 0.]]]]]), tensor([[[ 1.,  0.,  0.,  0.],</span>
<span class="go">         [ 0., -1.,  0.,  2.],</span>
<span class="go">         [ 0.,  0.,  1.,  0.],</span>
<span class="go">         [ 0.,  0.,  0.,  1.]]]))</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomVerticalFlip3D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</section>
<section id="id10">
<h3>Intensity<a class="headerlink" href="#id10" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomEqualize3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomEqualize3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomEqualize3D" title="Link to this definition">¶</a></dt>
<dd><p>Apply random equalization to 3D volumes (5D tensor).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of the image being equalized.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>same_on_batch</strong><strong>)</strong> – apply the same transformation across the batch.</p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, D, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 4, 4)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 4, 4)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomEqualize3D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[[0.4963, 0.7682, 0.0885],</span>
<span class="go">           [0.1320, 0.3074, 0.6341],</span>
<span class="go">           [0.4901, 0.8964, 0.4556]],</span>

<span class="go">          [[0.6323, 0.3489, 0.4017],</span>
<span class="go">           [0.0223, 0.1689, 0.2939],</span>
<span class="go">           [0.5185, 0.6977, 0.8000]],</span>

<span class="go">          [[0.1610, 0.2823, 0.6816],</span>
<span class="go">           [0.9152, 0.3971, 0.8742],</span>
<span class="go">           [0.4194, 0.5529, 0.9527]]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomEqualize3D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomMotionBlur3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomMotionBlur3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">angle</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">direction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">border_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">BorderType.CONSTANT.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.NEAREST.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_on_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomMotionBlur3D" title="Link to this definition">¶</a></dt>
<dd><p>Apply random motion blur on 3D volumes (5D tensor).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.5</span></code></p></li>
<li><p><strong>kernel_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]]</span>) – motion kernel size (odd and positive).
If int, the kernel will have a fixed size.
If Tuple[int, int], it will randomly generate the value from the range batch-wisely.</p></li>
<li><p><strong>angle</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]]</span>) – Range of degrees to select from.
If angle is a number, then yaw, pitch, roll will be generated from the range of (-angle, +angle).
If angle is a tuple of (min, max), then yaw, pitch, roll will be generated from the range of (min, max).
If angle is a list of floats [a, b, c], then yaw, pitch, roll will be generated from (-a, a), (-b, b)
and (-c, c).
If angle is a list of tuple ((a, b), (m, n), (x, y)), then yaw, pitch, roll will be generated from
(a, b), (m, n) and (x, y).
Set to 0 to deactivate rotations.</p></li>
<li><p><strong>direction</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</span>) – forward/backward direction of the motion blur.
Lower values towards -1.0 will point the motion blur towards the back (with angle provided via angle),
while higher values towards 1.0 will point the motion blur forward. A value of 0.0 leads to a
uniformly (but still angled) motion blur.
If float, it will generate the value from (-direction, direction).
If Tuple[int, int], it will randomly generate the value from the range.</p></li>
<li><p><strong>border_type</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BorderType</span></code>]</span>, <em>optional</em>) – the padding mode to be applied before convolving.
CONSTANT = 0, REFLECT = 1, REPLICATE = 2, CIRCULAR = 3. Default: BorderType.CONSTANT.</p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – resample mode from “nearest” (0) or “bilinear” (1).
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.NEAREST.name</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((C, D, H, W)\)</span> or <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span>, Optional: <span class="math notranslate nohighlight">\((B, 4, 4)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input tensor must be float and normalized into [0, 1] for the best differentiability support.
Additionally, this function accepts another transformation tensor (<span class="math notranslate nohighlight">\((B, 4, 4)\)</span>), then the
applied transformation will be merged int to the input transformation tensor and returned.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">motion_blur</span> <span class="o">=</span> <span class="n">RandomMotionBlur3D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">35.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">motion_blur</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[[0.1654, 0.4772, 0.2004, 0.3566, 0.2613],</span>
<span class="go">           [0.4557, 0.3131, 0.4809, 0.2574, 0.2696],</span>
<span class="go">           [0.2721, 0.5998, 0.3956, 0.5363, 0.1541],</span>
<span class="go">           [0.3006, 0.4773, 0.6395, 0.2856, 0.3989],</span>
<span class="go">           [0.4491, 0.5595, 0.1836, 0.3811, 0.1398]],</span>

<span class="go">          [[0.1843, 0.4240, 0.3370, 0.1231, 0.2186],</span>
<span class="go">           [0.4047, 0.3332, 0.1901, 0.5329, 0.3023],</span>
<span class="go">           [0.3070, 0.3088, 0.4807, 0.4928, 0.2590],</span>
<span class="go">           [0.2416, 0.4614, 0.7091, 0.5237, 0.1433],</span>
<span class="go">           [0.1582, 0.4577, 0.2749, 0.1369, 0.1607]],</span>

<span class="go">          [[0.2733, 0.4040, 0.4396, 0.2284, 0.3319],</span>
<span class="go">           [0.3856, 0.6730, 0.4624, 0.3878, 0.3076],</span>
<span class="go">           [0.4307, 0.4217, 0.2977, 0.5086, 0.5406],</span>
<span class="go">           [0.3686, 0.2778, 0.5228, 0.7592, 0.6455],</span>
<span class="go">           [0.2033, 0.3014, 0.4898, 0.6164, 0.3117]]]]])</span>
</pre></div>
</div>
<dl>
<dt>To apply the exact augmenation again, you may take the advantage of the previous parameter state:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aug</span> <span class="o">=</span> <span class="n">RandomMotionBlur3D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">35.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">aug</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">aug</span><span class="o">.</span><span class="n">_params</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">tensor(True)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</section>
<section id="id11">
<h3>Mix<a class="headerlink" href="#id11" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.RandomTransplantation3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomTransplantation3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">excluded_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_keys</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.RandomTransplantation3D" title="Link to this definition">¶</a></dt>
<dd><p>RandomTransplantation3D augmentation.</p>
<p>3D version of the <a class="reference internal" href="#kornia.augmentation.RandomTransplantation" title="kornia.augmentation.RandomTransplantation"><code class="xref py py-class docutils literal notranslate"><span class="pre">kornia.augmentation.RandomTransplantation</span></code></a> augmentation intended to be used with
<code class="xref py py-class docutils literal notranslate"><span class="pre">kornia.augmentation.AugmentationSequential</span></code>. The interface is identical to the 2D version.</p>
</dd></dl>

</section>
</section>
<section id="normalizations">
<h2>Normalizations<a class="headerlink" href="#normalizations" title="Link to this heading">¶</a></h2>
<p>Normalization operations are shape-agnostic for both 2D and 3D tensors.</p>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.Denormalize">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">Denormalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.Denormalize" title="Link to this definition">¶</a></dt>
<dd><p>Denormalize tensor images with mean and standard deviation.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\text{input[channel] = (input[channel] * std[channel]) + mean[channel]}\]</div>
</div>
<p>Where <cite>mean</cite> is <span class="math notranslate nohighlight">\((M_1, ..., M_n)\)</span> and <cite>std</cite> <span class="math notranslate nohighlight">\((S_1, ..., S_n)\)</span> for <cite>n</cite> channels,</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>) – Mean for each channel.</p></li>
<li><p><strong>std</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>) – Standard deviations for each channel.</p></li>
<li><p><strong>same_on_batch</strong> – apply the same transformation across the batch.</p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Denormalised tensor with same size as input <span class="math notranslate nohighlight">\((*, C, H, W)\)</span>.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.denormalize" title="kornia.enhance.denormalize"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.denormalize()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">norm</span> <span class="o">=</span> <span class="n">Denormalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 4, 3, 3])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.Normalize">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">Normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.Normalize" title="Link to this definition">¶</a></dt>
<dd><p>Normalize tensor images with mean and standard deviation.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\text{input[channel] = (input[channel] - mean[channel]) / std[channel]}\]</div>
</div>
<p>Where <cite>mean</cite> is <span class="math notranslate nohighlight">\((M_1, ..., M_n)\)</span> and <cite>std</cite> <span class="math notranslate nohighlight">\((S_1, ..., S_n)\)</span> for <cite>n</cite> channels,</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean</strong> (<span class="sphinx_autodoc_typehints-type">Tensor | tuple[float, …] | list[float] | float</span>) – Mean for each channel.</p></li>
<li><p><strong>std</strong> (<span class="sphinx_autodoc_typehints-type">Tensor | tuple[float, …] | list[float] | float</span>) – Standard deviations for each channel.</p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type">float</span>, <em>optional</em>) – probability of applying the transformation.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type">bool</span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Normalised tensor with same size as input <span class="math notranslate nohighlight">\((*, C, H, W)\)</span>.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function internally uses <a class="reference internal" href="enhance.html#kornia.enhance.normalize" title="kornia.enhance.normalize"><code class="xref py py-func docutils literal notranslate"><span class="pre">kornia.enhance.normalize()</span></code></a>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">norm</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 4, 3, 3])</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="image-resize">
<h2>Image Resize<a class="headerlink" href="#image-resize" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.LongestMaxSize">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">LongestMaxSize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.LongestMaxSize" title="Link to this definition">¶</a></dt>
<dd><p>Rescale an image so that maximum side is equal to max_size, keeping the aspect ratio of the initial image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>max_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>) – maximum size of the image after the transformation.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.Resize">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">Resize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">side</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'short'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">antialias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.Resize" title="Link to this definition">¶</a></dt>
<dd><p>Resize to size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]]</span>) – Size (h, w) in pixels of the resized region or just one side.</p></li>
<li><p><strong>side</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – Which side to resize, if size is only of type int.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;short&quot;</span></code></p></li>
<li><p><strong>resample</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Resample</span></code>]</span>, <em>optional</em>) – Resampling mode.
Default:  <code class="code docutils literal notranslate"><span class="pre">Resample.BILINEAR.name</span></code></p></li>
<li><p><strong>align_corners</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – interpolation flag.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>antialias</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if True, then image will be filtered with Gaussian before downscaling. No effect for upscaling.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>p</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – probability of the augmentation been applied.
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>keepdim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – whether to keep the output shape the same as input (True) or broadcast it
to the batch form (False).
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.augmentation.SmallestMaxSize">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.augmentation.</span></span><span class="sig-name descname"><span class="pre">SmallestMaxSize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Resample.BILINEAR.name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.augmentation.SmallestMaxSize" title="Link to this definition">¶</a></dt>
<dd><p>Rescale an image so that minimum side is equal to max_size, keeping the aspect ratio of the initial image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>max_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>) – maximum size of the image after the transformation.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>

        </article>
      </div>
      <footer>

        <div class="related-pages">
          <a class="next-page" href="color.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">kornia.color</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="augmentation.container.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>

                <div class="title">Augmentation Containers</div>

              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, Kornia developers
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s

            <a href="https://github.com/pradyunsg/furo">Furo</a>

          </div>
          <div class="right-details">

          </div>
        </div>

      </footer>
    </div>
    <aside class="toc-drawer">


      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Image Augmentations</a><ul>
<li><a class="reference internal" href="#transforms2d">Transforms2D</a><ul>
<li><a class="reference internal" href="#intensity">Intensity</a><ul>
<li><a class="reference internal" href="#kornia.augmentation.ColorJiggle"><code class="docutils literal notranslate"><span class="pre">ColorJiggle</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.ColorJitter"><code class="docutils literal notranslate"><span class="pre">ColorJitter</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomAutoContrast"><code class="docutils literal notranslate"><span class="pre">RandomAutoContrast</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomBoxBlur"><code class="docutils literal notranslate"><span class="pre">RandomBoxBlur</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomBrightness"><code class="docutils literal notranslate"><span class="pre">RandomBrightness</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomChannelDropout"><code class="docutils literal notranslate"><span class="pre">RandomChannelDropout</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomChannelShuffle"><code class="docutils literal notranslate"><span class="pre">RandomChannelShuffle</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomClahe"><code class="docutils literal notranslate"><span class="pre">RandomClahe</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomContrast"><code class="docutils literal notranslate"><span class="pre">RandomContrast</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomEqualize"><code class="docutils literal notranslate"><span class="pre">RandomEqualize</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomDissolving"><code class="docutils literal notranslate"><span class="pre">RandomDissolving</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomGamma"><code class="docutils literal notranslate"><span class="pre">RandomGamma</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomGaussianBlur"><code class="docutils literal notranslate"><span class="pre">RandomGaussianBlur</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomGaussianIllumination"><code class="docutils literal notranslate"><span class="pre">RandomGaussianIllumination</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomGaussianNoise"><code class="docutils literal notranslate"><span class="pre">RandomGaussianNoise</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomGrayscale"><code class="docutils literal notranslate"><span class="pre">RandomGrayscale</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomHue"><code class="docutils literal notranslate"><span class="pre">RandomHue</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomInvert"><code class="docutils literal notranslate"><span class="pre">RandomInvert</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomJPEG"><code class="docutils literal notranslate"><span class="pre">RandomJPEG</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomLinearCornerIllumination"><code class="docutils literal notranslate"><span class="pre">RandomLinearCornerIllumination</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomLinearIllumination"><code class="docutils literal notranslate"><span class="pre">RandomLinearIllumination</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomMedianBlur"><code class="docutils literal notranslate"><span class="pre">RandomMedianBlur</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomMotionBlur"><code class="docutils literal notranslate"><span class="pre">RandomMotionBlur</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomPlanckianJitter"><code class="docutils literal notranslate"><span class="pre">RandomPlanckianJitter</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomPlasmaBrightness"><code class="docutils literal notranslate"><span class="pre">RandomPlasmaBrightness</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomPlasmaContrast"><code class="docutils literal notranslate"><span class="pre">RandomPlasmaContrast</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomPlasmaShadow"><code class="docutils literal notranslate"><span class="pre">RandomPlasmaShadow</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomPosterize"><code class="docutils literal notranslate"><span class="pre">RandomPosterize</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomRain"><code class="docutils literal notranslate"><span class="pre">RandomRain</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomRGBShift"><code class="docutils literal notranslate"><span class="pre">RandomRGBShift</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomSaltAndPepperNoise"><code class="docutils literal notranslate"><span class="pre">RandomSaltAndPepperNoise</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomSaturation"><code class="docutils literal notranslate"><span class="pre">RandomSaturation</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomSharpness"><code class="docutils literal notranslate"><span class="pre">RandomSharpness</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomSnow"><code class="docutils literal notranslate"><span class="pre">RandomSnow</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomSolarize"><code class="docutils literal notranslate"><span class="pre">RandomSolarize</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#geometric">Geometric</a><ul>
<li><a class="reference internal" href="#kornia.augmentation.CenterCrop"><code class="docutils literal notranslate"><span class="pre">CenterCrop</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.PadTo"><code class="docutils literal notranslate"><span class="pre">PadTo</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomAffine"><code class="docutils literal notranslate"><span class="pre">RandomAffine</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomCrop"><code class="docutils literal notranslate"><span class="pre">RandomCrop</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomElasticTransform"><code class="docutils literal notranslate"><span class="pre">RandomElasticTransform</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomErasing"><code class="docutils literal notranslate"><span class="pre">RandomErasing</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomFisheye"><code class="docutils literal notranslate"><span class="pre">RandomFisheye</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomHorizontalFlip"><code class="docutils literal notranslate"><span class="pre">RandomHorizontalFlip</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomPerspective"><code class="docutils literal notranslate"><span class="pre">RandomPerspective</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomResizedCrop"><code class="docutils literal notranslate"><span class="pre">RandomResizedCrop</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomRotation90"><code class="docutils literal notranslate"><span class="pre">RandomRotation90</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomRotation"><code class="docutils literal notranslate"><span class="pre">RandomRotation</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomShear"><code class="docutils literal notranslate"><span class="pre">RandomShear</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomThinPlateSpline"><code class="docutils literal notranslate"><span class="pre">RandomThinPlateSpline</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomVerticalFlip"><code class="docutils literal notranslate"><span class="pre">RandomVerticalFlip</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mix">Mix</a><ul>
<li><a class="reference internal" href="#kornia.augmentation.RandomCutMixV2"><code class="docutils literal notranslate"><span class="pre">RandomCutMixV2</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomJigsaw"><code class="docutils literal notranslate"><span class="pre">RandomJigsaw</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomMixUpV2"><code class="docutils literal notranslate"><span class="pre">RandomMixUpV2</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomMosaic"><code class="docutils literal notranslate"><span class="pre">RandomMosaic</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomTransplantation"><code class="docutils literal notranslate"><span class="pre">RandomTransplantation</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#transforms3d">Transforms3D</a><ul>
<li><a class="reference internal" href="#id9">Geometric</a><ul>
<li><a class="reference internal" href="#kornia.augmentation.CenterCrop3D"><code class="docutils literal notranslate"><span class="pre">CenterCrop3D</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomAffine3D"><code class="docutils literal notranslate"><span class="pre">RandomAffine3D</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomCrop3D"><code class="docutils literal notranslate"><span class="pre">RandomCrop3D</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomDepthicalFlip3D"><code class="docutils literal notranslate"><span class="pre">RandomDepthicalFlip3D</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomHorizontalFlip3D"><code class="docutils literal notranslate"><span class="pre">RandomHorizontalFlip3D</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomRotation3D"><code class="docutils literal notranslate"><span class="pre">RandomRotation3D</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomVerticalFlip3D"><code class="docutils literal notranslate"><span class="pre">RandomVerticalFlip3D</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#id10">Intensity</a><ul>
<li><a class="reference internal" href="#kornia.augmentation.RandomEqualize3D"><code class="docutils literal notranslate"><span class="pre">RandomEqualize3D</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.RandomMotionBlur3D"><code class="docutils literal notranslate"><span class="pre">RandomMotionBlur3D</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#id11">Mix</a><ul>
<li><a class="reference internal" href="#kornia.augmentation.RandomTransplantation3D"><code class="docutils literal notranslate"><span class="pre">RandomTransplantation3D</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#normalizations">Normalizations</a><ul>
<li><a class="reference internal" href="#kornia.augmentation.Denormalize"><code class="docutils literal notranslate"><span class="pre">Denormalize</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.Normalize"><code class="docutils literal notranslate"><span class="pre">Normalize</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#image-resize">Image Resize</a><ul>
<li><a class="reference internal" href="#kornia.augmentation.LongestMaxSize"><code class="docutils literal notranslate"><span class="pre">LongestMaxSize</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.Resize"><code class="docutils literal notranslate"><span class="pre">Resize</span></code></a></li>
<li><a class="reference internal" href="#kornia.augmentation.SmallestMaxSize"><code class="docutils literal notranslate"><span class="pre">SmallestMaxSize</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>


    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=cce5339e"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/custom.js?v=107dad88"></script>
    <script defer="defer" type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.38.1/gradio.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/iframe-resizer/4.3.2/iframeResizer.min.js"></script>
    </body>
</html>
