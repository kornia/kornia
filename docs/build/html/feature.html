<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta content="description" name="name" />
<meta content="&quot;The Local Features and Image Matching module in Kornia offers tools to detect, describe, and match local features in images. It includes various detectors, descriptors, and matching algorithms based on classical methods and deep learning models like Harris, SIFT, KeyNet, DISK, and LoFTR. The module also provides tools for working with local affine frames (LAFs), including affine shape and orientation estimation.&quot;" name="content" />

        <script async src="https://www.googletagmanager.com/gtag/js?id=G-YSCFZB2WDV"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            
            gtag('config', 'G-YSCFZB2WDV');
            
        </script>
    <link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="kornia.filters" href="filters.html" /><link rel="prev" title="kornia.enhance" href="enhance.html" />
        <link rel="canonical" href="https://kornia.readthedocs.io/feature.html" />

    <link rel="shortcut icon" href="_static/kornia_logo_favicon.png"/><!-- Generated with Sphinx 7.4.7 and Furo 2024.08.06 -->
        <title>Local Features and Image Matching - Kornia</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d75fae25" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="_static/css/main.css?v=9b880210" />
    
    


<style>
  body {
    --color-code-background: #f0f0f0;
  --color-code-foreground: black;
  --color-sidebar-background: #3980F5;
  --color-sidebar-background-border: #3980F5;
  --color-sidebar-caption-text: white;
  --color-sidebar-link-text--top-level: white;
  --color-sidebar-link-text: white;
  --sidebar-caption-font-size: normal;
  --color-sidebar-item-background--hover:  #5dade2;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-sidebar-background: #1a1c1e;
  --color-sidebar-background-border: #1a1c1e;
  --color-sidebar-caption-text: white;
  --color-sidebar-link-text--top-level: white;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-sidebar-background: #1a1c1e;
  --color-sidebar-background-border: #1a1c1e;
  --color-sidebar-caption-text: white;
  --color-sidebar-link-text--top-level: white;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">Kornia</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="_static/img/kornia_logo_only_light.svg" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="_static/img/kornia_logo_only_dark.svg" alt="Dark Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">GET STARTED</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="get-started/introduction.html">What is Kornia library ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/highlights.html">Highlighted Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/about.html">About</a></li>
<li class="toctree-l1"><a class="reference external" href="https://kornia.github.io/tutorials/">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/multi-framework-support.html">Multi-Framework Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/training.html">Training API (experimental)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.luxonis.com/en/latest/pages/tutorials/creating-custom-nn-models/#kornia">OpenCV AI Kit</a></li>
<li class="toctree-l1"><a class="reference internal" href="get-started/governance.html">Kornia AI Organization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API REFERENCE</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="augmentation.html">kornia.augmentation</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of kornia.augmentation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="augmentation.auto.html">Automatic Augmentation Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="augmentation.base.html">Base Classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="augmentation.container.html">Augmentation Containers</a></li>
<li class="toctree-l2"><a class="reference internal" href="augmentation.module.html">Image Augmentations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="color.html">kornia.color</a></li>
<li class="toctree-l1"><a class="reference internal" href="contrib.html">kornia.contrib</a></li>
<li class="toctree-l1"><a class="reference internal" href="core.html">kornia.core</a></li>
<li class="toctree-l1"><a class="reference internal" href="enhance.html">kornia.enhance</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Local Features and Image Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="filters.html">kornia.filters</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="geometry.html">kornia.geometry</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of kornia.geometry</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="geometry.bbox.html">kornia.geometry.bbox</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.boxes.html">kornia.geometry.boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.keypoints.html">kornia.geometry.keypoints</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.calibration.html">kornia.geometry.calibration</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="geometry.camera.html">kornia.geometry.camera</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of kornia.geometry.camera</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="geometry.camera.pinhole.html">Pinhole Camera</a></li>
<li class="toctree-l3"><a class="reference internal" href="geometry.camera.perspective.html">Perspective Camera</a></li>
<li class="toctree-l3"><a class="reference internal" href="geometry.camera.stereo.html">Stereo Camera</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="geometry.conversions.html">kornia.geometry.conversions</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.depth.html">kornia.geometry.depth</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.epipolar.html">kornia.geometry.epipolar</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.homography.html">kornia.geometry.homography</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.liegroup.html">kornia.geometry.liegroup</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.liegroup.html#lie-algebra">lie algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.liegroup.html#lie-group-and-lie-algebra">lie group and lie algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.linalg.html">kornia.geometry.linalg</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.line.html">kornia.geometry.line</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.quaternion.html">kornia.geometry.quaternion</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.solvers.html">kornia.geometry.solvers</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.subpix.html">kornia.geometry.subpix</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.transform.html">kornia.geometry.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="geometry.ransac.html">kornia.geometry.ransac</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="sensors.html">kornia.sensors</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of kornia.sensors</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="sensors.camera.html">kornia.sensors.camera</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="io.html">kornia.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="image.html">kornia.image</a></li>
<li class="toctree-l1"><a class="reference internal" href="losses.html">kornia.losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Models Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">kornia.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="morphology.html">kornia.morphology</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerf.html">kornia.nerf</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">ONNXSequential: Chain Multiple ONNX Models with Ease</a></li>
<li class="toctree-l1"><a class="reference internal" href="tracking.html">kornia.tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">kornia.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">kornia.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="x.html">kornia.x</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KORNIA APPLICATIONS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="applications/intro.html">Computer Vision Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/visual_prompting.html">Visual Prompting</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/face_detection.html">Face Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_augmentations.html">Image Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_classification.html">Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_matching.html">Image Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_stitching.html">Image Stitching</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_registration.html">Image Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/image_denoising.html">Image Denoising</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/semantic_segmentation.html">Semantic segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications/object_detection.html">Object detection</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KORNIA MODELS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="models/efficient_vit.html">EfficientViT</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/rt_detr.html">Real-Time Detection Transformer (RT-DETR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/segment_anything.html">Segment Anything (SAM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/mobile_sam.html">Faster Segment Anything (MobileSAM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/yunet.html">YuNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/vit.html">Vision Transformer (ViT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/vit_mobile.html">MobileViT</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/tiny_vit.html">TinyViT</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/loftr.html">LoFTR (matching)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/defmo.html">DeFMO (video)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/hardnet.html">Hardnet (descriptor)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/affnet.html">Affnet (detection)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/sold2.html">SOLD2 (Line detection and matching)</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/dexined.html">Dexined (edge detection)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">SUPPORT</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/kornia/kornia/issues">Issue tracker</a></li>
<li class="toctree-l1"><a class="reference external" href="https://join.slack.com/t/kornia/shared_invite/zt-csobk21g-2AQRi~X9Uu6PLMuUZdvfjA">Slack community</a></li>
<li class="toctree-l1"><a class="reference external" href="https://librecv.org">LibreCV community</a></li>
<li class="toctree-l1"><a class="reference external" href="https://twitter.com/kornia_foss">Twitter @kornia_foss</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/chinese.html">Kornia 社区</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.youtube.com/channel/UCI1SE1Ij2Fast5BSKxoa7Ag">Kornia Youtube</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.linkedin.com/company/kornia/">Kornia LinkedIn</a></li>
<li class="toctree-l1"><a class="reference external" href="https://kornia.org">Kornia AI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">COMMUNITY</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community/contribute.html">Contribute to Kornia</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/faqs.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/bibliography.html">Bibliography</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="_sources/feature.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="local-features-and-image-matching">
<h1>Local Features and Image Matching<a class="headerlink" href="#local-features-and-image-matching" title="Link to this heading">¶</a></h1>
<p>This module provides a set of tools to detect and describe local features in images. The module is designed to be
compatible with the PyTorch ecosystem and provides a set of models and differentiable operations to be used in deep learning
pipelines.</p>
<p>The module is divided into three main components:</p>
<ol class="arabic simple">
<li><p><strong>Detectors</strong>: These are models that are used to detect keypoints in images. The module provides a set of detectors that
are based on different algorithms such as Harris, GFTT, Hessian, and DoG. The module also provides a set of detectors that
are based on deep learning models such as KeyNet, DISK and DeDoDe.</p></li>
<li><p><strong>Descriptors</strong>: These are models that are used to describe the local features detected by the detectors. The module
provides a set of descriptors that are based on different algorithms such as SIFT, HardNet, and TFeat. The module also
provides a set of descriptors that are based on deep learning models such as HyNet, SOSNet, and LAFDescriptor.</p></li>
<li><p><strong>Matching</strong>: These are models that are used to match the local features detected and described by the detectors and
descriptors. The module provides a set of matching algorithms such as nearest neighbor, mutual nearest neighbor, and
geometrically aware matching. Besides this, the module also contains AdaLAM hancrafted and LightGlue learned matchers.
Finally, the module provides LoFTR - detector-less semi-dense image matching model.</p></li>
</ol>
<p>Besides this, the module also provides a set of tools to work with local affine frames (LAF) such as extracting patches,
normalizing, denormalizing, and rotating LAFs. The module also provides a set of models to estimate the affine shape of
LAFs such as LAFAffineShapeEstimator and PatchAffineShapeEstimator. The module also provides a set of models to estimate
the orientation of LAFs such as OriNet and LAFOrienter.</p>
<p>Finally, kind of addition, module contains a DeFMO model for the task of video frame interpolation, specifically high speed objects debluring.</p>
<section id="benchmarks-and-recommendations">
<h2>Benchmarks and recommendations<a class="headerlink" href="#benchmarks-and-recommendations" title="Link to this heading">¶</a></h2>
<p>The following table shows the performance of the different models on <a class="reference external" href="https://www.cs.ubc.ca/research/image-matching-challenge/2021/leaderboard/">IMC2021 benchmark</a> .</p>
<div class="table-wrapper colwidths-given docutils container" id="id26">
<table class="docutils align-default" id="id26">
<caption><span class="caption-text">IMC2021 Benchmark, 8000 features</span><a class="headerlink" href="#id26" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Feature name</p></th>
<th class="head"><p>Stereo mAA &#64; 10 degrees, PhotoTourism.</p></th>
<th class="head"><p>Multiview mAA &#64; 10 degrees, PhotoTourism.</p></th>
<th class="head"><p>Stereo mAA &#64; 10 degrees, PragueParks.</p></th>
<th class="head"><p>Multiview mAA &#64; 10 degrees, PragueParks.</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>DISK-LightGlue</p></td>
<td><p>0.6184</p></td>
<td><p>0.7741</p></td>
<td><p>0.6116</p></td>
<td><p>0.4988</p></td>
</tr>
<tr class="row-odd"><td><p>LoFTR</p></td>
<td><p>0.6090</p></td>
<td><p>0.7609</p></td>
<td><p>0.7546</p></td>
<td><p>0.4711</p></td>
</tr>
<tr class="row-even"><td><p>OpenCV-DoG-HardNet-LightGlue</p></td>
<td><p>0.5850</p></td>
<td><p>0.7587</p></td>
<td><p>0.6525</p></td>
<td><p>0.4973</p></td>
</tr>
<tr class="row-odd"><td><p>OpenCV-DoG-AffNet-HardNet8-AdaLAM</p></td>
<td><p>0.5502</p></td>
<td><p>0.7522</p></td>
<td><p>0.5998</p></td>
<td><p>0.4712</p></td>
</tr>
<tr class="row-even"><td><p>Upright SIFT (OpenCV)</p></td>
<td><p>0.5122</p></td>
<td><p>0.6849</p></td>
<td><p>0.6060</p></td>
<td><p>0.4439</p></td>
</tr>
</tbody>
</table>
</div>
<div class="table-wrapper colwidths-given docutils container" id="id27">
<table class="docutils align-default" id="id27">
<caption><span class="caption-text">IMC2021 Benchmark, 2048 features</span><a class="headerlink" href="#id27" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Feature name</p></th>
<th class="head"><p>Stereo mAA &#64; 10 degrees, PhotoTourism.</p></th>
<th class="head"><p>Multiview mAA &#64; 10 degrees, PhotoTourism.</p></th>
<th class="head"><p>Stereo mAA &#64; 10 degrees, PragueParks.</p></th>
<th class="head"><p>Multiview mAA &#64; 10 degrees, PragueParks.</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>DISK-LightGlue</p></td>
<td><p>0.5720</p></td>
<td><p>0.7543</p></td>
<td><p>0.5099</p></td>
<td><p>0.4565</p></td>
</tr>
<tr class="row-odd"><td><p>OpenCV-DoG-HardNet-LightGlue</p></td>
<td><p>0.3954</p></td>
<td><p>0.6272</p></td>
<td><p>0.5157</p></td>
<td><p>0.4456</p></td>
</tr>
<tr class="row-even"><td><p>Upright SIFT (OpenCV)</p></td>
<td><p>0.3827</p></td>
<td><p>0.5545</p></td>
<td><p>0.4136</p></td>
<td><p>0.3607</p></td>
</tr>
</tbody>
</table>
</div>
<p>LoFTR works the best for indoor scenes, whereas DISK and DeDoDe + LightGlue work the best for outdoor scenes.
The DeDoDe and speed benchmarks are coming soon.
For some other use-cases you may want to use SIFT, or SIFT + HardNet + LightGlue, e.g. for remote sensing or medical imaging.</p>
</section>
<section id="detectors">
<h2>Detectors<a class="headerlink" href="#detectors" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.gftt_response">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">gftt_response</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grads_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sobel'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigmas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.gftt_response" title="Link to this definition">¶</a></dt>
<dd><p>Compute the Shi-Tomasi cornerness function.</p>
<img alt="_images/gftt_response.png" src="_images/gftt_response.png" />
<p>Function does not do any normalization or nms. The response map is computed according the following formulation:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[R = min(eig(M))\]</div>
</div>
<p>where:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}M = \sum_{(x,y) \in W}
\begin{bmatrix}
    I^{2}_x &amp; I_x I_y \\
    I_x I_y &amp; I^{2}_y \\
\end{bmatrix}\end{split}\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – input image with shape <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p></li>
<li><p><strong>grads_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – can be <code class="docutils literal notranslate"><span class="pre">'sobel'</span></code> for standalone use or <code class="docutils literal notranslate"><span class="pre">'diff'</span></code> for use on Gaussian pyramid.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;sobel&quot;</span></code></p></li>
<li><p><strong>sigmas</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – coefficients to be multiplied by multichannel response. Should be shape of <span class="math notranslate nohighlight">\((B)\)</span>
It is necessary for performing non-maxima-suppression across different scale pyramid levels.
See <a class="reference external" href="https://github.com/vlfeat/vlfeat/blob/master/vl/covdet.c#L874">vlfeat</a>.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the response map per channel with shape <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span><span class="p">]]])</span>  <span class="c1"># 1x1x7x7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># compute the response map</span>
<span class="go">gftt_response(input)</span>
<span class="go">tensor([[[[0.0155, 0.0334, 0.0194, 0.0000, 0.0194, 0.0334, 0.0155],</span>
<span class="go">          [0.0334, 0.0575, 0.0339, 0.0000, 0.0339, 0.0575, 0.0334],</span>
<span class="go">          [0.0194, 0.0339, 0.0497, 0.0000, 0.0497, 0.0339, 0.0194],</span>
<span class="go">          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],</span>
<span class="go">          [0.0194, 0.0339, 0.0497, 0.0000, 0.0497, 0.0339, 0.0194],</span>
<span class="go">          [0.0334, 0.0575, 0.0339, 0.0000, 0.0339, 0.0575, 0.0334],</span>
<span class="go">          [0.0155, 0.0334, 0.0194, 0.0000, 0.0194, 0.0334, 0.0155]]]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.harris_response">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">harris_response</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.04</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grads_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sobel'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigmas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.harris_response" title="Link to this definition">¶</a></dt>
<dd><p>Compute the Harris cornerness function.</p>
<img alt="_images/harris_response.png" src="_images/harris_response.png" />
<p>Function does not do any normalization or nms. The response map is computed according the following formulation:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[R = max(0, det(M) - k \cdot trace(M)^2)\]</div>
</div>
<p>where:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}M = \sum_{(x,y) \in W}
\begin{bmatrix}
    I^{2}_x &amp; I_x I_y \\
    I_x I_y &amp; I^{2}_y \\
\end{bmatrix}\end{split}\]</div>
</div>
<p>and <span class="math notranslate nohighlight">\(k\)</span> is an empirically determined constant
<span class="math notranslate nohighlight">\(k ∈ [ 0.04 , 0.06 ]\)</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – input image with shape <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p></li>
<li><p><strong>k</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]</span>, <em>optional</em>) – the Harris detector free parameter.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.04</span></code></p></li>
<li><p><strong>grads_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – can be <code class="docutils literal notranslate"><span class="pre">'sobel'</span></code> for standalone use or <code class="docutils literal notranslate"><span class="pre">'diff'</span></code> for use on Gaussian pyramid.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;sobel&quot;</span></code></p></li>
<li><p><strong>sigmas</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – <p>coefficients to be multiplied by multichannel response. Should be shape of <span class="math notranslate nohighlight">\((B)\)</span>
It is necessary for performing non-maxima-suppression across different scale pyramid levels.
See <a class="reference external" href="https://github.com/vlfeat/vlfeat/blob/master/vl/covdet.c#L874">vlfeat</a>.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the response map per channel with shape <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span><span class="p">]]])</span>  <span class="c1"># 1x1x7x7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># compute the response map</span>
<span class="go">harris_response(input, 0.04)</span>
<span class="go">tensor([[[[0.0012, 0.0039, 0.0020, 0.0000, 0.0020, 0.0039, 0.0012],</span>
<span class="go">          [0.0039, 0.0065, 0.0040, 0.0000, 0.0040, 0.0065, 0.0039],</span>
<span class="go">          [0.0020, 0.0040, 0.0029, 0.0000, 0.0029, 0.0040, 0.0020],</span>
<span class="go">          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],</span>
<span class="go">          [0.0020, 0.0040, 0.0029, 0.0000, 0.0029, 0.0040, 0.0020],</span>
<span class="go">          [0.0039, 0.0065, 0.0040, 0.0000, 0.0040, 0.0065, 0.0039],</span>
<span class="go">          [0.0012, 0.0039, 0.0020, 0.0000, 0.0020, 0.0039, 0.0012]]]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.hessian_response">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">hessian_response</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grads_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sobel'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigmas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.hessian_response" title="Link to this definition">¶</a></dt>
<dd><p>Compute the absolute of determinant of the Hessian matrix.</p>
<img alt="_images/hessian_response.png" src="_images/hessian_response.png" />
<p>Function does not do any normalization or nms. The response map is computed according the following formulation:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[R = det(H)\]</div>
</div>
<p>where:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}M = \sum_{(x,y) \in W}
\begin{bmatrix}
    I_{xx} &amp; I_{xy} \\
    I_{xy} &amp; I_{yy} \\
\end{bmatrix}\end{split}\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – input image with shape <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p></li>
<li><p><strong>grads_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – can be <code class="docutils literal notranslate"><span class="pre">'sobel'</span></code> for standalone use or <code class="docutils literal notranslate"><span class="pre">'diff'</span></code> for use on Gaussian pyramid.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;sobel&quot;</span></code></p></li>
<li><p><strong>sigmas</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – <p>coefficients to be multiplied by multichannel response. Should be shape of <span class="math notranslate nohighlight">\((B)\)</span>
It is necessary for performing non-maxima-suppression across different scale pyramid levels.
See <a class="reference external" href="https://github.com/vlfeat/vlfeat/blob/master/vl/covdet.c#L874">vlfeat</a>.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the response map per channel with shape <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, C, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span><span class="p">]]])</span>  <span class="c1"># 1x1x7x7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># compute the response map</span>
<span class="go">hessian_response(input)</span>
<span class="go">tensor([[[[0.0155, 0.0334, 0.0194, 0.0000, 0.0194, 0.0334, 0.0155],</span>
<span class="go">          [0.0334, 0.0575, 0.0339, 0.0000, 0.0339, 0.0575, 0.0334],</span>
<span class="go">          [0.0194, 0.0339, 0.0497, 0.0000, 0.0497, 0.0339, 0.0194],</span>
<span class="go">          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],</span>
<span class="go">          [0.0194, 0.0339, 0.0497, 0.0000, 0.0497, 0.0339, 0.0194],</span>
<span class="go">          [0.0334, 0.0575, 0.0339, 0.0000, 0.0339, 0.0575, 0.0334],</span>
<span class="go">          [0.0155, 0.0334, 0.0194, 0.0000, 0.0194, 0.0334, 0.0155]]]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.dog_response">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">dog_response</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.dog_response" title="Link to this definition">¶</a></dt>
<dd><p>Compute the Difference-of-Gaussian response.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – a given the gaussian 5d tensor <span class="math notranslate nohighlight">\((B, C, D, H, W)\)</span>.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the response map per channel with shape <span class="math notranslate nohighlight">\((B, C, D-1, H, W)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.dog_response_single">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">dog_response_single</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.6</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.dog_response_single" title="Link to this definition">¶</a></dt>
<dd><p>Compute the Difference-of-Gaussian response.</p>
<img alt="_images/dog_response_single.png" src="_images/dog_response_single.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – a given the gaussian 4d tensor <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p></li>
<li><p><strong>sigma1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – lower gaussian sigma
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
<li><p><strong>sigma2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – bigger gaussian sigma
Default:  <code class="code docutils literal notranslate"><span class="pre">1.6</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the response map per channel with shape <span class="math notranslate nohighlight">\((B, C, H, W)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.BlobHessian">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">BlobHessian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sobel'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.BlobHessian" title="Link to this definition">¶</a></dt>
<dd><p>Module that calculates Hessian blobs.</p>
<img alt="_images/hessian_response.png" src="_images/hessian_response.png" />
<p>See <a class="reference internal" href="#kornia.feature.hessian_response" title="kornia.feature.hessian_response"><code class="xref py py-func docutils literal notranslate"><span class="pre">hessian_response()</span></code></a> for details.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.CornerGFTT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">CornerGFTT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sobel'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.CornerGFTT" title="Link to this definition">¶</a></dt>
<dd><p>Module that calculates Shi-Tomasi corners.</p>
<img alt="_images/gftt_response.png" src="_images/gftt_response.png" />
<p>See <a class="reference internal" href="#kornia.feature.gftt_response" title="kornia.feature.gftt_response"><code class="xref py py-func docutils literal notranslate"><span class="pre">gftt_response()</span></code></a> for details.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.CornerHarris">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">CornerHarris</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grads_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sobel'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.CornerHarris" title="Link to this definition">¶</a></dt>
<dd><p>Module that calculates Harris corners.</p>
<img alt="_images/harris_response.png" src="_images/harris_response.png" />
<p>See <a class="reference internal" href="#kornia.feature.harris_response" title="kornia.feature.harris_response"><code class="xref py py-func docutils literal notranslate"><span class="pre">harris_response()</span></code></a> for details.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.BlobDoG">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">BlobDoG</span></span><a class="headerlink" href="#kornia.feature.BlobDoG" title="Link to this definition">¶</a></dt>
<dd><p>Module that calculates Difference-of-Gaussians blobs.</p>
<p>See
:func: <cite>~kornia.feature.dog_response</cite> for details.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.BlobDoGSingle">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">BlobDoGSingle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sigma1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.6</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.BlobDoGSingle" title="Link to this definition">¶</a></dt>
<dd><p>Module that calculates Difference-of-Gaussians blobs.</p>
<img alt="_images/dog_response_single.png" src="_images/dog_response_single.png" />
<p>See <a class="reference internal" href="#kornia.feature.dog_response_single" title="kornia.feature.dog_response_single"><code class="xref py py-func docutils literal notranslate"><span class="pre">dog_response_single()</span></code></a> for details.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.KeyNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">KeyNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keynet_conf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">keynet_default_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.KeyNet" title="Link to this definition">¶</a></dt>
<dd><p>Key.Net model definition – local feature detector (response function).</p>
<p>This is based on the original code
from paper “Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters”. See <span id="id3">[<a class="reference internal" href="community/bibliography.html#id23" title="Axel Barroso-Laguna, Edgar Riba, Daniel Ponsa, and Krystian Mikolajczyk. Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters. In ICCV. 2019.">BLRPM19</a>]</span> for
more details.</p>
<img alt="_images/KeyNet.png" src="_images/KeyNet.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Download and set pretrained weights to the model.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>keynet_conf</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">KeyNet_conf</span></code></span>, <em>optional</em>) – Dict with initialization parameters. Do not pass it, unless you know what you are doing`.
Default:  <code class="code docutils literal notranslate"><span class="pre">keynet_default_config</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>KeyNet response score.</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.MultiResolutionDetector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">MultiResolutionDetector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ori_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aff_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.MultiResolutionDetector" title="Link to this definition">¶</a></dt>
<dd><p>Multi-scale feature detector, based on code from KeyNet. Can be used with any response function.</p>
<p>This is based on the original code from paper
“Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters”.
See <span id="id4">[<a class="reference internal" href="community/bibliography.html#id23" title="Axel Barroso-Laguna, Edgar Riba, Daniel Ponsa, and Krystian Mikolajczyk. Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters. In ICCV. 2019.">BLRPM19</a>]</span> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – response function, such as KeyNet or BlobHessian</p></li>
<li><p><strong>num_features</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Number of features to detect.
Default:  <code class="code docutils literal notranslate"><span class="pre">2048</span></code></p></li>
<li><p><strong>conf</strong> – Dict with initialization parameters. Do not pass it, unless you know what you are doing`.</p></li>
<li><p><strong>ori_module</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – for local feature orientation estimation. Default: <a class="reference internal" href="#kornia.feature.PassLAF" title="kornia.feature.PassLAF"><code class="xref py py-class docutils literal notranslate"><span class="pre">PassLAF</span></code></a>,
which does nothing. See <a class="reference internal" href="#kornia.feature.LAFOrienter" title="kornia.feature.LAFOrienter"><code class="xref py py-class docutils literal notranslate"><span class="pre">LAFOrienter</span></code></a> for details.</p></li>
<li><p><strong>aff_module</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – for local feature affine shape estimation. Default: <a class="reference internal" href="#kornia.feature.PassLAF" title="kornia.feature.PassLAF"><code class="xref py py-class docutils literal notranslate"><span class="pre">PassLAF</span></code></a>,
which does nothing. See <a class="reference internal" href="#kornia.feature.LAFAffineShapeEstimator" title="kornia.feature.LAFAffineShapeEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">LAFAffineShapeEstimator</span></code></a> for details.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.MultiResolutionDetector.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.MultiResolutionDetector.forward" title="Link to this definition">¶</a></dt>
<dd><p>Three stage local feature detection.</p>
<p>First the location and scale of interest points are determined by detect function.
Then affine shape and orientation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,</p>
</dd>
</dl>
<dl class="simple">
<dt>because the number of detections is different on each image.</dt><dd><dl class="simple">
<dt>mask: a mask with weights where to apply the response function. The shape must be the same as</dt><dd><p>the input image.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>shape [1xNx2x3]. Detected local affine frames.
responses: shape [1xNx1]. Response function values for corresponding lafs</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>lafs</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.MultiResolutionDetector.remove_borders">
<span class="sig-name descname"><span class="pre">remove_borders</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score_map</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">borders</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">15</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.MultiResolutionDetector.remove_borders" title="Link to this definition">¶</a></dt>
<dd><p>Remove the borders of the image to avoid detections on the corners.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.ScaleSpaceDetector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">ScaleSpaceDetector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mr_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_pyr_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resp_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nms_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ori_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aff_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minima_are_also_good</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_space_response</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.ScaleSpaceDetector" title="Link to this definition">¶</a></dt>
<dd><p>Module for differentiable local feature detection.</p>
<p>As close as possible to classical local feature detectors
like Harris, Hessian-Affine or SIFT (DoG).</p>
<p>It has 5 modules inside: scale pyramid generator, response (“cornerness”) function,
soft nms function, affine shape estimator and patch orientation estimator.
Each of those modules could be replaced with learned custom one, as long, as
they respect output shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Number of features to detect. In order to keep everything batchable,
output would always have num_features output, even for completely homogeneous images.
Default:  <code class="code docutils literal notranslate"><span class="pre">500</span></code></p></li>
<li><p><strong>mr_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – multiplier for local feature scale compared to the detection scale.
6.0 is matching OpenCV 12.0 convention for SIFT.
Default:  <code class="code docutils literal notranslate"><span class="pre">6.0</span></code></p></li>
<li><p><strong>scale_pyr_module</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – generates scale pyramid. See <code class="xref py py-class docutils literal notranslate"><span class="pre">ScalePyramid</span></code> for details.
Default: ScalePyramid(3, 1.6, 10).</p></li>
<li><p><strong>resp_module</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – calculates <code class="docutils literal notranslate"><span class="pre">'cornerness'</span></code> of the pixel.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>nms_module</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – outputs per-patch coordinates of the response maxima.
See <code class="xref py py-class docutils literal notranslate"><span class="pre">ConvSoftArgmax3d</span></code> for details.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>ori_module</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – for local feature orientation estimation. Default:class:<cite>~kornia.feature.PassLAF</cite>,
which does nothing. See <a class="reference internal" href="#kornia.feature.LAFOrienter" title="kornia.feature.LAFOrienter"><code class="xref py py-class docutils literal notranslate"><span class="pre">LAFOrienter</span></code></a> for details.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>aff_module</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – for local feature affine shape estimation. Default: <a class="reference internal" href="#kornia.feature.PassLAF" title="kornia.feature.PassLAF"><code class="xref py py-class docutils literal notranslate"><span class="pre">PassLAF</span></code></a>,
which does nothing. See <a class="reference internal" href="#kornia.feature.LAFAffineShapeEstimator" title="kornia.feature.LAFAffineShapeEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">LAFAffineShapeEstimator</span></code></a> for details.</p></li>
<li><p><strong>minima_are_also_good</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if True, then both response function minima and maxima are detected
Useful for symmetric response functions like DoG or Hessian. Default is False
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.ScaleSpaceDetector.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.ScaleSpaceDetector.forward" title="Link to this definition">¶</a></dt>
<dd><p>Three stage local feature detection.</p>
<p>First the location and scale of interest points are determined by detect function.
Then affine shape and orientation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – image to extract features with shape [BxCxHxW]</p></li>
<li><p><strong>mask</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – a mask with weights where to apply the response function. The shape must be the same as
the input image.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>shape [BxNx2x3]. Detected local affine frames.
responses: shape [BxNx1]. Response function values for corresponding lafs</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>lafs</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.KeyNetDetector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">KeyNetDetector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keynet_conf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">keynet_default_config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ori_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aff_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.KeyNetDetector" title="Link to this definition">¶</a></dt>
<dd><p>Multi-scale feature detector based on KeyNet.</p>
<p>This is based on the original code from paper
“Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters”.
See <span id="id5">[<a class="reference internal" href="community/bibliography.html#id23" title="Axel Barroso-Laguna, Edgar Riba, Daniel Ponsa, and Krystian Mikolajczyk. Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters. In ICCV. 2019.">BLRPM19</a>]</span> for more details.</p>
<img alt="_images/keynet.jpg" src="_images/keynet.jpg" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Download and set pretrained weights to the model.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>num_features</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Number of features to detect.
Default:  <code class="code docutils literal notranslate"><span class="pre">2048</span></code></p></li>
<li><p><strong>keynet_conf</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">KeyNet_conf</span></code></span>, <em>optional</em>) – Dict with initialization parameters. Do not pass it, unless you know what you are doing`.
Default:  <code class="code docutils literal notranslate"><span class="pre">keynet_default_config</span></code></p></li>
<li><p><strong>ori_module</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – for local feature orientation estimation. Default: <a class="reference internal" href="#kornia.feature.PassLAF" title="kornia.feature.PassLAF"><code class="xref py py-class docutils literal notranslate"><span class="pre">PassLAF</span></code></a>,
which does nothing. See <a class="reference internal" href="#kornia.feature.LAFOrienter" title="kornia.feature.LAFOrienter"><code class="xref py py-class docutils literal notranslate"><span class="pre">LAFOrienter</span></code></a> for details.</p></li>
<li><p><strong>aff_module</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – for local feature affine shape estimation. Default: <a class="reference internal" href="#kornia.feature.PassLAF" title="kornia.feature.PassLAF"><code class="xref py py-class docutils literal notranslate"><span class="pre">PassLAF</span></code></a>,
which does nothing. See <a class="reference internal" href="#kornia.feature.LAFAffineShapeEstimator" title="kornia.feature.LAFAffineShapeEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">LAFAffineShapeEstimator</span></code></a> for details.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.KeyNetDetector.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.KeyNetDetector.forward" title="Link to this definition">¶</a></dt>
<dd><p>Three stage local feature detection.</p>
<p>First the location and scale of interest points are determined by detect function.
Then affine shape and orientation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,</p>
</dd>
</dl>
<dl class="simple">
<dt>because the number of detections is different on each image.</dt><dd><dl class="simple">
<dt>mask: a mask with weights where to apply the response function. The shape must be the same as</dt><dd><p>the input image.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>shape [1xNx2x3]. Detected local affine frames.
responses: shape [1xNx1]. Response function values for corresponding lafs</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>lafs</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="descriptors">
<h2>Descriptors<a class="headerlink" href="#descriptors" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.DenseSIFTDescriptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">DenseSIFTDescriptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_ang_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_spatial_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_bin_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rootsift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clipval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DenseSIFTDescriptor" title="Link to this definition">¶</a></dt>
<dd><p>Module, which computes SIFT descriptor densely over the image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_ang_bins</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Number of angular bins. (8 is default)
Default:  <code class="code docutils literal notranslate"><span class="pre">8</span></code></p></li>
<li><p><strong>num_spatial_bins</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Number of spatial bins per descriptor (4 is default).
Default:  <code class="code docutils literal notranslate"><span class="pre">4</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>You might want to set odd number and relevant padding to keep feature map size</dt><dd><p>spatial_bin_size: Size of a spatial bin in pixels (4 is default)
clipval: clipping value to reduce single-bin dominance
rootsift: (bool) if True, RootSIFT (Arandjelović et. al, 2012) is computed
stride: default 1
padding: default 0</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>DenseSIFT descriptor of the image</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: (B, 1, H, W)</p></li>
<li><p>Output: (B, num_ang_bins * num_spatial_bins ** 2, (H+padding)/stride, (W+padding)/stride)</p></li>
</ul>
</dd>
<dt>Examples::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span>  <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SIFT</span> <span class="o">=</span> <span class="n">DenseSIFTDescriptor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descs</span> <span class="o">=</span> <span class="n">SIFT</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># 2x128x194x294</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.SIFTDescriptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">SIFTDescriptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">41</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ang_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_spatial_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rootsift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clipval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.SIFTDescriptor" title="Link to this definition">¶</a></dt>
<dd><p>Module which computes SIFT descriptors of given patches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patch_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Input patch size in pixels.
Default:  <code class="code docutils literal notranslate"><span class="pre">41</span></code></p></li>
<li><p><strong>num_ang_bins</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Number of angular bins.
Default:  <code class="code docutils literal notranslate"><span class="pre">8</span></code></p></li>
<li><p><strong>num_spatial_bins</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Number of spatial bins.
Default:  <code class="code docutils literal notranslate"><span class="pre">4</span></code></p></li>
<li><p><strong>clipval</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – clipping value to reduce single-bin dominance
Default:  <code class="code docutils literal notranslate"><span class="pre">0.2</span></code></p></li>
<li><p><strong>rootsift</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, RootSIFT (Arandjelović et. al, 2012) is computed.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SIFT descriptor of the patches with shape.</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((B, 1, \text{num_spatial_bins}, \text{num_spatial_bins})\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, \text{num_ang_bins * num_spatial_bins ** 2})\)</span></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">23</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SIFT</span> <span class="o">=</span> <span class="n">SIFTDescriptor</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descs</span> <span class="o">=</span> <span class="n">SIFT</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># 23x128</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.MKDDescriptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">MKDDescriptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'concat'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">whitening</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'pcawt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'liberty'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.MKDDescriptor" title="Link to this definition">¶</a></dt>
<dd><p>Module that computes Multiple Kernel local descriptors.</p>
<p>This is based on the paper “Understanding and Improving Kernel Local Descriptors”.
See <span id="id6">[<a class="reference internal" href="community/bibliography.html#id12" title="Arun Mukundan, Giorgos Tolias, Andrei Bursuc, Hervé Jégou, and Ondřej Chum. Understanding and improving kernel local descriptors. International Journal of Computer Vision, 2019.">MTB+19</a>]</span> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patch_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Input patch size in pixels.
Default:  <code class="code docutils literal notranslate"><span class="pre">32</span></code></p></li>
<li><p><strong>kernel_type</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – Parametrization of kernel <code class="docutils literal notranslate"><span class="pre">'concat'</span></code>, <code class="docutils literal notranslate"><span class="pre">'cart'</span></code>, <code class="docutils literal notranslate"><span class="pre">'polar'</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;concat&quot;</span></code></p></li>
<li><p><strong>whitening</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – Whitening transform to apply <code class="docutils literal notranslate"><span class="pre">None</span></code>, <code class="docutils literal notranslate"><span class="pre">'lw'</span></code>, <code class="docutils literal notranslate"><span class="pre">'pca'</span></code>, <code class="docutils literal notranslate"><span class="pre">'pcawt'</span></code>, <code class="docutils literal notranslate"><span class="pre">'pcaws'</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;pcawt&quot;</span></code></p></li>
<li><p><strong>training_set</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – Set that model was trained on <code class="docutils literal notranslate"><span class="pre">'liberty'</span></code>, <code class="docutils literal notranslate"><span class="pre">'notredame'</span></code>, <code class="docutils literal notranslate"><span class="pre">'yosemite'</span></code>.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;liberty&quot;</span></code></p></li>
<li><p><strong>output_dims</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Dimensionality reduction.
Default:  <code class="code docutils literal notranslate"><span class="pre">128</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explicit cartesian or polar embedding.</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((B, in_{dims}, fmap_{size}, fmap_{size})\)</span>.</p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, out_{dims}, fmap_{size}, fmap_{size})\)</span>,</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">patches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">23</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mkd</span> <span class="o">=</span> <span class="n">MKDDescriptor</span><span class="p">(</span><span class="n">patch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">kernel_type</span><span class="o">=</span><span class="s1">&#39;concat&#39;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">whitening</span><span class="o">=</span><span class="s1">&#39;pcawt&#39;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">training_set</span><span class="o">=</span><span class="s1">&#39;liberty&#39;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">output_dims</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">desc</span> <span class="o">=</span> <span class="n">mkd</span><span class="p">(</span><span class="n">patches</span><span class="p">)</span> <span class="c1"># 23x128</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.HardNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">HardNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.HardNet" title="Link to this definition">¶</a></dt>
<dd><p>Module, which computes HardNet descriptors of given grayscale patches of 32x32.</p>
<p>This is based on the original code from paper “Working hard to know your neighbor’s
margins: Local descriptor learning loss”. See <span id="id7">[<a class="reference internal" href="community/bibliography.html#id6" title="Anastasiya Mishchuk, Dmytro Mishkin, Filip Radenovic, and Jiri Matas. Working hard to know your neighbor's margins: local descriptor learning loss. In Proceedings of NeurIPS. 2017.">MMRM17</a>]</span> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Download and set pretrained weights to the model.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>HardNet descriptor of the patches.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)">torch.Tensor</a></p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((B, 1, 32, 32)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, 128)\)</span></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hardnet</span> <span class="o">=</span> <span class="n">HardNet</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descs</span> <span class="o">=</span> <span class="n">hardnet</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># 16x128</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.HardNet8">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">HardNet8</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.HardNet8" title="Link to this definition">¶</a></dt>
<dd><p>Module, which computes HardNet8 descriptors of given grayscale patches of 32x32.</p>
<p>This is based on the original code from paper “Improving the HardNet Descriptor”.
See <span id="id8">[<a class="reference internal" href="community/bibliography.html#id7" title="Milan Pultar. Improving the hardnet descriptor. arXiv ePrint 2007.09699, 2020.">Pul20</a>]</span> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Download and set pretrained weights to the model.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>HardNet8 descriptor of the patches.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)">torch.Tensor</a></p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((B, 1, 32, 32)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, 128)\)</span></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hardnet</span> <span class="o">=</span> <span class="n">HardNet8</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descs</span> <span class="o">=</span> <span class="n">hardnet</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># 16x128</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.HyNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">HyNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_bias_FRN</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim_desc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_l2_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.HyNet" title="Link to this definition">¶</a></dt>
<dd><p>Module, which computes HyNet descriptors of given grayscale patches of 32x32.</p>
<p>This is based on the original code from paper
“HyNet: Learning Local Descriptor with Hybrid Similarity Measure and Triplet Loss”.
See <span id="id9">[<a class="reference internal" href="community/bibliography.html#id10" title="Yurun Tian, Axel Barroso Laguna, Tony Ng, Vassileios Balntas, and Krystian Mikolajczyk. Hynet: learning local descriptor with hybrid similarity measure and triplet loss. In NeurIPS. 2020.">TBLN+20</a>]</span> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Download and set pretrained weights to the model.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>is_bias</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – use bias in TLU layers
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>is_bias_FRN</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – use bias in FRN layers
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>dim_desc</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – descriptor dimensionality,
Default:  <code class="code docutils literal notranslate"><span class="pre">128</span></code></p></li>
<li><p><strong>drop_rate</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – dropout rate,
Default:  <code class="code docutils literal notranslate"><span class="pre">0.3</span></code></p></li>
<li><p><strong>eps_l2_norm</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – to avoid div by zero
Default:  <code class="code docutils literal notranslate"><span class="pre">1e-10</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>HyNet descriptor of the patches.</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((B, 1, 32, 32)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, 128)\)</span></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hynet</span> <span class="o">=</span> <span class="n">HyNet</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descs</span> <span class="o">=</span> <span class="n">hynet</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># 16x128</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.TFeat">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">TFeat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.TFeat" title="Link to this definition">¶</a></dt>
<dd><p>Module, which computes TFeat descriptors of given grayscale patches of 32x32.</p>
<p>This is based on the original code from paper “Learning local feature descriptors
with triplets and shallow convolutional neural networks”.
See <span id="id10">[<a class="reference internal" href="community/bibliography.html#id11" title="Vassileios Balntas, Edgar Riba, Daniel Ponsa, and Krystian Mikolajczyk. Learning local feature descriptors with triplets and shallow convolutional neural networks. In British Machine Vision Conference (BMVC). 2016.">BRPM16</a>]</span> for more details</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Download and set pretrained weights to the model.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>TFeat descriptor of the patches.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)">torch.Tensor</a></p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((B, 1, 32, 32)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, 128)\)</span></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tfeat</span> <span class="o">=</span> <span class="n">TFeat</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descs</span> <span class="o">=</span> <span class="n">tfeat</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># 16x128</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.SOSNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">SOSNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.SOSNet" title="Link to this definition">¶</a></dt>
<dd><p>128-dimensional SOSNet model definition for 32x32 patches.</p>
<p>This is based on the original code from paper
“SOSNet:Second Order Similarity Regularization for Local Descriptor Learning”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Download and set pretrained weights to the model.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((B, 1, 32, 32)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, 128)\)</span></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sosnet</span> <span class="o">=</span> <span class="n">SOSNet</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descs</span> <span class="o">=</span> <span class="n">sosnet</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># 8x128</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.LAFDescriptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">LAFDescriptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch_descriptor_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grayscale_descriptor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LAFDescriptor" title="Link to this definition">¶</a></dt>
<dd><p>Module to get local descriptors, corresponding to LAFs (keypoints).</p>
<p>Internally uses <a class="reference internal" href="#kornia.feature.get_laf_descriptors" title="kornia.feature.get_laf_descriptors"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_laf_descriptors()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patch_descriptor_module</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – patch descriptor module, e.g. <a class="reference internal" href="#kornia.feature.SIFTDescriptor" title="kornia.feature.SIFTDescriptor"><code class="xref py py-class docutils literal notranslate"><span class="pre">SIFTDescriptor</span></code></a>
or <a class="reference internal" href="#kornia.feature.HardNet" title="kornia.feature.HardNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">HardNet</span></code></a>. Default: <a class="reference internal" href="#kornia.feature.HardNet" title="kornia.feature.HardNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">HardNet</span></code></a>.</p></li>
<li><p><strong>patch_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – patch size in pixels, which descriptor expects.
Default:  <code class="code docutils literal notranslate"><span class="pre">32</span></code></p></li>
<li><p><strong>grayscale_descriptor</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – <code class="docutils literal notranslate"><span class="pre">True</span></code> if patch_descriptor expects single-channel image.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.LAFDescriptor.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lafs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LAFDescriptor.forward" title="Link to this definition">¶</a></dt>
<dd><p>Three stage local feature detection.</p>
<p>First the location and scale of interest points are determined by
detect function. Then affine shape and orientation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – image features with shape <span class="math notranslate nohighlight">\((B,C,H,W)\)</span>.</p></li>
<li><p><strong>lafs</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – local affine frames <span class="math notranslate nohighlight">\((B,N,2,3)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Local descriptors of shape <span class="math notranslate nohighlight">\((B,N,D)\)</span> where <span class="math notranslate nohighlight">\(D\)</span> is descriptor size.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.SOLD2">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">SOLD2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.SOLD2" title="Link to this definition">¶</a></dt>
<dd><p>Module, which detects and describe line segments in an image.</p>
<p>This is based on the original code from the paper “SOLD²: Self-supervised
Occlusion-aware Line Detector and Descriptor”. See <span id="id11">[<a class="reference internal" href="community/bibliography.html#id26" title="Rémi Pautrat*, Juan-Ting Lin*, Viktor Larsson, Martin R. Oswald, and Marc Pollefeys. Sold2: self-supervised occlusion-aware line description and detection. In Computer Vision and Pattern Recognition (CVPR). 2021.">PautratLinL+21</a>]</span> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">DetectorCfg</span></code>]</span>, <em>optional</em>) – Dict specifying parameters. None will load the default parameters,
which are tuned for images in the range 400~800 px.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – If True, download and set pretrained weights to the model.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The raw junction and line heatmaps, the semi-dense descriptor map,
as well as the list of detected line segments (ij coordinates convention).</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sold2</span> <span class="o">=</span> <span class="n">SOLD2</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">sold2</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">line_seg1</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;line_segments&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">line_seg2</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;line_segments&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">desc1</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;dense_desc&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">desc2</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;dense_desc&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matches</span> <span class="o">=</span> <span class="n">sold2</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">line_seg1</span><span class="p">,</span> <span class="n">line_seg2</span><span class="p">,</span> <span class="n">desc1</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">desc2</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.SOLD2.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.SOLD2.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – batched images with shape <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of N line segments in each of the B images <span class="math notranslate nohighlight">\(List[(N, 2, 2)]\)</span>.
junction_heatmap: raw junction heatmap of shape <span class="math notranslate nohighlight">\((B, H, W)\)</span>.
line_heatmap: raw line heatmap of shape <span class="math notranslate nohighlight">\((B, H, W)\)</span>.
dense_desc: the semi-dense descriptor map of shape <span class="math notranslate nohighlight">\((B, 128, H/4, W/4)\)</span>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>line_segments</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.get_laf_descriptors">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">get_laf_descriptors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lafs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_descriptor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grayscale_descriptor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.get_laf_descriptors" title="Link to this definition">¶</a></dt>
<dd><p>Get local descriptors, corresponding to LAFs (keypoints).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – image features with shape <span class="math notranslate nohighlight">\((B,C,H,W)\)</span>.</p></li>
<li><p><strong>lafs</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – local affine frames <span class="math notranslate nohighlight">\((B,N,2,3)\)</span>.</p></li>
<li><p><strong>patch_descriptor</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – patch descriptor module, e.g. <a class="reference internal" href="#kornia.feature.SIFTDescriptor" title="kornia.feature.SIFTDescriptor"><code class="xref py py-class docutils literal notranslate"><span class="pre">SIFTDescriptor</span></code></a>
or <a class="reference internal" href="#kornia.feature.HardNet" title="kornia.feature.HardNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">HardNet</span></code></a>.</p></li>
<li><p><strong>patch_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – patch size in pixels, which descriptor expects.
Default:  <code class="code docutils literal notranslate"><span class="pre">32</span></code></p></li>
<li><p><strong>grayscale_descriptor</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – True if <code class="docutils literal notranslate"><span class="pre">patch_descriptor</span></code> expects single-channel image.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Local descriptors of shape <span class="math notranslate nohighlight">\((B,N,D)\)</span> where <span class="math notranslate nohighlight">\(D\)</span> is descriptor size.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="local-features-detector-and-descriptors-together">
<h2>Local Features (Detector and Descriptors together)<a class="headerlink" href="#local-features-detector-and-descriptors-together" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.LocalFeature">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">LocalFeature</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">detector</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">descriptor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaling_coef</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LocalFeature" title="Link to this definition">¶</a></dt>
<dd><p>Module, which combines local feature detector and descriptor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>detector</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – the detection module.</p></li>
<li><p><strong>descriptor</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#kornia.feature.LAFDescriptor" title="kornia.feature.integrated.LAFDescriptor"><code class="xref py py-class docutils literal notranslate"><span class="pre">LAFDescriptor</span></code></a></span>) – the descriptor module.</p></li>
<li><p><strong>scaling_coef</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – multiplier for change default detector scale (e.g. it is too small for KeyNet by default)
Default:  <code class="code docutils literal notranslate"><span class="pre">1.0</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.LocalFeature.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LocalFeature.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – image to extract features with shape <span class="math notranslate nohighlight">\((B,C,H,W)\)</span>.</p></li>
<li><p><strong>mask</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – a mask with weights where to apply the response function.
The shape must be the same as the input image.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Detected local affine frames with shape <span class="math notranslate nohighlight">\((B,N,2,3)\)</span>.</p></li>
<li><p>Response function values for corresponding lafs with shape <span class="math notranslate nohighlight">\((B,N,1)\)</span>.</p></li>
<li><p>Local descriptors of shape <span class="math notranslate nohighlight">\((B,N,D)\)</span> where <span class="math notranslate nohighlight">\(D\)</span> is descriptor size.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.SOLD2_detector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">SOLD2_detector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.SOLD2_detector" title="Link to this definition">¶</a></dt>
<dd><p>Module, which detects line segments in an image.</p>
<p>This is based on the original code from the paper “SOLD²: Self-supervised
Occlusion-aware Line Detector and Descriptor”. See <span id="id12">[<a class="reference internal" href="community/bibliography.html#id26" title="Rémi Pautrat*, Juan-Ting Lin*, Viktor Larsson, Martin R. Oswald, and Marc Pollefeys. Sold2: self-supervised occlusion-aware line description and detection. In Computer Vision and Pattern Recognition (CVPR). 2021.">PautratLinL+21</a>]</span> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<em>DetectorCfg</em>) – Configuration object containing all parameters. None will load the default parameters,
which are tuned for images in the range 400~800 px. Using a dataclass ensures type safety and clearer
parameter management.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>pretrained</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If True, download and set pretrained weights to the model.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The raw junction and line heatmaps, as well as the list of detected line segments (ij coordinates convention).</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sold2_detector</span> <span class="o">=</span> <span class="n">SOLD2_detector</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">line_segments</span> <span class="o">=</span> <span class="n">sold2_detector</span><span class="p">(</span><span class="n">img</span><span class="p">)[</span><span class="s2">&quot;line_segments&quot;</span><span class="p">]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.SOLD2_detector.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.SOLD2_detector.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – batched images with shape <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of N line segments in each of the B images <span class="math notranslate nohighlight">\(List[(N, 2, 2)]\)</span>.
junction_heatmap: raw junction heatmap of shape <span class="math notranslate nohighlight">\((B, H, W)\)</span>.
line_heatmap: raw line heatmap of shape <span class="math notranslate nohighlight">\((B, H, W)\)</span>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>line_segments</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.DeDoDe">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">DeDoDe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">detector_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'L'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">descriptor_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'G'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.float16</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DeDoDe" title="Link to this definition">¶</a></dt>
<dd><p>Module which detects and/or describes local features in an image using the DeDode method.</p>
<p>See <span id="id13">[<a class="reference internal" href="community/bibliography.html#id40" title="Johan Edstedt, Georg Bökman, Mårten Wadenbäck, and Michael Felsberg. DeDoDe: Detect, Don't Describe — Describe, Don't Detect for Local Feature Matching. In 2024 International Conference on 3D Vision (3DV). 2024.">EBWF24</a>]</span> for details.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>DeDode takes ImageNet normalized images as input (not in range [0, 1]).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>detector_model</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code></a>[<code class="docutils literal notranslate"><span class="pre">'L'</span></code>]</span>, <em>optional</em>) – The detector model kind. Available options are: <cite>L</cite>.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;L&quot;</span></code></p></li>
<li><p><strong>descriptor_model</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code></a>[<code class="docutils literal notranslate"><span class="pre">'G'</span></code>, <code class="docutils literal notranslate"><span class="pre">'B'</span></code>]</span>, <em>optional</em>) – The descriptor model kind. Available options are: <cite>G</cite> or <cite>B</cite>
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;G&quot;</span></code></p></li>
<li><p><strong>amp_dtype</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dtype</span></code></a></span>, <em>optional</em>) – The automatic mixed precision desired.
Default:  <code class="code docutils literal notranslate"><span class="pre">torch.float16</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dedode</span> <span class="o">=</span> <span class="n">DeDoDe</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">detector_weights</span><span class="o">=</span><span class="s2">&quot;L-C4-v2&quot;</span><span class="p">,</span> <span class="n">descriptor_weights</span><span class="o">=</span><span class="s2">&quot;B-upright&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keypoints</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">dedode</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descriptions</span> <span class="o">=</span> <span class="n">dedode</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">keypoints</span> <span class="o">=</span> <span class="n">keypoints</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keypoints</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="n">dedode</span><span class="p">(</span><span class="n">images</span><span class="p">)</span> <span class="c1"># alternatively do both</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.DeDoDe.describe">
<span class="sig-name descname"><span class="pre">describe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keypoints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apply_imagenet_normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DeDoDe.describe" title="Link to this definition">¶</a></dt>
<dd><p>Describe keypoints in the input images. If keypoints are not provided, returns the dense descriptors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>images</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – A tensor of shape <span class="math notranslate nohighlight">\((B, 3, H, W)\)</span> containing the input images.</p></li>
<li><p><strong>keypoints</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – An optional tensor of shape <span class="math notranslate nohighlight">\((B, N, 2)\)</span> containing the detected keypoints.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>apply_imagenet_normalization</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Whether to apply ImageNet normalization to the input images.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of shape <span class="math notranslate nohighlight">\((B, N, DIM)\)</span> containing the descriptions of the detected keypoints.
If the dense descriptors are requested, the shape is <span class="math notranslate nohighlight">\((B, DIM, H, W)\)</span>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>descriptions</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.DeDoDe.detect">
<span class="sig-name descname"><span class="pre">detect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apply_imagenet_normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_if_not_divisible</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_h</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_w</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DeDoDe.detect" title="Link to this definition">¶</a></dt>
<dd><p>Detect keypoints in the input images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>images</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – A tensor of shape <span class="math notranslate nohighlight">\((B, 3, H, W)\)</span> containing the input images.</p></li>
<li><p><strong>n</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – The number of keypoints to detect.
Default:  <code class="code docutils literal notranslate"><span class="pre">10000</span></code></p></li>
<li><p><strong>apply_imagenet_normalization</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Whether to apply ImageNet normalization to the input images.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>pad_if_not_divisible</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – pad image shape if not evenly divisible.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>crop_h</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – The height of the crop to be used for detection. If None, the full image is used.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>crop_w</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – The width of the crop to be used for detection. If None, the full image is used.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of shape <span class="math notranslate nohighlight">\((B, N, 2)\)</span> containing the detected keypoints,
normalized to the range <span class="math notranslate nohighlight">\([-1, 1]\)</span>.
scores: A tensor of shape <span class="math notranslate nohighlight">\((B, N)\)</span> containing the scores of the detected keypoints.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>keypoints</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.DeDoDe.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10_000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apply_imagenet_normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_if_not_divisible</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DeDoDe.forward" title="Link to this definition">¶</a></dt>
<dd><p>Detect and describe keypoints in the input images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>images</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – A tensor of shape <span class="math notranslate nohighlight">\((B, 3, H, W)\)</span> containing the ImageNet-Normalized input images.</p></li>
<li><p><strong>n</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – The number of keypoints to detect.
Default:  <code class="code docutils literal notranslate"><span class="pre">10_000</span></code></p></li>
<li><p><strong>apply_imagenet_normalization</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Whether to apply ImageNet normalization to the input images.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>pad_if_not_divisible</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – pad image shape if not evenly divisible.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of shape <span class="math notranslate nohighlight">\((B, N, 2)\)</span> containing the detected keypoints in the image range,
unlike <cite>.detect()</cite> function
scores: A tensor of shape <span class="math notranslate nohighlight">\((B, N)\)</span> containing the scores of the detected keypoints.
descriptions: A tensor of shape <span class="math notranslate nohighlight">\((B, N, DIM)\)</span> containing the descriptions of the detected keypoints.
DIM is 256 for B and 512 for G.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>keypoints</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.DeDoDe.from_pretrained">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">detector_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'L-C4-v2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">descriptor_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'G-upright'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.float16</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DeDoDe.from_pretrained" title="Link to this definition">¶</a></dt>
<dd><p>Load a pretrained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>detector_weights</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – The weights to load for the detector.
One of ‘L-upright’ (original paper, <a class="reference external" href="https://arxiv.org/abs/2308.08479">https://arxiv.org/abs/2308.08479</a>),
‘L-C4’, ‘L-SO2’ (from steerers, better for rotations, <a class="reference external" href="https://arxiv.org/abs/2312.02152">https://arxiv.org/abs/2312.02152</a>),
‘L-C4-v2’ (from dedode v2, better at rotations, less clustering, <a class="reference external" href="https://arxiv.org/abs/2404.08928">https://arxiv.org/abs/2404.08928</a>)
Default is ‘L-C4-v2’, but perhaps it should be ‘L-C4-v2’?
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;L-C4-v2&quot;</span></code></p></li>
<li><p><strong>descriptor_weights</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – The weights to load for the descriptor.
One of ‘B-upright’,’G-upright’ (original paper, <a class="reference external" href="https://arxiv.org/abs/2308.08479">https://arxiv.org/abs/2308.08479</a>),
‘B-C4’, ‘B-SO2’, ‘G-C4’, ‘G-SO2’ (from steerers, better for rotations, <a class="reference external" href="https://arxiv.org/abs/2312.02152">https://arxiv.org/abs/2312.02152</a>).
Default is ‘G-upright’.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;G-upright&quot;</span></code></p></li>
<li><p><strong>amp_dtype</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dtype</span></code></a></span>, <em>optional</em>) – the dtype to use for the model. One of torch.float16 or torch.float32.
Default:  <code class="code docutils literal notranslate"><span class="pre">torch.float16</span></code></p></li>
<li><p><strong>torch.float16</strong> (<em>Default is</em>)</p></li>
<li><p><strong>MPS</strong> (<em>suitable for CUDA. Use torch.float32 for CPU or</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The pretrained model.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.DISK">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">DISK</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desc_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unet</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DISK" title="Link to this definition">¶</a></dt>
<dd><p>Module which detects and described local features in an image using the DISK method.</p>
<p>See <span id="id14">[<a class="reference internal" href="community/bibliography.html#id39" title="Michał Tyszkiewicz, Pascal Fua, and Eduard Trulls. Disk: learning local features with policy gradient. Advances in Neural Information Processing Systems, 33:14254–14265, 2020.">TFT20</a>]</span> for details.</p>
<img alt="_images/disk_outdoor_depth.jpg" src="_images/disk_outdoor_depth.jpg" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desc_dim</strong> (<span class="sphinx_autodoc_typehints-type">int</span>, <em>optional</em>) – The dimension of the descriptor.
Default:  <code class="code docutils literal notranslate"><span class="pre">128</span></code></p></li>
<li><p><strong>unet</strong> (<span class="sphinx_autodoc_typehints-type">None | Module</span>, <em>optional</em>) – The U-Net to use. If None, a default U-Net is used. Kornia doesn’t provide the training code for DISK
so this is only useful when using a custom checkpoint trained using the code released with the paper.
The unet should take as input a tensor of shape <span class="math notranslate nohighlight">\((B, C, H, W)\)</span> and output a tensor of shape
<span class="math notranslate nohighlight">\((B, \mathrm{desc\_dim} + 1, H, W)\)</span>.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">disk</span> <span class="o">=</span> <span class="n">DISK</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;depth&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">features</span> <span class="o">=</span> <span class="n">disk</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.DISK.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_if_not_divisible</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DISK.forward" title="Link to this definition">¶</a></dt>
<dd><p>Detect features in an image, returning keypoint locations, descriptors and detection scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>images</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The image to detect features in. Shape <span class="math notranslate nohighlight">\((B, 3, H, W)\)</span>.</p></li>
<li><p><strong>n</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>, <em>optional</em>) – The maximum number of keypoints to detect. If None, all keypoints are returned.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>window_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – The size of the non-maxima suppression window used to filter detections.
Default:  <code class="code docutils literal notranslate"><span class="pre">5</span></code></p></li>
<li><p><strong>score_threshold</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – The minimum score a detection must have to be returned.
See <a class="reference internal" href="#kornia.feature.DISKFeatures" title="kornia.feature.DISKFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">DISKFeatures</span></code></a> for details.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
<li><p><strong>pad_if_not_divisible</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if True, the non-16 divisible input is zero-padded to the closest 16-multiply
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>[<a class="reference internal" href="#kornia.feature.DISKFeatures" title="kornia.feature.disk.structs.DISKFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">DISKFeatures</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list of length <span class="math notranslate nohighlight">\(B\)</span> containing the detected features.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.DISK.from_pretrained">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'depth'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DISK.from_pretrained" title="Link to this definition">¶</a></dt>
<dd><p>Load a pretrained model.</p>
<p>Depth model was trained using depth map supervision and is slightly more precise but biased to detect keypoints
only where SfM depth is available. Epipolar model was trained using epipolar geometry supervision and
is less precise but detects keypoints everywhere where they are matchable. The difference is especially
pronounced on thin structures and on edges of objects.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – The checkpoint to load. One of ‘depth’ or ‘epipolar’.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;depth&quot;</span></code></p></li>
<li><p><strong>device</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></a>]</span>, <em>optional</em>) – The device to load the model to.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#kornia.feature.DISK" title="kornia.feature.disk.disk.DISK"><code class="xref py py-class docutils literal notranslate"><span class="pre">DISK</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The pretrained model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.DISK.heatmap_and_dense_descriptors">
<span class="sig-name descname"><span class="pre">heatmap_and_dense_descriptors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DISK.heatmap_and_dense_descriptors" title="Link to this definition">¶</a></dt>
<dd><p>Return the heatmap and the dense descriptors.</p>
<img alt="_images/DISK.png" src="_images/DISK.png" />
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>images</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – The image to detect features in. Shape <span class="math notranslate nohighlight">\((B, 3, H, W)\)</span>.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple of dense detection scores and descriptors.
Shapes are <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span> and <span class="math notranslate nohighlight">\((B, D, H, W)\)</span>, where
<span class="math notranslate nohighlight">\(D\)</span> is the descriptor dimension.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.DISKFeatures">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">DISKFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keypoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">descriptors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">detection_scores</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DISKFeatures" title="Link to this definition">¶</a></dt>
<dd><p>A data structure holding DISK keypoints, descriptors and detection scores for an image.</p>
<p>Since DISK detects a varying number of keypoints per image, <cite>DISKFeatures</cite> is not batched.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keypoints</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Tensor of shape <span class="math notranslate nohighlight">\((N, 2)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the number of keypoints.</p></li>
<li><p><strong>descriptors</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Tensor of shape <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(D\)</span> is the descriptor dimension.</p></li>
<li><p><strong>detection_scores</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Tensor of shape <span class="math notranslate nohighlight">\((N,)\)</span> where the detection score can be interpreted as
the log-probability of keeping a keypoint after it has been proposed (see the paper
section <em>Method → Feature distribution</em> for details).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.DISKFeatures.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DISKFeatures.to" title="Link to this definition">¶</a></dt>
<dd><p>Call <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code> on each tensor to move the keypoints, descriptors and detection scores to
the specified device and/or data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></span>) – Arguments passed to <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code>.</p></li>
<li><p><strong>**kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></span>) – Keyword arguments passed to <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#kornia.feature.DISKFeatures" title="kornia.feature.disk.structs.DISKFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">DISKFeatures</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A new DISKFeatures object with tensors of appropriate type and location.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="kornia.feature.DISKFeatures.x">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">x</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#kornia.feature.DISKFeatures.x" title="Link to this definition">¶</a></dt>
<dd><p>Accesses the x coordinates of keypoints (along image width).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="kornia.feature.DISKFeatures.y">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">y</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#kornia.feature.DISKFeatures.y" title="Link to this definition">¶</a></dt>
<dd><p>Accesses the y coordinates of keypoints (along image height).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.SIFTFeature">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">SIFTFeature</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upright</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rootsift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.SIFTFeature" title="Link to this definition">¶</a></dt>
<dd><p>Convenience module, which implements DoG detector + (Root)SIFT descriptor.</p>
<p>Using <cite>kornia.feature.MultiResolutionDetector</cite> without blur pyramid Still not as good as OpenCV/VLFeat because of
<a class="reference external" href="https://github.com/kornia/kornia/pull/884">https://github.com/kornia/kornia/pull/884</a>,
but we are working on it</p>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.SIFTFeature.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.SIFTFeature.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – image to extract features with shape <span class="math notranslate nohighlight">\((B,C,H,W)\)</span>.</p></li>
<li><p><strong>mask</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – a mask with weights where to apply the response function.
The shape must be the same as the input image.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Detected local affine frames with shape <span class="math notranslate nohighlight">\((B,N,2,3)\)</span>.</p></li>
<li><p>Response function values for corresponding lafs with shape <span class="math notranslate nohighlight">\((B,N,1)\)</span>.</p></li>
<li><p>Local descriptors of shape <span class="math notranslate nohighlight">\((B,N,D)\)</span> where <span class="math notranslate nohighlight">\(D\)</span> is descriptor size.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.SIFTFeatureScaleSpace">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">SIFTFeatureScaleSpace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upright</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rootsift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.SIFTFeatureScaleSpace" title="Link to this definition">¶</a></dt>
<dd><p>Convenience module, which implements DoG detector + (Root)SIFT descriptor.</p>
<p>Using <cite>kornia.feature.ScaleSpaceDetector</cite> with blur pyramid.</p>
<p>Still not as good as OpenCV/VLFeat because of <a class="reference external" href="https://github.com/kornia/kornia/pull/884">https://github.com/kornia/kornia/pull/884</a>, but we are working on it</p>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.SIFTFeatureScaleSpace.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.SIFTFeatureScaleSpace.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – image to extract features with shape <span class="math notranslate nohighlight">\((B,C,H,W)\)</span>.</p></li>
<li><p><strong>mask</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – a mask with weights where to apply the response function.
The shape must be the same as the input image.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Detected local affine frames with shape <span class="math notranslate nohighlight">\((B,N,2,3)\)</span>.</p></li>
<li><p>Response function values for corresponding lafs with shape <span class="math notranslate nohighlight">\((B,N,1)\)</span>.</p></li>
<li><p>Local descriptors of shape <span class="math notranslate nohighlight">\((B,N,D)\)</span> where <span class="math notranslate nohighlight">\(D\)</span> is descriptor size.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.GFTTAffNetHardNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">GFTTAffNetHardNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upright</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.GFTTAffNetHardNet" title="Link to this definition">¶</a></dt>
<dd><p>Convenience module, which implements GFTT detector + AffNet-HardNet descriptor.</p>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.GFTTAffNetHardNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.GFTTAffNetHardNet.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – image to extract features with shape <span class="math notranslate nohighlight">\((B,C,H,W)\)</span>.</p></li>
<li><p><strong>mask</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – a mask with weights where to apply the response function.
The shape must be the same as the input image.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Detected local affine frames with shape <span class="math notranslate nohighlight">\((B,N,2,3)\)</span>.</p></li>
<li><p>Response function values for corresponding lafs with shape <span class="math notranslate nohighlight">\((B,N,1)\)</span>.</p></li>
<li><p>Local descriptors of shape <span class="math notranslate nohighlight">\((B,N,D)\)</span> where <span class="math notranslate nohighlight">\(D\)</span> is descriptor size.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.KeyNetAffNetHardNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">KeyNetAffNetHardNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upright</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_laf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.KeyNetAffNetHardNet" title="Link to this definition">¶</a></dt>
<dd><p>Convenience module, which implements KeyNet detector + AffNet + HardNet descriptor.</p>
<img alt="_images/keynet_affnet.jpg" src="_images/keynet_affnet.jpg" />
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.KeyNetAffNetHardNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.KeyNetAffNetHardNet.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – image to extract features with shape <span class="math notranslate nohighlight">\((B,C,H,W)\)</span>.</p></li>
<li><p><strong>mask</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – a mask with weights where to apply the response function.
The shape must be the same as the input image.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Detected local affine frames with shape <span class="math notranslate nohighlight">\((B,N,2,3)\)</span>.</p></li>
<li><p>Response function values for corresponding lafs with shape <span class="math notranslate nohighlight">\((B,N,1)\)</span>.</p></li>
<li><p>Local descriptors of shape <span class="math notranslate nohighlight">\((B,N,D)\)</span> where <span class="math notranslate nohighlight">\(D\)</span> is descriptor size.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.KeyNetHardNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">KeyNetHardNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upright</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_laf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.KeyNetHardNet" title="Link to this definition">¶</a></dt>
<dd><p>Convenience module, which implements KeyNet detector + HardNet descriptor.</p>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.KeyNetHardNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.KeyNetHardNet.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – image to extract features with shape <span class="math notranslate nohighlight">\((B,C,H,W)\)</span>.</p></li>
<li><p><strong>mask</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – a mask with weights where to apply the response function.
The shape must be the same as the input image.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Detected local affine frames with shape <span class="math notranslate nohighlight">\((B,N,2,3)\)</span>.</p></li>
<li><p>Response function values for corresponding lafs with shape <span class="math notranslate nohighlight">\((B,N,1)\)</span>.</p></li>
<li><p>Local descriptors of shape <span class="math notranslate nohighlight">\((B,N,D)\)</span> where <span class="math notranslate nohighlight">\(D\)</span> is descriptor size.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="matching">
<h2>Matching<a class="headerlink" href="#matching" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.match_nn">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">match_nn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desc1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">desc2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.match_nn" title="Link to this definition">¶</a></dt>
<dd><p>Find nearest neighbors in desc2 for each vector in desc1.</p>
<p>If the distance matrix dm is not provided, <a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.cdist.html#torch.cdist" title="(in PyTorch v2.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cdist()</span></code></a> is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desc1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B1, D)\)</span>.</p></li>
<li><p><strong>desc2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B2, D)\)</span>.</p></li>
<li><p><strong>dm</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – Tensor containing the distances from each descriptor in desc1
to each descriptor in desc2, shape of <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Descriptor distance of matching descriptors, shape of <span class="math notranslate nohighlight">\((B1, 1)\)</span>.</p></li>
<li><p>Long tensor indexes of matching descriptors in desc1 and desc2, shape of <span class="math notranslate nohighlight">\((B1, 2)\)</span>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.match_mnn">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">match_mnn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desc1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">desc2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.match_mnn" title="Link to this definition">¶</a></dt>
<dd><p>Find mutual nearest neighbors in desc2 for each vector in desc1.</p>
<p>If the distance matrix dm is not provided, <a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.cdist.html#torch.cdist" title="(in PyTorch v2.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cdist()</span></code></a> is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desc1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B1, D)\)</span>.</p></li>
<li><p><strong>desc2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B2, D)\)</span>.</p></li>
<li><p><strong>dm</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – Tensor containing the distances from each descriptor in desc1
to each descriptor in desc2, shape of <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Descriptor distance of matching descriptors, shape of. <span class="math notranslate nohighlight">\((B3, 1)\)</span>.</p></li>
<li><p>Long tensor indexes of matching descriptors in desc1 and desc2, shape of <span class="math notranslate nohighlight">\((B3, 2)\)</span>,
where 0 &lt;= B3 &lt;= min(B1, B2)</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.match_snn">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">match_snn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desc1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">desc2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">th</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.match_snn" title="Link to this definition">¶</a></dt>
<dd><p>Find nearest neighbors in desc2 for each vector in desc1.</p>
<p>The method satisfies first to second nearest neighbor distance &lt;= th.</p>
<p>If the distance matrix dm is not provided, <a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.cdist.html#torch.cdist" title="(in PyTorch v2.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cdist()</span></code></a> is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desc1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B1, D)\)</span>.</p></li>
<li><p><strong>desc2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B2, D)\)</span>.</p></li>
<li><p><strong>th</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – distance ratio threshold.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.8</span></code></p></li>
<li><p><strong>dm</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – Tensor containing the distances from each descriptor in desc1
to each descriptor in desc2, shape of <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Descriptor distance of matching descriptors, shape of <span class="math notranslate nohighlight">\((B3, 1)\)</span>.</p></li>
<li><p>Long tensor indexes of matching descriptors in desc1 and desc2. Shape: <span class="math notranslate nohighlight">\((B3, 2)\)</span>,
where 0 &lt;= B3 &lt;= B1.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.match_smnn">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">match_smnn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desc1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">desc2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">th</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.match_smnn" title="Link to this definition">¶</a></dt>
<dd><p>Find mutual nearest neighbors in desc2 for each vector in desc1.</p>
<p>the method satisfies first to second nearest neighbor distance &lt;= th.</p>
<p>If the distance matrix dm is not provided, <a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.cdist.html#torch.cdist" title="(in PyTorch v2.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cdist()</span></code></a> is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desc1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B1, D)\)</span>.</p></li>
<li><p><strong>desc2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B2, D)\)</span>.</p></li>
<li><p><strong>th</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – distance ratio threshold.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.95</span></code></p></li>
<li><p><strong>dm</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – Tensor containing the distances from each descriptor in desc1
to each descriptor in desc2, shape of <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Descriptor distance of matching descriptors, shape of. <span class="math notranslate nohighlight">\((B3, 1)\)</span>.</p></li>
<li><p>Long tensor indexes of matching descriptors in desc1 and desc2,
shape of <span class="math notranslate nohighlight">\((B3, 2)\)</span> where 0 &lt;= B3 &lt;= B1.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.match_fginn">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">match_fginn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desc1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">desc2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lafs1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lafs2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">th</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spatial_th</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mutual</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.match_fginn" title="Link to this definition">¶</a></dt>
<dd><p>Find nearest neighbors in desc2 for each vector in desc1.</p>
<p>The method satisfies first to second nearest neighbor distance &lt;= th,
and assures 2nd nearest neighbor is geometrically inconsistent with the 1st one
(see <span id="id15">[<a class="reference internal" href="community/bibliography.html#id32" title="Dmytro Mishkin, Jiri Matas, and Michal Perdoch. Mods: fast and robust method for two-view matching. Computer Vision and Image Understanding, 141:81 - 93, 2015.">MMP15</a>]</span> for more details)</p>
<p>If the distance matrix dm is not provided, <a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.cdist.html#torch.cdist" title="(in PyTorch v2.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cdist()</span></code></a> is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desc1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B1, D)\)</span>.</p></li>
<li><p><strong>desc2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B2, D)\)</span>.</p></li>
<li><p><strong>lafs1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – LAFs of a shape <span class="math notranslate nohighlight">\((1, B1, 2, 3)\)</span>.</p></li>
<li><p><strong>lafs2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – LAFs of a shape <span class="math notranslate nohighlight">\((1, B2, 2, 3)\)</span>.</p></li>
<li><p><strong>th</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – distance ratio threshold.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.8</span></code></p></li>
<li><p><strong>spatial_th</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – minimal distance in pixels to 2nd nearest neighbor.
Default:  <code class="code docutils literal notranslate"><span class="pre">10.0</span></code></p></li>
<li><p><strong>mutual</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – also perform mutual nearest neighbor check
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>dm</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – Tensor containing the distances from each descriptor in desc1
to each descriptor in desc2, shape of <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Descriptor distance of matching descriptors, shape of <span class="math notranslate nohighlight">\((B3, 1)\)</span>.</p></li>
<li><p>Long tensor indexes of matching descriptors in desc1 and desc2. Shape: <span class="math notranslate nohighlight">\((B3, 2)\)</span>,
where 0 &lt;= B3 &lt;= B1.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.match_adalam">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">match_adalam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desc1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">desc2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lafs1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lafs2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hw1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hw2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.match_adalam" title="Link to this definition">¶</a></dt>
<dd><p>Perform descriptor matching, followed by AdaLAM filtering.</p>
<p>See <span id="id16">[<a class="reference internal" href="community/bibliography.html#id34" title="Luca Cavalli, Viktor Larsson, Martin Ralf Oswald, Torsten Sattler, and Marc Pollefeys. Adalam: revisiting handcrafted outlier detection. CoRR, 2020. URL: https://arxiv.org/abs/2006.04250, arXiv:2006.04250.">CLO+20</a>]</span> for more details.</p>
<p>If the distance matrix dm is not provided, <a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.cdist.html#torch.cdist" title="(in PyTorch v2.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cdist()</span></code></a> is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desc1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B1, D)\)</span>.</p></li>
<li><p><strong>desc2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B2, D)\)</span>.</p></li>
<li><p><strong>lafs1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – LAFs of a shape <span class="math notranslate nohighlight">\((1, B1, 2, 3)\)</span>.</p></li>
<li><p><strong>lafs2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – LAFs of a shape <span class="math notranslate nohighlight">\((1, B2, 2, 3)\)</span>.</p></li>
<li><p><strong>config</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">AdalamConfig</span></code>]</span>, <em>optional</em>) – dict with AdaLAM config
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>dm</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – Tensor containing the distances from each descriptor in desc1
to each descriptor in desc2, shape of <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>hw1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]]</span>, <em>optional</em>) – Height/width of image.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>hw2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]]</span>, <em>optional</em>) – Height/width of image.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Descriptor distance of matching descriptors, shape of <span class="math notranslate nohighlight">\((B3, 1)\)</span>.</p></li>
<li><p>Long tensor indexes of matching descriptors in desc1 and desc2. Shape: <span class="math notranslate nohighlight">\((B3, 2)\)</span>,
where 0 &lt;= B3 &lt;= B1.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.DescriptorMatcher">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">DescriptorMatcher</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">match_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'snn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">th</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DescriptorMatcher" title="Link to this definition">¶</a></dt>
<dd><p>Module version of matching functions.</p>
<dl class="simple">
<dt>See <a class="reference internal" href="#kornia.feature.match_nn" title="kornia.feature.match_nn"><code class="xref py py-func docutils literal notranslate"><span class="pre">match_nn()</span></code></a>, <a class="reference internal" href="#kornia.feature.match_snn" title="kornia.feature.match_snn"><code class="xref py py-func docutils literal notranslate"><span class="pre">match_snn()</span></code></a>,</dt><dd><p><a class="reference internal" href="#kornia.feature.match_mnn" title="kornia.feature.match_mnn"><code class="xref py py-func docutils literal notranslate"><span class="pre">match_mnn()</span></code></a> or <a class="reference internal" href="#kornia.feature.match_smnn" title="kornia.feature.match_smnn"><code class="xref py py-func docutils literal notranslate"><span class="pre">match_smnn()</span></code></a> for more details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>match_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – type of matching, can be <cite>nn</cite>, <cite>snn</cite>, <cite>mnn</cite>, <cite>smnn</cite>.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;snn&quot;</span></code></p></li>
<li><p><strong>th</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – threshold on distance ratio, or other quality measure.
Default:  <code class="code docutils literal notranslate"><span class="pre">0.8</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.DescriptorMatcher.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desc1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">desc2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DescriptorMatcher.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desc1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B1, D)\)</span>.</p></li>
<li><p><strong>desc2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B2, D)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Descriptor distance of matching descriptors, shape of <span class="math notranslate nohighlight">\((B3, 1)\)</span>.</p></li>
<li><dl class="simple">
<dt>Long tensor indexes of matching descriptors in desc1 and desc2,</dt><dd><p>shape of <span class="math notranslate nohighlight">\((B3, 2)\)</span> where <span class="math notranslate nohighlight">\(0 &lt;= B3 &lt;= B1\)</span>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.GeometryAwareDescriptorMatcher">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">GeometryAwareDescriptorMatcher</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">match_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'fginn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.GeometryAwareDescriptorMatcher" title="Link to this definition">¶</a></dt>
<dd><p>Module version of matching functions.</p>
<dl class="simple">
<dt>See <a class="reference internal" href="#kornia.feature.match_nn" title="kornia.feature.match_nn"><code class="xref py py-func docutils literal notranslate"><span class="pre">match_nn()</span></code></a>, <a class="reference internal" href="#kornia.feature.match_snn" title="kornia.feature.match_snn"><code class="xref py py-func docutils literal notranslate"><span class="pre">match_snn()</span></code></a>,</dt><dd><p><a class="reference internal" href="#kornia.feature.match_mnn" title="kornia.feature.match_mnn"><code class="xref py py-func docutils literal notranslate"><span class="pre">match_mnn()</span></code></a> or <a class="reference internal" href="#kornia.feature.match_smnn" title="kornia.feature.match_smnn"><code class="xref py py-func docutils literal notranslate"><span class="pre">match_smnn()</span></code></a> for more details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>match_mode</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – type of matching, can be <cite>fginn</cite>.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;fginn&quot;</span></code></p></li>
<li><p><strong>th</strong> – threshold on distance ratio, or other quality measure.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.GeometryAwareDescriptorMatcher.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desc1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">desc2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lafs1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lafs2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.GeometryAwareDescriptorMatcher.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desc1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B1, D)\)</span>.</p></li>
<li><p><strong>desc2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B2, D)\)</span>.</p></li>
<li><p><strong>lafs1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – LAFs of a shape <span class="math notranslate nohighlight">\((1, B1, 2, 3)\)</span>.</p></li>
<li><p><strong>lafs2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – LAFs of a shape <span class="math notranslate nohighlight">\((1, B2, 2, 3)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Descriptor distance of matching descriptors, shape of <span class="math notranslate nohighlight">\((B3, 1)\)</span>.</p></li>
<li><dl class="simple">
<dt>Long tensor indexes of matching descriptors in desc1 and desc2,</dt><dd><p>shape of <span class="math notranslate nohighlight">\((B3, 2)\)</span> where <span class="math notranslate nohighlight">\(0 &lt;= B3 &lt;= B1\)</span>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.LocalFeatureMatcher">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">LocalFeatureMatcher</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">matcher</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LocalFeatureMatcher" title="Link to this definition">¶</a></dt>
<dd><p>Module, which finds correspondences between two images based on local features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>local_feature</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – Local feature detector. See <a class="reference internal" href="#kornia.feature.GFTTAffNetHardNet" title="kornia.feature.GFTTAffNetHardNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">GFTTAffNetHardNet</span></code></a>.</p></li>
<li><p><strong>matcher</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>) – Descriptor matcher, see <a class="reference internal" href="#kornia.feature.DescriptorMatcher" title="kornia.feature.DescriptorMatcher"><code class="xref py py-class docutils literal notranslate"><span class="pre">DescriptorMatcher</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary with image correspondences and confidence scores.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>, Tensor]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">320</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;image0&quot;</span><span class="p">:</span> <span class="n">img1</span><span class="p">,</span> <span class="s2">&quot;image1&quot;</span><span class="p">:</span> <span class="n">img2</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gftt_hardnet_matcher</span> <span class="o">=</span> <span class="n">LocalFeatureMatcher</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">GFTTAffNetHardNet</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">kornia</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">DescriptorMatcher</span><span class="p">(</span><span class="s1">&#39;snn&#39;</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">gftt_hardnet_matcher</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.LocalFeatureMatcher.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LocalFeatureMatcher.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – dictionary containing the input data in the following format:</p>
</dd>
<dt class="field-even">Keyword Arguments<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>image0</strong> – left image with shape <span class="math notranslate nohighlight">\((N, 1, H1, W1)\)</span>.</p></li>
<li><p><strong>image1</strong> – right image with shape <span class="math notranslate nohighlight">\((N, 1, H2, W2)\)</span>.</p></li>
<li><p><strong>mask0</strong> (<em>optional</em>) – left image mask. ‘0’ indicates a padded position <span class="math notranslate nohighlight">\((N, H1, W1)\)</span>.</p></li>
<li><p><strong>mask1</strong> (<em>optional</em>) – right image mask. ‘0’ indicates a padded position <span class="math notranslate nohighlight">\((N, H2, W2)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">keypoints0</span></code>, matching keypoints from image0 <span class="math notranslate nohighlight">\((NC, 2)\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">keypoints1</span></code>, matching keypoints from image1 <span class="math notranslate nohighlight">\((NC, 2)\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">confidence</span></code>, confidence score [0, 1] <span class="math notranslate nohighlight">\((NC)\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lafs0</span></code>, matching LAFs from image0 <span class="math notranslate nohighlight">\((1, NC, 2, 3)\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lafs1</span></code>, matching LAFs from image1 <span class="math notranslate nohighlight">\((1, NC, 2, 3)\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_indexes</span></code>, batch indexes for the keypoints and lafs <span class="math notranslate nohighlight">\((NC)\)</span>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.LightGlueMatcher">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">LightGlueMatcher</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'disk'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LightGlueMatcher" title="Link to this definition">¶</a></dt>
<dd><p>LightGlue-based matcher in kornia API.</p>
<p>This is based on the original code from paper “LightGlue: Local Feature Matching at Light Speed”.
See <span id="id17">[<a class="reference internal" href="community/bibliography.html#id9" title="Philipp Lindenberger, Paul-Edouard Sarlin, and Marc Pollefeys. Lightglue: local feature matching at light speed. arXiv ePrint 2306.13643, 2023.">LSP23</a>]</span> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_name</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>, <em>optional</em>) – type of feature for matching, can be <cite>disk</cite> or <cite>superpoint</cite>.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;disk&quot;</span></code></p></li>
<li><p><strong>params</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>]</span>, <em>optional</em>) – LightGlue params.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.LightGlueMatcher.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desc1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">desc2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lafs1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lafs2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hw1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hw2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LightGlueMatcher.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desc1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B1, D)\)</span>.</p></li>
<li><p><strong>desc2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Batch of descriptors of a shape <span class="math notranslate nohighlight">\((B2, D)\)</span>.</p></li>
<li><p><strong>lafs1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – LAFs of a shape <span class="math notranslate nohighlight">\((1, B1, 2, 3)\)</span>.</p></li>
<li><p><strong>lafs2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – LAFs of a shape <span class="math notranslate nohighlight">\((1, B2, 2, 3)\)</span>.</p></li>
<li><p><strong>hw1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]]</span>, <em>optional</em>) – Height/width of image.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>hw2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]]</span>, <em>optional</em>) – Height/width of image.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Descriptor distance of matching descriptors, shape of <span class="math notranslate nohighlight">\((B3, 1)\)</span>.</p></li>
<li><dl class="simple">
<dt>Long tensor indexes of matching descriptors in desc1 and desc2,</dt><dd><p>shape of <span class="math notranslate nohighlight">\((B3, 2)\)</span> where <span class="math notranslate nohighlight">\(0 &lt;= B3 &lt;= B1\)</span>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.LightGlue">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">LightGlue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'superpoint'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">conf_</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LightGlue" title="Link to this definition">¶</a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.LightGlue.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LightGlue.forward" title="Link to this definition">¶</a></dt>
<dd><p>Match keypoints and descriptors between two images.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a></span></p>
</dd>
</dl>
<dl class="simple">
<dt>Input (dict):</dt><dd><dl class="simple">
<dt>image0: dict</dt><dd><p>keypoints: [B x M x 2]
descriptors: [B x M x D]
image: [B x C x H x W] or image_size: [B x 2]</p>
</dd>
<dt>image1: dict</dt><dd><p>keypoints: [B x N x 2]
descriptors: [B x N x D]
image: [B x C x H x W] or image_size: [B x 2]</p>
</dd>
</dl>
</dd>
<dt>Output (dict):</dt><dd><p>log_assignment: [B x M+1 x N+1]
matches0: [B x M]
matching_scores0: [B x M]
matches1: [B x N]
matching_scores1: [B x N]
matches: List[[Si x 2]], scores: List[[Si]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.LoFTR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">LoFTR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'outdoor'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default_cfg</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LoFTR" title="Link to this definition">¶</a></dt>
<dd><p>Module, which finds correspondences between two images.</p>
<p>This is based on the original code from paper “LoFTR: Detector-Free Local
Feature Matching with Transformers”. See <span id="id18">[<a class="reference internal" href="community/bibliography.html#id20" title="Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: detector-free local feature matching with transformers. In CVPR. 2021.">SSW+21</a>]</span> for more details.</p>
<p>If the distance matrix dm is not provided, <a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.cdist.html#torch.cdist" title="(in PyTorch v2.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cdist()</span></code></a> is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]</span>, <em>optional</em>) – Dict with initialization parameters. Do not pass it, unless you know what you are doing`.
Default:  <code class="code docutils literal notranslate"><span class="pre">default_cfg</span></code></p></li>
<li><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>]</span>, <em>optional</em>) – Download and set pretrained weights to the model. Options: ‘outdoor’, ‘indoor’.
‘outdoor’ is trained on the MegaDepth dataset and ‘indoor’
on the ScanNet.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;outdoor&quot;</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary with image correspondences and confidence scores.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">320</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;image0&quot;</span><span class="p">:</span> <span class="n">img1</span><span class="p">,</span> <span class="s2">&quot;image1&quot;</span><span class="p">:</span> <span class="n">img2</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loftr</span> <span class="o">=</span> <span class="n">LoFTR</span><span class="p">(</span><span class="s1">&#39;outdoor&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">loftr</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.LoFTR.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LoFTR.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – dictionary containing the input data in the following format:</p>
</dd>
<dt class="field-even">Keyword Arguments<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>image0</strong> – left image with shape <span class="math notranslate nohighlight">\((N, 1, H1, W1)\)</span>.</p></li>
<li><p><strong>image1</strong> – right image with shape <span class="math notranslate nohighlight">\((N, 1, H2, W2)\)</span>.</p></li>
<li><p><strong>mask0</strong> (<em>optional</em>) – left image mask. ‘0’ indicates a padded position <span class="math notranslate nohighlight">\((N, H1, W1)\)</span>.</p></li>
<li><p><strong>mask1</strong> (<em>optional</em>) – right image mask. ‘0’ indicates a padded position <span class="math notranslate nohighlight">\((N, H2, W2)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">keypoints0</span></code>, matching keypoints from image0 <span class="math notranslate nohighlight">\((NC, 2)\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">keypoints1</span></code>, matching keypoints from image1 <span class="math notranslate nohighlight">\((NC, 2)\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">confidence</span></code>, confidence score [0, 1] <span class="math notranslate nohighlight">\((NC)\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_indexes</span></code>, batch indexes for the keypoints and lafs <span class="math notranslate nohighlight">\((NC)\)</span>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="interactive-demo">
<h3>Interactive Demo<a class="headerlink" href="#interactive-demo" title="Link to this heading">¶</a></h3>
<gradio-app src="https://kornia-kornia-loftr.hf.space"></gradio-app><dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.OnnxLightGlue">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">OnnxLightGlue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.OnnxLightGlue" title="Link to this definition">¶</a></dt>
<dd><p>Wrapper for loading LightGlue-ONNX models and running inference via ONNXRuntime.</p>
<p>LightGlue <span id="id19">[<a class="reference internal" href="community/bibliography.html#id9" title="Philipp Lindenberger, Paul-Edouard Sarlin, and Marc Pollefeys. Lightglue: local feature matching at light speed. arXiv ePrint 2306.13643, 2023.">LSP23</a>]</span> performs fast descriptor-based deep keypoint matching.
This module requires <cite>onnxruntime</cite> to be installed.</p>
<p>If you have trained your own LightGlue model, see <a class="reference external" href="https://github.com/fabio-sim/LightGlue-ONNX">https://github.com/fabio-sim/LightGlue-ONNX</a>
for how to export the model to ONNX and optimize it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<span class="sphinx_autodoc_typehints-type">str | None</span>, <em>optional</em>) – Pretrained weights, or a path to your own exported ONNX model. Available pretrained weights
are <code class="docutils literal notranslate"><span class="pre">'disk'</span></code>, <code class="docutils literal notranslate"><span class="pre">'superpoint'</span></code>, <code class="docutils literal notranslate"><span class="pre">'disk_fp16'</span></code>, and <code class="docutils literal notranslate"><span class="pre">'superpoint_fp16'</span></code>. <cite>Note that FP16 requires CUDA.</cite>
Defaults to <code class="docutils literal notranslate"><span class="pre">'disk_fp16'</span></code> if <code class="docutils literal notranslate"><span class="pre">device</span></code> is CUDA, and <code class="docutils literal notranslate"><span class="pre">'disk'</span></code> if CPU.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>device</strong> (<span class="sphinx_autodoc_typehints-type">Device</span>, <em>optional</em>) – Device to run inference on.
Default:  <code class="code docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.OnnxLightGlue.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.OnnxLightGlue.forward" title="Link to this definition">¶</a></dt>
<dd><p>Match keypoints and descriptors between two images.</p>
<p>The output contains the matches (the indices of the matching keypoint pairs between the first and second image)
and the corresponding confidence scores.
Only a batch size of 1 is supported.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]]</span>) – Dictionary containing both images and the keypoints and descriptors thereof.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dictionary containing the matches and scores.</p>
</dd>
</dl>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">data</span></code> (<code class="docutils literal notranslate"><span class="pre">dict</span></code>):</dt><dd><dl>
<dt><code class="docutils literal notranslate"><span class="pre">image0</span></code> (<code class="docutils literal notranslate"><span class="pre">dict</span></code>):</dt><dd><p><code class="docutils literal notranslate"><span class="pre">keypoints</span></code> (<cite>float32</cite>): <span class="math notranslate nohighlight">\((1, M, 2)\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">descriptors</span></code> (<cite>float32</cite>): <span class="math notranslate nohighlight">\((1, M, D)\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">image</span></code>: <span class="math notranslate nohighlight">\((1, C, H, W)\)</span> or <code class="docutils literal notranslate"><span class="pre">image_size</span></code>: <span class="math notranslate nohighlight">\((1, 2)\)</span></p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">image1</span></code> (<code class="docutils literal notranslate"><span class="pre">dict</span></code>):</dt><dd><p><code class="docutils literal notranslate"><span class="pre">keypoints</span></code> (<cite>float32</cite>): <span class="math notranslate nohighlight">\((1, N, 2)\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">descriptors</span></code> (<cite>float32</cite>): <span class="math notranslate nohighlight">\((1, N, D)\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">image</span></code>: <span class="math notranslate nohighlight">\((1, C, H, W)\)</span> or <code class="docutils literal notranslate"><span class="pre">image_size</span></code>: <span class="math notranslate nohighlight">\((1, 2)\)</span></p>
</dd>
</dl>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">output</span></code> (<code class="docutils literal notranslate"><span class="pre">dict</span></code>):</dt><dd><p><code class="docutils literal notranslate"><span class="pre">matches</span></code> (<cite>int64</cite>): <span class="math notranslate nohighlight">\((S, 2)\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">scores</span></code> (<cite>float32</cite>): <span class="math notranslate nohighlight">\((S)\)</span></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="local-affine-frames-laf">
<h2>Local Affine Frames (LAF)<a class="headerlink" href="#local-affine-frames-laf" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.extract_patches_from_pyramid">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">extract_patches_from_pyramid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">laf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">PS</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_lafs_before_extraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.extract_patches_from_pyramid" title="Link to this definition">¶</a></dt>
<dd><p>Extract patches defined by LAFs from image tensor.</p>
<p>Patches are extracted from appropriate pyramid level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – images, LAFs are detected in  <span class="math notranslate nohighlight">\((B, CH, H, W)\)</span>.</p></li>
<li><p><strong>laf</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span>.</p></li>
<li><p><strong>PS</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – patch size.
Default:  <code class="code docutils literal notranslate"><span class="pre">32</span></code></p></li>
<li><p><strong>normalize_lafs_before_extraction</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if True, lafs are normalized to image size.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>patches with shape <span class="math notranslate nohighlight">\((B, N, CH, PS,PS)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.extract_patches_simple">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">extract_patches_simple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">laf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">PS</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_lafs_before_extraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.extract_patches_simple" title="Link to this definition">¶</a></dt>
<dd><p>Extract patches defined by LAFs from image tensor.</p>
<p>No smoothing applied, huge aliasing (better use extract_patches_from_pyramid).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – images, LAFs are detected in  <span class="math notranslate nohighlight">\((B, CH, H, W)\)</span>.</p></li>
<li><p><strong>laf</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span>.</p></li>
<li><p><strong>PS</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – patch size.
Default:  <code class="code docutils literal notranslate"><span class="pre">32</span></code></p></li>
<li><p><strong>normalize_lafs_before_extraction</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if True, lafs are normalized to image size.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>patches with shape <span class="math notranslate nohighlight">\((B, N, CH, PS,PS)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.normalize_laf">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">normalize_laf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">LAF</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">images</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.normalize_laf" title="Link to this definition">¶</a></dt>
<dd><p>Normalize LAFs to [0,1] scale from pixel scale.</p>
<dl class="simple">
<dt>See below:</dt><dd><p>B,N,H,W = images.size()
MIN_SIZE =  min(H - 1, W -1)
[a11 a21 x]
[a21 a22 y]
becomes:
[a11/MIN_SIZE a21/MIN_SIZE x/(W-1)]
[a21/MIN_SIZE a22/MIN_SIZE y/(H-1)]</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>LAF</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p></li>
<li><p><strong>images</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, CH, H, W)\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span>, scale in image percentage (0, 1)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>the denormalized LAF</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.denormalize_laf">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">denormalize_laf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">LAF</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">images</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.denormalize_laf" title="Link to this definition">¶</a></dt>
<dd><p>De-normalize LAFs from scale to image scale.</p>
<p>The convention is that center of 5-pixel image (coordinates from 0 to 4) is 2, and not 2.5.</p>
<blockquote>
<div><p>B,N,H,W = images.size()
MIN_SIZE = min(H - 1, W -1)
[a11 a21 x]
[a21 a22 y]
becomes
[a11*MIN_SIZE a21*MIN_SIZE x*(W-1)]
[a21*MIN_SIZE a22*MIN_SIZE y*(W-1)]</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>LAF</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p></li>
<li><p><strong>images</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, CH, H, W)\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span>, scale in pixels</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>the denormalized LAF</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.laf_to_boundary_points">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">laf_to_boundary_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">LAF</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_pts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.laf_to_boundary_points" title="Link to this definition">¶</a></dt>
<dd><p>Convert LAFs to boundary points of the regions + center.</p>
<p>Used for local features visualization, see visualize_laf function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>LAF</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p></li>
<li><p><strong>n_pts</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – number of points to output.
Default:  <code class="code docutils literal notranslate"><span class="pre">50</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="math notranslate nohighlight">\((B, N, n_pts, 2)\)</span></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tensor of boundary points LAF</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.ellipse_to_laf">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">ellipse_to_laf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ells</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.ellipse_to_laf" title="Link to this definition">¶</a></dt>
<dd><p>Convert ellipse regions to LAF format.</p>
<p>Ellipse (a, b, c) and upright covariance matrix [a11 a12; 0 a22] are connected
by inverse matrix square root: A = invsqrt([a b; b c]).</p>
<p>See also <a class="reference external" href="https://github.com/vlfeat/vlfeat/blob/master/toolbox/sift/vl_frame2oell.m">https://github.com/vlfeat/vlfeat/blob/master/toolbox/sift/vl_frame2oell.m</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ells</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – tensor <span class="math notranslate nohighlight">\((B, N, 5)\)</span> of ellipses in Oxford format [x y a b c].</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>LAF <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># BxNx5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">ellipse_to_laf</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>  <span class="c1">#  BxNx2x3</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.make_upright">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">make_upright</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">laf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-9</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.make_upright" title="Link to this definition">¶</a></dt>
<dd><p>Rectify the affine matrix, so that it becomes upright.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>laf</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p></li>
<li><p><strong>eps</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – for safe division.
Default:  <code class="code docutils literal notranslate"><span class="pre">1e-9</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>laf</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># BxNx2x3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">make_upright</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>  <span class="c1">#  BxNx2x3</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.scale_laf">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">scale_laf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">laf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_coef</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.scale_laf" title="Link to this definition">¶</a></dt>
<dd><p>Multiplies region part of LAF ([:, :, :2, :2]) by a scale_coefficient.</p>
<p>So the center, shape and orientation of the local feature stays the same, but the region area changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>laf</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p></li>
<li><p><strong>scale_coef</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>) – broadcastable tensor or float.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>LAF <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># BxNx2x3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">scale_laf</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>  <span class="c1"># BxNx2x3</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.get_laf_scale">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">get_laf_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">LAF</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.get_laf_scale" title="Link to this definition">¶</a></dt>
<dd><p>Return a scale of the LAFs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>LAF</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>scale <span class="math notranslate nohighlight">\((B, N, 1, 1)\)</span></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># BxNx2x3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">get_laf_scale</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>  <span class="c1"># BxNx1x1</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.get_laf_center">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">get_laf_center</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">LAF</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.get_laf_center" title="Link to this definition">¶</a></dt>
<dd><p>Return a center (keypoint) of the LAFs.</p>
<p>The convention is that center of 5-pixel image (coordinates from 0 to 4) is 2, and not 2.5.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>LAF</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>xy <span class="math notranslate nohighlight">\((B, N, 2)\)</span></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># BxNx2x3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">get_laf_center</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>  <span class="c1"># BxNx2</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.rotate_laf">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">rotate_laf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">LAF</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">angles_degrees</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.rotate_laf" title="Link to this definition">¶</a></dt>
<dd><p>Apply additional rotation to the LAFs.</p>
<p>Compared to <cite>set_laf_orientation</cite>, the resulting rotation is original LAF orientation plus angles_degrees.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>LAF</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p></li>
<li><p><strong>angles_degrees</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 1)\)</span> in degrees.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>LAF oriented with angles <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.get_laf_orientation">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">get_laf_orientation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">LAF</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.get_laf_orientation" title="Link to this definition">¶</a></dt>
<dd><p>Return orientation of the LAFs, in degrees.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>LAF</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>angle in degrees <span class="math notranslate nohighlight">\((B, N, 1)\)</span></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># BxNx2x3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">get_laf_orientation</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>  <span class="c1"># BxNx1</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.set_laf_orientation">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">set_laf_orientation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">LAF</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">angles_degrees</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.set_laf_orientation" title="Link to this definition">¶</a></dt>
<dd><p>Change the orientation of the LAFs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>LAF</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p></li>
<li><p><strong>angles_degrees</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 1)\)</span> in degrees.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>LAF oriented with angles <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.laf_from_center_scale_ori">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">laf_from_center_scale_ori</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ori</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.laf_from_center_scale_ori" title="Link to this definition">¶</a></dt>
<dd><p>Create a LAF from keypoint center, scale and orientation.</p>
<p>Useful to create kornia LAFs from OpenCV keypoints.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xy</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2)\)</span>.</p></li>
<li><p><strong>scale</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – <span class="math notranslate nohighlight">\((B, N, 1, 1)\)</span>. If not provided, scale = 1.0 is assumed
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>ori</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span>, <em>optional</em>) – angle in degrees <span class="math notranslate nohighlight">\((B, N, 1)\)</span>. If not provided orientation = 0 is assumed
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>LAF <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.laf_is_inside_image">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">laf_is_inside_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">laf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">images</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">border</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.laf_is_inside_image" title="Link to this definition">¶</a></dt>
<dd><p>Check if the LAF is touching or partly outside the image boundary.</p>
<p>Returns the mask of LAFs, which are fully inside the image, i.e. valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>laf</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span>.</p></li>
<li><p><strong>images</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – images, lafs are detected in <span class="math notranslate nohighlight">\((B, CH, H, W)\)</span>.</p></li>
<li><p><strong>border</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – additional border.
Default:  <code class="code docutils literal notranslate"><span class="pre">0</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>mask with shape <span class="math notranslate nohighlight">\((B, N)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.laf_to_three_points">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">laf_to_three_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">laf</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.laf_to_three_points" title="Link to this definition">¶</a></dt>
<dd><p>Convert local affine frame(LAF) to alternative representation: coordinates of LAF center, LAF-x unit vector,
LAF-y unit vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>laf</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span>.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>threepts <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.laf_from_three_points">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">laf_from_three_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threepts</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.laf_from_three_points" title="Link to this definition">¶</a></dt>
<dd><p>Convert three points to local affine frame.</p>
<p>Order is (0,0), (0, 1), (1, 0).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>threepts</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span>.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>laf <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.KORNIA_CHECK_LAF">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">KORNIA_CHECK_LAF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">laf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raises</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.KORNIA_CHECK_LAF" title="Link to this definition">¶</a></dt>
<dd><p>Check whether a Local Affine Frame (laf) has a valid shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>laf</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – local affine frame tensor to evaluate.</p></li>
<li><p><strong>raises</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – bool indicating whether an exception should be raised upon failure.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#Exception" title="(in Python v3.13)"><strong>Exception</strong></a> – if the input laf does not have a shape <span class="math notranslate nohighlight">\((B,N,2,3)\)</span> and raises is True.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lafs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">KORNIA_CHECK_LAF</span><span class="p">(</span><span class="n">lafs</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="kornia.feature.perspective_transform_lafs">
<span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">perspective_transform_lafs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trans_01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lafs_1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.perspective_transform_lafs" title="Link to this definition">¶</a></dt>
<dd><p>Apply perspective transformations to a set of local affine frames (LAFs).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trans_01</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – tensor for perspective transformations of shape <span class="math notranslate nohighlight">\((B, 3, 3)\)</span>.</p></li>
<li><p><strong>lafs_1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – tensor of lafs of shape <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>tensor of N-dimensional points of shape <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lafs_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># BxNx2x3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lafs_1</span>
<span class="go">tensor([[[[0.4963, 0.7682, 0.0885],</span>
<span class="go">          [0.1320, 0.3074, 0.6341]],</span>

<span class="go">         [[0.4901, 0.8964, 0.4556],</span>
<span class="go">          [0.6323, 0.3489, 0.4017]],</span>

<span class="go">         [[0.0223, 0.1689, 0.2939],</span>
<span class="go">          [0.5185, 0.6977, 0.8000]],</span>

<span class="go">         [[0.1610, 0.2823, 0.6816],</span>
<span class="go">          [0.9152, 0.3971, 0.8742]]],</span>


<span class="go">        [[[0.4194, 0.5529, 0.9527],</span>
<span class="go">          [0.0362, 0.1852, 0.3734]],</span>

<span class="go">         [[0.3051, 0.9320, 0.1759],</span>
<span class="go">          [0.2698, 0.1507, 0.0317]],</span>

<span class="go">         [[0.2081, 0.9298, 0.7231],</span>
<span class="go">          [0.7423, 0.5263, 0.2437]],</span>

<span class="go">         [[0.5846, 0.0332, 0.1387],</span>
<span class="go">          [0.2422, 0.8155, 0.7932]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trans_01</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Bx3x3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trans_01</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([2, 3, 3])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lafs_0</span> <span class="o">=</span> <span class="n">perspective_transform_lafs</span><span class="p">(</span><span class="n">trans_01</span><span class="p">,</span> <span class="n">lafs_1</span><span class="p">)</span>  <span class="c1"># BxNx2x3</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.PassLAF">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">PassLAF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.PassLAF" title="Link to this definition">¶</a></dt>
<dd><p>Dummy module to use instead of local feature orientation or affine shape estimator.</p>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.PassLAF.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">laf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.PassLAF.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>laf</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p></li>
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>LAF, unchanged <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.PatchAffineShapeEstimator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">PatchAffineShapeEstimator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">19</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.PatchAffineShapeEstimator" title="Link to this definition">¶</a></dt>
<dd><p>Module, which estimates the second moment matrix of the patch gradients.</p>
<p>The method determines the affine shape of the local feature as in <span id="id20">[<a class="reference internal" href="community/bibliography.html#id5" title="A. Baumberg. Reliable feature matching across widely separated views. In CVPR. 2000.">Baumberg00</a>]</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patch_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – the input image patch size.
Default:  <code class="code docutils literal notranslate"><span class="pre">19</span></code></p></li>
<li><p><strong>eps</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – for safe division.
Default:  <code class="code docutils literal notranslate"><span class="pre">1e-10</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.PatchAffineShapeEstimator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.PatchAffineShapeEstimator.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>patch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ellipse_shape <span class="math notranslate nohighlight">\((B, 1, 3)\)</span></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.LAFAffineShapeEstimator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">LAFAffineShapeEstimator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affine_shape_detector</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preserve_orientation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LAFAffineShapeEstimator" title="Link to this definition">¶</a></dt>
<dd><p>Module, which extracts patches using input images and local affine frames (LAFs).</p>
<p>Then runs <a class="reference internal" href="#kornia.feature.PatchAffineShapeEstimator" title="kornia.feature.PatchAffineShapeEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">PatchAffineShapeEstimator</span></code></a> on patches to estimate LAFs shape.</p>
<p>Then original LAF shape is replaced with estimated one. The original LAF orientation is not preserved,
so it is recommended to first run LAFAffineShapeEstimator and then LAFOrienter,</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patch_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – the input image patch size.
Default:  <code class="code docutils literal notranslate"><span class="pre">32</span></code></p></li>
<li><p><strong>affine_shape_detector</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – Patch affine shape estimator, <a class="reference internal" href="#kornia.feature.PatchAffineShapeEstimator" title="kornia.feature.PatchAffineShapeEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">PatchAffineShapeEstimator</span></code></a>.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>preserve_orientation</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if True, the original orientation is preserved.
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.LAFAffineShapeEstimator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">laf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LAFAffineShapeEstimator.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>laf</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p></li>
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>LAF_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.LAFOrienter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">LAFOrienter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_angular_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">36</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">angle_detector</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LAFOrienter" title="Link to this definition">¶</a></dt>
<dd><p>Module, which extracts patches using input images and local affine frames (LAFs).</p>
<p>Then runs <a class="reference internal" href="#kornia.feature.PatchDominantGradientOrientation" title="kornia.feature.PatchDominantGradientOrientation"><code class="xref py py-class docutils literal notranslate"><span class="pre">PatchDominantGradientOrientation</span></code></a> or
<a class="reference internal" href="#kornia.feature.OriNet" title="kornia.feature.OriNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">OriNet</span></code></a> on patches and then rotates the LAFs by the estimated angles</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patch_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Default:  <code class="code docutils literal notranslate"><span class="pre">32</span></code></p></li>
<li><p><strong>num_angular_bins</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – Default:  <code class="code docutils literal notranslate"><span class="pre">36</span></code></p></li>
<li><p><strong>angle_detector</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="http://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>]</span>, <em>optional</em>) – Patch orientation estimator, e.g. <a class="reference internal" href="#kornia.feature.PatchDominantGradientOrientation" title="kornia.feature.PatchDominantGradientOrientation"><code class="xref py py-class docutils literal notranslate"><span class="pre">PatchDominantGradientOrientation</span></code></a>
or OriNet.
Default:  <code class="code docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.LAFOrienter.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">laf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LAFOrienter.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>laf</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p></li>
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>LAF_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.PatchDominantGradientOrientation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">PatchDominantGradientOrientation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_angular_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">36</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-8</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.PatchDominantGradientOrientation" title="Link to this definition">¶</a></dt>
<dd><p>Module, which estimates the dominant gradient orientation of the given patches, in radians.</p>
<p>Zero angle points towards right.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patch_size</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – size of the (square) input patch.
Default:  <code class="code docutils literal notranslate"><span class="pre">32</span></code></p></li>
<li><p><strong>num_angular_bins</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>, <em>optional</em>) – number of histogram bins.
Default:  <code class="code docutils literal notranslate"><span class="pre">36</span></code></p></li>
<li><p><strong>eps</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – for safe division, and arctan.
Default:  <code class="code docutils literal notranslate"><span class="pre">1e-8</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.PatchDominantGradientOrientation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.PatchDominantGradientOrientation.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>patch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="math notranslate nohighlight">\((B)\)</span></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>angle in radians</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.OriNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">OriNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-8</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.OriNet" title="Link to this definition">¶</a></dt>
<dd><p>Network, which estimates the canonical orientation of the given 32x32 patches, in radians.</p>
<p>Zero angle points towards right. This is based on the original code from paper
“Repeatability Is Not Enough: Learning Discriminative Affine Regions via Discriminability””.
See <span id="id21">[<a class="reference internal" href="community/bibliography.html#id14" title="D. Mishkin, F. Radenovic, and J. Matas. Repeatability is Not Enough: Learning Affine Regions via Discriminability. In ECCV. 2018.">MRM18</a>]</span> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Download and set pretrained weights to the model.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>eps</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – to avoid division by zero in atan2.
Default:  <code class="code docutils literal notranslate"><span class="pre">1e-8</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Angle in radians.</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: (B, 1, 32, 32)</p></li>
<li><p>Output: (B)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">orinet</span> <span class="o">=</span> <span class="n">OriNet</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">angle</span> <span class="o">=</span> <span class="n">orinet</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># 16</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.OriNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.OriNet.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>patch</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="math notranslate nohighlight">\((B)\)</span></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>angle in radians</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.LAFAffNetShapeEstimator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">LAFAffNetShapeEstimator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preserve_orientation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LAFAffNetShapeEstimator" title="Link to this definition">¶</a></dt>
<dd><p>Module, which extracts patches using input images and local affine frames (LAFs).</p>
<p>Then runs AffNet on patches to estimate LAFs shape. This is based on the original code from paper
“Repeatability Is Not Enough: Learning Discriminative Affine Regions via Discriminability””.
See <span id="id22">[<a class="reference internal" href="community/bibliography.html#id14" title="D. Mishkin, F. Radenovic, and J. Matas. Repeatability is Not Enough: Learning Affine Regions via Discriminability. In ECCV. 2018.">MRM18</a>]</span> for more details.</p>
<p>Then original LAF shape is replaced with estimated one. The original LAF orientation is not preserved,
so it is recommended to first run LAFAffineShapeEstimator and then LAFOrienter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Download and set pretrained weights to the model.
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.LAFAffNetShapeEstimator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">laf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.LAFAffNetShapeEstimator.forward" title="Link to this definition">¶</a></dt>
<dd><p>Run forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>laf</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p></li>
<li><p><strong>img</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – <span class="math notranslate nohighlight">\((B, 1, H, W)\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="math notranslate nohighlight">\((B, N, 2, 3)\)</span></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>LAF_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="layers">
<h2>Layers<a class="headerlink" href="#layers" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.FilterResponseNorm2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">FilterResponseNorm2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_eps_leanable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.FilterResponseNorm2d" title="Link to this definition">¶</a></dt>
<dd><p>Feature Response Normalization layer from ‘Filter Response Normalization Layer: Eliminating Batch Dependence
in the Training of Deep Neural Networks’, see <span id="id23">[<a class="reference internal" href="community/bibliography.html#id8" title="Saurabh Singh and Shankar Krishnan. Filter response normalization layer: eliminating batch dependence in the training of deep neural networks. In CVPR. 2020.">SK20</a>]</span> for more details.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[y =  \gamma \times \frac{x}{\sqrt{\mathrm{E}[x^2]} + |\epsilon|} + \beta\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>) – number of channels</p></li>
<li><p><strong>eps</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>, <em>optional</em>) – normalization constant
Default:  <code class="code docutils literal notranslate"><span class="pre">1e-6</span></code></p></li>
<li><p><strong>is_bias</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – use bias
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>is_scale</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – use scale
Default:  <code class="code docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>drop_rate</strong> – dropout rate,</p></li>
<li><p><strong>is_eps_leanable</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – if eps is learnable
Default:  <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Normalized features</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)">torch.Tensor</a></p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((B, \text{num_features}, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, \text{num_features}, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.TLU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">TLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.TLU" title="Link to this definition">¶</a></dt>
<dd><p>TLU layer from ‘Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep
Neural Networks, see <span id="id24">[<a class="reference internal" href="community/bibliography.html#id8" title="Saurabh Singh and Shankar Krishnan. Filter response normalization layer: eliminating batch dependence in the training of deep neural networks. In CVPR. 2020.">SK20</a>]</span> for more details. <span class="math notranslate nohighlight">\({\tau}\)</span> is learnable per channel.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[y = \max(x, {\tau})\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_features</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>) – number of channels</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((B, \text{num_features}, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((B, \text{num_features}, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="other">
<h2>Other<a class="headerlink" href="#other" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="kornia.feature.DeFMO">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kornia.feature.</span></span><span class="sig-name descname"><span class="pre">DeFMO</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DeFMO" title="Link to this definition">¶</a></dt>
<dd><p>Module that disentangle a fast-moving object from the background and performs deblurring.</p>
<dl class="simple">
<dt>This is based on the original code from paper “DeFMO: Deblurring and Shape Recovery</dt><dd><p>of Fast Moving Objects”. See <span id="id25">[<a class="reference internal" href="community/bibliography.html#id3" title="Denys Rozumnyi, Martin R. Oswald, Vittorio Ferrari, Jiri Matas, and Marc Pollefeys. Defmo: deblurring and shape recovery of fast moving objects. In CVPR. 2021.">ROF+21</a>]</span> for more details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>pretrained</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></span>, <em>optional</em>) – Download and set pretrained weights to the model. Default: false.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Temporal super-resolution without background.</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: (B, 6, H, W)</p></li>
<li><p>Output: (B, S, 4, H, W)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">kornia</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">320</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">defmo</span> <span class="o">=</span> <span class="n">kornia</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">DeFMO</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tsr_nobgr</span> <span class="o">=</span> <span class="n">defmo</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># 2x24x4x240x320</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="kornia.feature.DeFMO.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kornia.feature.DeFMO.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.
:rtype: <span class="sphinx_autodoc_typehints-type"><a class="reference external" href="http://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="filters.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">kornia.filters</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="enhance.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">kornia.enhance</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, Kornia developers
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Local Features and Image Matching</a><ul>
<li><a class="reference internal" href="#benchmarks-and-recommendations">Benchmarks and recommendations</a></li>
<li><a class="reference internal" href="#detectors">Detectors</a><ul>
<li><a class="reference internal" href="#kornia.feature.gftt_response"><code class="docutils literal notranslate"><span class="pre">gftt_response()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.harris_response"><code class="docutils literal notranslate"><span class="pre">harris_response()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.hessian_response"><code class="docutils literal notranslate"><span class="pre">hessian_response()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.dog_response"><code class="docutils literal notranslate"><span class="pre">dog_response()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.dog_response_single"><code class="docutils literal notranslate"><span class="pre">dog_response_single()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.BlobHessian"><code class="docutils literal notranslate"><span class="pre">BlobHessian</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.CornerGFTT"><code class="docutils literal notranslate"><span class="pre">CornerGFTT</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.CornerHarris"><code class="docutils literal notranslate"><span class="pre">CornerHarris</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.BlobDoG"><code class="docutils literal notranslate"><span class="pre">BlobDoG</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.BlobDoGSingle"><code class="docutils literal notranslate"><span class="pre">BlobDoGSingle</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.KeyNet"><code class="docutils literal notranslate"><span class="pre">KeyNet</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.MultiResolutionDetector"><code class="docutils literal notranslate"><span class="pre">MultiResolutionDetector</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.MultiResolutionDetector.forward"><code class="docutils literal notranslate"><span class="pre">MultiResolutionDetector.forward()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.MultiResolutionDetector.remove_borders"><code class="docutils literal notranslate"><span class="pre">MultiResolutionDetector.remove_borders()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.ScaleSpaceDetector"><code class="docutils literal notranslate"><span class="pre">ScaleSpaceDetector</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.ScaleSpaceDetector.forward"><code class="docutils literal notranslate"><span class="pre">ScaleSpaceDetector.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.KeyNetDetector"><code class="docutils literal notranslate"><span class="pre">KeyNetDetector</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.KeyNetDetector.forward"><code class="docutils literal notranslate"><span class="pre">KeyNetDetector.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#descriptors">Descriptors</a><ul>
<li><a class="reference internal" href="#kornia.feature.DenseSIFTDescriptor"><code class="docutils literal notranslate"><span class="pre">DenseSIFTDescriptor</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.SIFTDescriptor"><code class="docutils literal notranslate"><span class="pre">SIFTDescriptor</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.MKDDescriptor"><code class="docutils literal notranslate"><span class="pre">MKDDescriptor</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.HardNet"><code class="docutils literal notranslate"><span class="pre">HardNet</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.HardNet8"><code class="docutils literal notranslate"><span class="pre">HardNet8</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.HyNet"><code class="docutils literal notranslate"><span class="pre">HyNet</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.TFeat"><code class="docutils literal notranslate"><span class="pre">TFeat</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.SOSNet"><code class="docutils literal notranslate"><span class="pre">SOSNet</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.LAFDescriptor"><code class="docutils literal notranslate"><span class="pre">LAFDescriptor</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.LAFDescriptor.forward"><code class="docutils literal notranslate"><span class="pre">LAFDescriptor.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.SOLD2"><code class="docutils literal notranslate"><span class="pre">SOLD2</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.SOLD2.forward"><code class="docutils literal notranslate"><span class="pre">SOLD2.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.get_laf_descriptors"><code class="docutils literal notranslate"><span class="pre">get_laf_descriptors()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#local-features-detector-and-descriptors-together">Local Features (Detector and Descriptors together)</a><ul>
<li><a class="reference internal" href="#kornia.feature.LocalFeature"><code class="docutils literal notranslate"><span class="pre">LocalFeature</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.LocalFeature.forward"><code class="docutils literal notranslate"><span class="pre">LocalFeature.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.SOLD2_detector"><code class="docutils literal notranslate"><span class="pre">SOLD2_detector</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.SOLD2_detector.forward"><code class="docutils literal notranslate"><span class="pre">SOLD2_detector.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.DeDoDe"><code class="docutils literal notranslate"><span class="pre">DeDoDe</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.DeDoDe.describe"><code class="docutils literal notranslate"><span class="pre">DeDoDe.describe()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.DeDoDe.detect"><code class="docutils literal notranslate"><span class="pre">DeDoDe.detect()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.DeDoDe.forward"><code class="docutils literal notranslate"><span class="pre">DeDoDe.forward()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.DeDoDe.from_pretrained"><code class="docutils literal notranslate"><span class="pre">DeDoDe.from_pretrained()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.DISK"><code class="docutils literal notranslate"><span class="pre">DISK</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.DISK.forward"><code class="docutils literal notranslate"><span class="pre">DISK.forward()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.DISK.from_pretrained"><code class="docutils literal notranslate"><span class="pre">DISK.from_pretrained()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.DISK.heatmap_and_dense_descriptors"><code class="docutils literal notranslate"><span class="pre">DISK.heatmap_and_dense_descriptors()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.DISKFeatures"><code class="docutils literal notranslate"><span class="pre">DISKFeatures</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.DISKFeatures.to"><code class="docutils literal notranslate"><span class="pre">DISKFeatures.to()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.DISKFeatures.x"><code class="docutils literal notranslate"><span class="pre">DISKFeatures.x</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.DISKFeatures.y"><code class="docutils literal notranslate"><span class="pre">DISKFeatures.y</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.SIFTFeature"><code class="docutils literal notranslate"><span class="pre">SIFTFeature</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.SIFTFeature.forward"><code class="docutils literal notranslate"><span class="pre">SIFTFeature.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.SIFTFeatureScaleSpace"><code class="docutils literal notranslate"><span class="pre">SIFTFeatureScaleSpace</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.SIFTFeatureScaleSpace.forward"><code class="docutils literal notranslate"><span class="pre">SIFTFeatureScaleSpace.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.GFTTAffNetHardNet"><code class="docutils literal notranslate"><span class="pre">GFTTAffNetHardNet</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.GFTTAffNetHardNet.forward"><code class="docutils literal notranslate"><span class="pre">GFTTAffNetHardNet.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.KeyNetAffNetHardNet"><code class="docutils literal notranslate"><span class="pre">KeyNetAffNetHardNet</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.KeyNetAffNetHardNet.forward"><code class="docutils literal notranslate"><span class="pre">KeyNetAffNetHardNet.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.KeyNetHardNet"><code class="docutils literal notranslate"><span class="pre">KeyNetHardNet</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.KeyNetHardNet.forward"><code class="docutils literal notranslate"><span class="pre">KeyNetHardNet.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#matching">Matching</a><ul>
<li><a class="reference internal" href="#kornia.feature.match_nn"><code class="docutils literal notranslate"><span class="pre">match_nn()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.match_mnn"><code class="docutils literal notranslate"><span class="pre">match_mnn()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.match_snn"><code class="docutils literal notranslate"><span class="pre">match_snn()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.match_smnn"><code class="docutils literal notranslate"><span class="pre">match_smnn()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.match_fginn"><code class="docutils literal notranslate"><span class="pre">match_fginn()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.match_adalam"><code class="docutils literal notranslate"><span class="pre">match_adalam()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.DescriptorMatcher"><code class="docutils literal notranslate"><span class="pre">DescriptorMatcher</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.DescriptorMatcher.forward"><code class="docutils literal notranslate"><span class="pre">DescriptorMatcher.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.GeometryAwareDescriptorMatcher"><code class="docutils literal notranslate"><span class="pre">GeometryAwareDescriptorMatcher</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.GeometryAwareDescriptorMatcher.forward"><code class="docutils literal notranslate"><span class="pre">GeometryAwareDescriptorMatcher.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.LocalFeatureMatcher"><code class="docutils literal notranslate"><span class="pre">LocalFeatureMatcher</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.LocalFeatureMatcher.forward"><code class="docutils literal notranslate"><span class="pre">LocalFeatureMatcher.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.LightGlueMatcher"><code class="docutils literal notranslate"><span class="pre">LightGlueMatcher</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.LightGlueMatcher.forward"><code class="docutils literal notranslate"><span class="pre">LightGlueMatcher.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.LightGlue"><code class="docutils literal notranslate"><span class="pre">LightGlue</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.LightGlue.forward"><code class="docutils literal notranslate"><span class="pre">LightGlue.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.LoFTR"><code class="docutils literal notranslate"><span class="pre">LoFTR</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.LoFTR.forward"><code class="docutils literal notranslate"><span class="pre">LoFTR.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#interactive-demo">Interactive Demo</a><ul>
<li><a class="reference internal" href="#kornia.feature.OnnxLightGlue"><code class="docutils literal notranslate"><span class="pre">OnnxLightGlue</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.OnnxLightGlue.forward"><code class="docutils literal notranslate"><span class="pre">OnnxLightGlue.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#local-affine-frames-laf">Local Affine Frames (LAF)</a><ul>
<li><a class="reference internal" href="#kornia.feature.extract_patches_from_pyramid"><code class="docutils literal notranslate"><span class="pre">extract_patches_from_pyramid()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.extract_patches_simple"><code class="docutils literal notranslate"><span class="pre">extract_patches_simple()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.normalize_laf"><code class="docutils literal notranslate"><span class="pre">normalize_laf()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.denormalize_laf"><code class="docutils literal notranslate"><span class="pre">denormalize_laf()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.laf_to_boundary_points"><code class="docutils literal notranslate"><span class="pre">laf_to_boundary_points()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.ellipse_to_laf"><code class="docutils literal notranslate"><span class="pre">ellipse_to_laf()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.make_upright"><code class="docutils literal notranslate"><span class="pre">make_upright()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.scale_laf"><code class="docutils literal notranslate"><span class="pre">scale_laf()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.get_laf_scale"><code class="docutils literal notranslate"><span class="pre">get_laf_scale()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.get_laf_center"><code class="docutils literal notranslate"><span class="pre">get_laf_center()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.rotate_laf"><code class="docutils literal notranslate"><span class="pre">rotate_laf()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.get_laf_orientation"><code class="docutils literal notranslate"><span class="pre">get_laf_orientation()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.set_laf_orientation"><code class="docutils literal notranslate"><span class="pre">set_laf_orientation()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.laf_from_center_scale_ori"><code class="docutils literal notranslate"><span class="pre">laf_from_center_scale_ori()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.laf_is_inside_image"><code class="docutils literal notranslate"><span class="pre">laf_is_inside_image()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.laf_to_three_points"><code class="docutils literal notranslate"><span class="pre">laf_to_three_points()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.laf_from_three_points"><code class="docutils literal notranslate"><span class="pre">laf_from_three_points()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.KORNIA_CHECK_LAF"><code class="docutils literal notranslate"><span class="pre">KORNIA_CHECK_LAF()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.perspective_transform_lafs"><code class="docutils literal notranslate"><span class="pre">perspective_transform_lafs()</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.PassLAF"><code class="docutils literal notranslate"><span class="pre">PassLAF</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.PassLAF.forward"><code class="docutils literal notranslate"><span class="pre">PassLAF.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.PatchAffineShapeEstimator"><code class="docutils literal notranslate"><span class="pre">PatchAffineShapeEstimator</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.PatchAffineShapeEstimator.forward"><code class="docutils literal notranslate"><span class="pre">PatchAffineShapeEstimator.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.LAFAffineShapeEstimator"><code class="docutils literal notranslate"><span class="pre">LAFAffineShapeEstimator</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.LAFAffineShapeEstimator.forward"><code class="docutils literal notranslate"><span class="pre">LAFAffineShapeEstimator.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.LAFOrienter"><code class="docutils literal notranslate"><span class="pre">LAFOrienter</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.LAFOrienter.forward"><code class="docutils literal notranslate"><span class="pre">LAFOrienter.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.PatchDominantGradientOrientation"><code class="docutils literal notranslate"><span class="pre">PatchDominantGradientOrientation</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.PatchDominantGradientOrientation.forward"><code class="docutils literal notranslate"><span class="pre">PatchDominantGradientOrientation.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.OriNet"><code class="docutils literal notranslate"><span class="pre">OriNet</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.OriNet.forward"><code class="docutils literal notranslate"><span class="pre">OriNet.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#kornia.feature.LAFAffNetShapeEstimator"><code class="docutils literal notranslate"><span class="pre">LAFAffNetShapeEstimator</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.LAFAffNetShapeEstimator.forward"><code class="docutils literal notranslate"><span class="pre">LAFAffNetShapeEstimator.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#layers">Layers</a><ul>
<li><a class="reference internal" href="#kornia.feature.FilterResponseNorm2d"><code class="docutils literal notranslate"><span class="pre">FilterResponseNorm2d</span></code></a></li>
<li><a class="reference internal" href="#kornia.feature.TLU"><code class="docutils literal notranslate"><span class="pre">TLU</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#other">Other</a><ul>
<li><a class="reference internal" href="#kornia.feature.DeFMO"><code class="docutils literal notranslate"><span class="pre">DeFMO</span></code></a><ul>
<li><a class="reference internal" href="#kornia.feature.DeFMO.forward"><code class="docutils literal notranslate"><span class="pre">DeFMO.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=cce5339e"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/custom.js?v=107dad88"></script>
    <script defer="defer" type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.38.1/gradio.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/iframe-resizer/4.3.2/iframeResizer.min.js"></script>
    </body>
</html>