{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production-ready with Kornia\n",
    "\n",
    "This tutorial presents the integration of Kornia image processings and neural networks. In real-world deployment, engineers commonly use OpenCV to read images then perform a bunch of preprocessing protocols to the image, which is sophisticated in C++ and likely to be buggy due to the decoupling of image preprocessing and many trained neural networks. In this sense, it is always a good practice to make the model grab-and-use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate neural image processors into PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model_with_proc = nn.Sequential(\n",
    "    kornia.color.BgrToRgb(),\n",
    "    kornia.enhance.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    kornia.contrib.face_detection.YuFaceDetectNet(\"test\", pretrained=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model to ONNX "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ONNX](https://onnx.ai) is an open format built to represent machine learning models. ONNX is the first step in enabling more of these tools to work together by allowing them to share models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(10, 3, 224, 224)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model_with_proc, dummy_input, \"yunet_with_proc.onnx\", verbose=False,\n",
    "    input_names=[\"input\"], output_names=[\"output\"], opset_version=13\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Convert to TensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with NVIDIA Jetson series, you may want to refer to [trtexec](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#trtexec) for the detailed command explaination.\n",
    "\n",
    "Commonly, you may use\n",
    "\n",
    "```bash\n",
    "./trtexec  --onnx=yunet_with_proc.onnx \\\n",
    "           --minShapes=input:1x3x224x224 \\\n",
    "           --optShapes=input:1x3x224x224 \\\n",
    "           --maxShapes=input:1x3x224x224 \\\n",
    "           --saveEngine=alexnet_with_proc_fp16.engine \\\n",
    "           --fp16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a9574ae5d7f28c92565154a93f74565ced849c34b51d20657bc2b5009ae35b7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
